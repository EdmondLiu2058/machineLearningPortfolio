{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nBAFs7cW7xiO",
        "outputId": "8e3c6d68-127e-4c8b-82b8-b42ba5ffc314"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import os\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAcJ0_6S7xiS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "outputId": "f65345c9-dbe3-4153-ee7e-2c9d5c44dd44"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-579c073f-49e5-475c-8a2e-e6879cf10692\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-579c073f-49e5-475c-8a2e-e6879cf10692\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving House-Price-Prediction-clean.csv to House-Price-Prediction-clean.csv\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import tarfile\n",
        "import urllib\n",
        "import pandas as pd\n",
        "import urllib.request\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
        "from sklearn.base import clone, BaseEstimator, TransformerMixin\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "get_ipython().run_line_magic('matplotlib', 'inline')\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "dataset = pd.read_csv('House-Price-Prediction-clean.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "4f4bmu7x7xiT",
        "outputId": "260709e0-b15d-49e7-fff9-af2a24c833cb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Id  MSSubClass  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
              "0        1          60     8450            7            5       2003   \n",
              "1        2          20     9600            6            8       1976   \n",
              "2        3          60    11250            7            5       2001   \n",
              "3        4          70     9550            7            5       1915   \n",
              "4        5          60    14260            8            5       2000   \n",
              "...    ...         ...      ...          ...          ...        ...   \n",
              "1455  1456          60     7917            6            5       1999   \n",
              "1456  1457          20    13175            6            6       1978   \n",
              "1457  1458          70     9042            7            9       1941   \n",
              "1458  1459          20     9717            5            6       1950   \n",
              "1459  1460          20     9937            5            6       1965   \n",
              "\n",
              "      YearRemodAdd  BsmtFinSF1  BsmtUnfSF  TotalBsmtSF  ...  WoodDeckSF  \\\n",
              "0             2003         706        150          856  ...           0   \n",
              "1             1976         978        284         1262  ...         298   \n",
              "2             2002         486        434          920  ...           0   \n",
              "3             1970         216        540          756  ...           0   \n",
              "4             2000         655        490         1145  ...         192   \n",
              "...            ...         ...        ...          ...  ...         ...   \n",
              "1455          2000           0        953          953  ...           0   \n",
              "1456          1988         790        589         1542  ...         349   \n",
              "1457          2006         275        877         1152  ...           0   \n",
              "1458          1996          49          0         1078  ...         366   \n",
              "1459          1965         830        136         1256  ...         736   \n",
              "\n",
              "      OpenPorchSF  EnclosedPorch  3SsnPorch  ScreenPorch  PoolArea  MiscVal  \\\n",
              "0              61              0          0            0         0        0   \n",
              "1               0              0          0            0         0        0   \n",
              "2              42              0          0            0         0        0   \n",
              "3              35            272          0            0         0        0   \n",
              "4              84              0          0            0         0        0   \n",
              "...           ...            ...        ...          ...       ...      ...   \n",
              "1455           40              0          0            0         0        0   \n",
              "1456            0              0          0            0         0        0   \n",
              "1457           60              0          0            0         0     2500   \n",
              "1458            0            112          0            0         0        0   \n",
              "1459           68              0          0            0         0        0   \n",
              "\n",
              "      MoSold  YrSold  SalePrice  \n",
              "0          2    2008     208500  \n",
              "1          5    2007     181500  \n",
              "2          9    2008     223500  \n",
              "3          2    2006     140000  \n",
              "4         12    2008     250000  \n",
              "...      ...     ...        ...  \n",
              "1455       8    2007     175000  \n",
              "1456       2    2010     210000  \n",
              "1457       5    2010     266500  \n",
              "1458       4    2010     142125  \n",
              "1459       6    2008     147500  \n",
              "\n",
              "[1460 rows x 32 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e55c2270-8ebc-44c4-86ba-ca414697c0ec\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>BsmtUnfSF</th>\n",
              "      <th>TotalBsmtSF</th>\n",
              "      <th>...</th>\n",
              "      <th>WoodDeckSF</th>\n",
              "      <th>OpenPorchSF</th>\n",
              "      <th>EnclosedPorch</th>\n",
              "      <th>3SsnPorch</th>\n",
              "      <th>ScreenPorch</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "      <td>8450</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2003</td>\n",
              "      <td>2003</td>\n",
              "      <td>706</td>\n",
              "      <td>150</td>\n",
              "      <td>856</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>61</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2008</td>\n",
              "      <td>208500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>9600</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>1976</td>\n",
              "      <td>1976</td>\n",
              "      <td>978</td>\n",
              "      <td>284</td>\n",
              "      <td>1262</td>\n",
              "      <td>...</td>\n",
              "      <td>298</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2007</td>\n",
              "      <td>181500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>60</td>\n",
              "      <td>11250</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2001</td>\n",
              "      <td>2002</td>\n",
              "      <td>486</td>\n",
              "      <td>434</td>\n",
              "      <td>920</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>2008</td>\n",
              "      <td>223500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>70</td>\n",
              "      <td>9550</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>1915</td>\n",
              "      <td>1970</td>\n",
              "      <td>216</td>\n",
              "      <td>540</td>\n",
              "      <td>756</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>272</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2006</td>\n",
              "      <td>140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>60</td>\n",
              "      <td>14260</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>655</td>\n",
              "      <td>490</td>\n",
              "      <td>1145</td>\n",
              "      <td>...</td>\n",
              "      <td>192</td>\n",
              "      <td>84</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>2008</td>\n",
              "      <td>250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1455</th>\n",
              "      <td>1456</td>\n",
              "      <td>60</td>\n",
              "      <td>7917</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>1999</td>\n",
              "      <td>2000</td>\n",
              "      <td>0</td>\n",
              "      <td>953</td>\n",
              "      <td>953</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>2007</td>\n",
              "      <td>175000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1456</th>\n",
              "      <td>1457</td>\n",
              "      <td>20</td>\n",
              "      <td>13175</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>1978</td>\n",
              "      <td>1988</td>\n",
              "      <td>790</td>\n",
              "      <td>589</td>\n",
              "      <td>1542</td>\n",
              "      <td>...</td>\n",
              "      <td>349</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2010</td>\n",
              "      <td>210000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1457</th>\n",
              "      <td>1458</td>\n",
              "      <td>70</td>\n",
              "      <td>9042</td>\n",
              "      <td>7</td>\n",
              "      <td>9</td>\n",
              "      <td>1941</td>\n",
              "      <td>2006</td>\n",
              "      <td>275</td>\n",
              "      <td>877</td>\n",
              "      <td>1152</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2500</td>\n",
              "      <td>5</td>\n",
              "      <td>2010</td>\n",
              "      <td>266500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1458</th>\n",
              "      <td>1459</td>\n",
              "      <td>20</td>\n",
              "      <td>9717</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>1950</td>\n",
              "      <td>1996</td>\n",
              "      <td>49</td>\n",
              "      <td>0</td>\n",
              "      <td>1078</td>\n",
              "      <td>...</td>\n",
              "      <td>366</td>\n",
              "      <td>0</td>\n",
              "      <td>112</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2010</td>\n",
              "      <td>142125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1459</th>\n",
              "      <td>1460</td>\n",
              "      <td>20</td>\n",
              "      <td>9937</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>1965</td>\n",
              "      <td>1965</td>\n",
              "      <td>830</td>\n",
              "      <td>136</td>\n",
              "      <td>1256</td>\n",
              "      <td>...</td>\n",
              "      <td>736</td>\n",
              "      <td>68</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2008</td>\n",
              "      <td>147500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1460 rows Ã— 32 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e55c2270-8ebc-44c4-86ba-ca414697c0ec')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e55c2270-8ebc-44c4-86ba-ca414697c0ec button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e55c2270-8ebc-44c4-86ba-ca414697c0ec');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QjMi44Qj7xiT"
      },
      "outputs": [],
      "source": [
        "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self,additional=1):\n",
        "        self.additional = additional\n",
        "    \n",
        "    def fit(self,X,y=None):\n",
        "        return self\n",
        "    \n",
        "    def transform(self,X):\n",
        "        if self.additional==1:\n",
        "            X[\"HouseArea\"] = X[\"TotalBsmtSF\"] + X[\"1stFlrSF\"] + X[\"2ndFlrSF\"]   \n",
        "            # X[\"TotalArea\"] = X[\"TotalBsmtSF\"] + X[\"1stFlrSF\"] + X[\"2ndFlrSF\"] + X[\"GarageArea\"] + X[\"WoodDeckSF\"] + [\"OpenPorchSF\"] + [\"PoolArea\"]\n",
        "            # X[\"HouseAge\"] = X[\"YrSold\"] - X[\"YearBuilt\"]\n",
        "        elif self.additional == 2:\n",
        "            X[\"HouseArea\"] = X[\"TotalBsmtSF\"] + X[\"1stFlrSF\"] + X[\"2ndFlrSF\"]   \n",
        "            X[\"TotalArea\"] = X[\"TotalBsmtSF\"] + X[\"1stFlrSF\"] + X[\"2ndFlrSF\"] + X[\"GarageArea\"] + X[\"WoodDeckSF\"] + X[\"OpenPorchSF\"] + X[\"PoolArea\"]\n",
        "            # X[\"HouseAge\"] = X[\"YrSold\"] - X[\"YearBuilt\"]\n",
        "        else :\n",
        "            X[\"HouseArea\"] = X[\"TotalBsmtSF\"] + X[\"1stFlrSF\"] + X[\"2ndFlrSF\"]   \n",
        "            X[\"TotalArea\"] = X[\"TotalBsmtSF\"] + X[\"1stFlrSF\"] + X[\"2ndFlrSF\"] + X[\"GarageArea\"] + X[\"WoodDeckSF\"] + X[\"OpenPorchSF\"] + X[\"PoolArea\"]\n",
        "            X[\"HouseAge\"]  = X[\"YrSold\"] - X[\"YearBuilt\"]\n",
        "\n",
        "        return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GzCxw2z7xiU",
        "outputId": "2500c1d2-889b-4a1a-acdc-3aefbfe28c5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  \"\"\"\n"
          ]
        }
      ],
      "source": [
        "# PIPELINE\n",
        "pipe = Pipeline([('add_feature', CombinedAttributesAdder(additional=3))])\n",
        "full_data = pd.read_csv('House-Price-Prediction-clean.csv')\n",
        "\n",
        "FullDataPipe = pipe.fit_transform(full_data.drop('Id',1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwKvLdKg7xiV",
        "outputId": "6a02c141-bf20-4d42-e1d4-7f2ca6d7b627"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SalePrice        1.000000\n",
              "TotalArea        0.813495\n",
              "OverallQual      0.790982\n",
              "HouseArea        0.782260\n",
              "GrLivArea        0.708624\n",
              "GarageCars       0.640409\n",
              "GarageArea       0.623431\n",
              "TotalBsmtSF      0.613581\n",
              "1stFlrSF         0.605852\n",
              "FullBath         0.560664\n",
              "TotRmsAbvGrd     0.533723\n",
              "YearBuilt        0.522897\n",
              "YearRemodAdd     0.507101\n",
              "Fireplaces       0.466929\n",
              "BsmtFinSF1       0.386420\n",
              "WoodDeckSF       0.324413\n",
              "2ndFlrSF         0.319334\n",
              "OpenPorchSF      0.315856\n",
              "HalfBath         0.284108\n",
              "LotArea          0.263843\n",
              "BsmtFullBath     0.227122\n",
              "BsmtUnfSF        0.214479\n",
              "BedroomAbvGr     0.168213\n",
              "ScreenPorch      0.111447\n",
              "PoolArea         0.092404\n",
              "MoSold           0.046432\n",
              "3SsnPorch        0.044584\n",
              "MiscVal         -0.021190\n",
              "YrSold          -0.028923\n",
              "OverallCond     -0.077856\n",
              "MSSubClass      -0.084284\n",
              "EnclosedPorch   -0.128578\n",
              "KitchenAbvGr    -0.135907\n",
              "HouseAge        -0.523350\n",
              "Name: SalePrice, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "corr_matrix = FullDataPipe.corr()\n",
        "corr_matrix[\"SalePrice\"].sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ykdrB_8W7xiV"
      },
      "outputs": [],
      "source": [
        "label_1 =  FullDataPipe[FullDataPipe['SalePrice']>100000]\n",
        "label_2 = label_1[label_1['SalePrice']<400000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "IQBcCoz57xiW",
        "outputId": "161c2998-38cb-4b85-a518-bd187878cf13"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEICAYAAAC3Y/QeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAXN0lEQVR4nO3df5Bd5X3f8ffX/C7rIAh0K0sqi2McilFDYAN47LS7duPwIyk4Q1wYYoNNKzfFbTxRUwt7psbjkshtZIIHD7ZcCDh2WFMbBg3YIVh4xyEpJsgmCJCJF7PEaIgAIwSrYFqJb/+4j8xlu9Lu/aW9u8/7NbOz5z7nOed5vjpXnz333LN3IzORJNXldfM9AUnS/mf4S1KFDH9JqpDhL0kVMvwlqUKGvyRVyPBXdSJiMiL+VQ/2+8sR8Wi39yv1guGvBSsi3h4RfxUROyLiuYj4y4j4pS7ufygiMiKmytdkRKzZW//M/IvM/PlujS/10oHzPQGpHRHxM8DtwG8DNwMHA78MvNyD4ZZk5q6IeCuwMSIeyMw/mzafAzNzVw/GlnrCM38tVG8GyMybMnN3Zr6UmX+emQ9GxM9FxN0R8eOIeDYivhwRS2baSUS8LiLWRMRjpf/NEXHUTH0z838DDwMnRcRIRDwZER+JiL8H/nhPW9O+V0TELRHxTNn3NU3rPhARWyJie0TcGRHHdvVfR5qF4a+F6m+B3RFxY0ScFRFHNq0L4A+ANwD/DFgBXLGX/fxH4DzgX5b+24HPTu8UDW8D3gJ8rzT/E+Ao4Fhg1bT+B9B4ZfIEMAQsA8bKunOBjwK/ARwD/AVw05wrl7rA8NeClJkvAG8HEvgC8ExEbIiIwcycyMy7MvPlzHwG+DSNcJ/Jvwc+lplPZubLNH5InB8RzZdEnwWeA/4nsCYzN5b2V4CPl3Femrbf02j8MPm9zNyZmT/JzHuaxvyDzNxSLhX9PnCyZ//an7zmrwUrM7cAlwBExAnAl4A/iogPA1fTeA/g9TROcrbvZTfHArdGxCtNbbuBwabHR+/lev4zmfmTvex3BfDEXrY7Frg6ItY1tQWNVwdP7GV/Uld55q9FITO/D9wAnETjTDqBlZn5M8Bv0QjXmfwIOCszlzR9HZqZW+cy7D7W/Qj4p9NeQTSv++C0MQ/LzL+aw5hSVxj+WpAi4oSIWB0Ry8vjFcCFwL00zvangB0RsQz4vX3s6nPAlXsuuUTEMeWafKfuA54C1kbE4RFxaHnPYM+Yl0fEW8qYR0TEb3ZhTGnODH8tVC8CpwPfiYidNEL/IWA18AngFGAHcAdwyz72czWwAfjziHix7Of0TieXmbuBXwfeBPwd8CTwb8q6W4FPAWMR8UKZ91mdjim1IvxjLpJUH8/8JalChr8kVcjwl6QKGf6SVKG++CWvo48+OoeGhlrebufOnRx++OHdn9A8sZ7+tpjqWUy1QL31bNq06dnMPKadMfoi/IeGhrj//vtb3m58fJyRkZHuT2ieWE9/W0z1LKZaoN56IqLt3wj3so8kVcjwl6QKGf6SVCHDX5IqZPhLUoUMf0mqkOEvSRUy/CWpQoa/JFWoL37Dd6EaWnNHV/e3euUuLpnDPifXntPVcSXVxzN/SaqQ4S9JFTL8JalChr8kVcjwl6QKGf6SVCHDX5IqZPhLUoUMf0mqkOEvSRUy/CWpQrOGf0QcGhH3RcTfRMTDEfGJ0n5cRHwnIiYi4isRcXBpP6Q8nijrh3pbgiSpVXM5838ZeEdm/gJwMnBmRJwBfAq4KjPfBGwHLi39LwW2l/arSj9JUh+ZNfyzYao8PKh8JfAO4Kul/UbgvLJ8bnlMWf/OiIiuzViS1LHIzNk7RRwAbALeBHwW+B/AveXsnohYAXwjM0+KiIeAMzPzybLuMeD0zHx22j5XAasABgcHTx0bG2t58lNTUwwMDLS8Xbds3rqjq/sbPAy2vTR7v5XLjujquL0y38en2xZTPYupFqi3ntHR0U2ZOdzOGHP6PP/M3A2cHBFLgFuBE9oZbNo+1wPrAYaHh3NkZKTlfYyPj9POdt0yl8/eb8XqlbtYt3n2QzJ50UhXx+2V+T4+3baY6llMtYD1tKOlu30y83ngW8BbgSURsSeplgNby/JWYAVAWX8E8OOuzFaS1BVzudvnmHLGT0QcBvwKsIXGD4HzS7eLgdvK8obymLL+7pzLtSVJ0n4zl8s+S4Eby3X/1wE3Z+btEfEIMBYR/w34HnBd6X8d8CcRMQE8B1zQg3lLkjowa/hn5oPAL87Q/kPgtBnafwL8ZldmJ0nqCX/DV5IqZPhLUoUMf0mqkOEvSRUy/CWpQoa/JFXI8JekChn+klQhw1+SKmT4S1KFDH9JqpDhL0kVMvwlqUKGvyRVyPCXpAoZ/pJUIcNfkipk+EtShebyN3zVZ4bW3DFvY0+uPWfexpbUPZ75S1KFDH9JqpDhL0kVMvwlqUKzvuEbESuALwKDQALrM/PqiLgC+HfAM6XrRzPz62Wby4FLgd3Af8rMO3swd2B+3/yUpIVqLnf77AJWZ+Z3I+L1wKaIuKusuyoz/7C5c0ScCFwAvAV4A/DNiHhzZu7u5sQlSe2b9bJPZj6Vmd8tyy8CW4Bl+9jkXGAsM1/OzMeBCeC0bkxWktQdkZlz7xwxBHwbOAn4XeAS4AXgfhqvDrZHxDXAvZn5pbLNdcA3MvOr0/a1ClgFMDg4eOrY2FjLk5+amuLxHYvnBcXgYbDtpfmexb6tXHbEnPtOTU0xMDDQw9nsX4upnsVUC9Rbz+jo6KbMHG5njDn/kldEDABfAz6cmS9ExLXAJ2m8D/BJYB3wgbnuLzPXA+sBhoeHc2RkpIVpN4yPj7Punp0tb9evVq/cxbrN/f17d5MXjcy57/j4OO0c1361mOpZTLWA9bRjTnf7RMRBNIL/y5l5C0BmbsvM3Zn5CvAFXr20sxVY0bT58tImSeoTs4Z/RARwHbAlMz/d1L60qdu7gYfK8gbggog4JCKOA44H7uvelCVJnZrLNYa3Ae8FNkfEA6Xto8CFEXEyjcs+k8AHATLz4Yi4GXiExp1Cl3mnjyT1l1nDPzPvAWKGVV/fxzZXAld2MC9JUg/5G76SVCHDX5IqZPhLUoUMf0mqkOEvSRUy/CWpQoa/JFXI8JekChn+klQhw1+SKmT4S1KFDH9JqpDhL0kVMvwlqUKGvyRVyPCXpAoZ/pJUIcNfkipk+EtShQx/SaqQ4S9JFTL8JalChr8kVWjW8I+IFRHxrYh4JCIejojfKe1HRcRdEfGD8v3I0h4R8ZmImIiIByPilF4XIUlqzVzO/HcBqzPzROAM4LKIOBFYA2zMzOOBjeUxwFnA8eVrFXBt12ctSerIrOGfmU9l5nfL8ovAFmAZcC5wY+l2I3BeWT4X+GI23AssiYilXZ+5JKltkZlz7xwxBHwbOAn4u8xcUtoD2J6ZSyLidmBtZt5T1m0EPpKZ90/b1yoarwwYHBw8dWxsrOXJT01N8fiO3S1v168GD4NtL833LPZt5bIj5tx3amqKgYGBHs5m/1pM9SymWqDeekZHRzdl5nA7Yxw4144RMQB8DfhwZr7QyPuGzMyImPtPkcY264H1AMPDwzkyMtLK5gCMj4+z7p6dLW/Xr1av3MW6zXM+JPNi8qKROfcdHx+nneParxZTPYupFrCedszpbp+IOIhG8H85M28pzdv2XM4p358u7VuBFU2bLy9tkqQ+MZe7fQK4DtiSmZ9uWrUBuLgsXwzc1tT+vnLXzxnAjsx8qotzliR1aC7XGN4GvBfYHBEPlLaPAmuBmyPiUuAJ4D1l3deBs4EJ4B+A93d1xpKkjs0a/uWN29jL6nfO0D+ByzqclySph/wNX0mqkOEvSRUy/CWpQoa/JFXI8JekChn+klQhw1+SKmT4S1KFDH9JqpDhL0kVMvwlqUKGvyRVyPCXpAoZ/pJUIcNfkipk+EtShQx/SaqQ4S9JFTL8JalChr8kVcjwl6QKGf6SVCHDX5IqNGv4R8T1EfF0RDzU1HZFRGyNiAfK19lN6y6PiImIeDQifrVXE5ckte/AOfS5AbgG+OK09qsy8w+bGyLiROAC4C3AG4BvRsSbM3N3F+aqPjC05o459129cheXtNB/XybXntOV/UhqmPXMPzO/DTw3x/2dC4xl5suZ+TgwAZzWwfwkST0QmTl7p4gh4PbMPKk8vgK4BHgBuB9YnZnbI+Ia4N7M/FLpdx3wjcz86gz7XAWsAhgcHDx1bGys5clPTU3x+I7F86Ji8DDY9tJ8z6J7ulnPymVHdGdHHZiammJgYGC+p9EVi6kWqLee0dHRTZk53M4Yc7nsM5NrgU8CWb6vAz7Qyg4ycz2wHmB4eDhHRkZansT4+Djr7tnZ8nb9avXKXazb3O4h6T/drGfyopGu7KcT4+PjtPM87UeLqRawnna0dbdPZm7LzN2Z+QrwBV69tLMVWNHUdXlpkyT1kbbCPyKWNj18N7DnTqANwAURcUhEHAccD9zX2RQlSd0262vyiLgJGAGOjogngY8DIxFxMo3LPpPABwEy8+GIuBl4BNgFXOadPpLUf2YN/8y8cIbm6/bR/0rgyk4mJUnqLX/DV5IqZPhLUoUMf0mqkOEvSRUy/CWpQoa/JFXI8JekChn+klQhw1+SKmT4S1KFDH9JqpDhL0kVMvwlqUKGvyRVyPCXpAoZ/pJUocXz18K1qA2tuWPexp5ce868jS31imf+klQhw1+SKmT4S1KFDH9JqpDhL0kVMvwlqUKzhn9EXB8RT0fEQ01tR0XEXRHxg/L9yNIeEfGZiJiIiAcj4pReTl6S1J65nPnfAJw5rW0NsDEzjwc2lscAZwHHl69VwLXdmaYkqZtmDf/M/Dbw3LTmc4Eby/KNwHlN7V/MhnuBJRGxtFuTlSR1R2Tm7J0ihoDbM/Ok8vj5zFxSlgPYnplLIuJ2YG1m3lPWbQQ+kpn3z7DPVTReHTA4OHjq2NhYy5Ofmpri8R27W96uXw0eBttemu9ZdM9iqWflsiOAxvNtYGBgnmfTHYupFqi3ntHR0U2ZOdzOGB1/vENmZkTM/hPk/99uPbAeYHh4OEdGRloee3x8nHX37Gx5u361euUu1m1ePJ+4sVjqmbxoBGg839p5nvajxVQLWE872r3bZ9ueyznl+9OlfSuwoqnf8tImSeoj7Yb/BuDisnwxcFtT+/vKXT9nADsy86kO5yhJ6rJZX5NHxE3ACHB0RDwJfBxYC9wcEZcCTwDvKd2/DpwNTAD/ALy/B3OWJHVo1vDPzAv3suqdM/RN4LJOJyVJ6i1/w1eSKmT4S1KFDH9JqpDhL0kVMvwlqUKGvyRVaOH/7r3UY0Nr7gAaH1dxSVneHybXnrPfxlJ9PPOXpAoZ/pJUIcNfkipk+EtShQx/SaqQ4S9JFTL8JalChr8kVcjwl6QKGf6SVCHDX5IqZPhLUoUMf0mqkOEvSRUy/CWpQoa/JFWooz/mEhGTwIvAbmBXZg5HxFHAV4AhYBJ4T2Zu72yakqRu6saZ/2hmnpyZw+XxGmBjZh4PbCyPJUl9pBeXfc4FbizLNwLn9WAMSVIHIjPb3zjicWA7kMDnM3N9RDyfmUvK+gC273k8bdtVwCqAwcHBU8fGxloef2pqisd37G57/v1m8DDY9tJ8z6J7rKczK5cd0bN9T01NMTAw0LP972+11jM6Orqp6apLSzr9A+5vz8ytEfGPgbsi4vvNKzMzI2LGny6ZuR5YDzA8PJwjIyMtDz4+Ps66e3a2Pus+tXrlLtZt7vSQ9A/r6czkRSM92/f4+Djt/J/rV9bTuo4u+2Tm1vL9aeBW4DRgW0QsBSjfn+50kpKk7mo7/CPi8Ih4/Z5l4F3AQ8AG4OLS7WLgtk4nKUnqrk5eww4CtzYu63Mg8KeZ+WcR8dfAzRFxKfAE8J7OpylJ6qa2wz8zfwj8wgztPwbe2cmkJEm9tXjejZMWmaE1d/Rs36tX7uKSHu6/XZNrz5nvKVTDj3eQpAoZ/pJUIcNfkipk+EtShQx/SaqQ4S9JFTL8JalChr8kVcjwl6QKGf6SVCHDX5Iq5Gf7SKpeLz9HaTbz9XlGnvlLUoUMf0mqkOEvSRXymr+kvtHutfd+/fsE/cwzf0mqkOEvSRUy/CWpQoa/JFXI8JekChn+klShnoV/RJwZEY9GxERErOnVOJKk1vUk/CPiAOCzwFnAicCFEXFiL8aSJLWuV2f+pwETmfnDzPw/wBhwbo/GkiS1KDKz+zuNOB84MzP/bXn8XuD0zPxQU59VwKry8OeBR9sY6mjg2Q6n20+sp78tpnoWUy1Qbz3HZuYx7Qwwbx/vkJnrgfWd7CMi7s/M4S5Nad5ZT39bTPUsplrAetrRq8s+W4EVTY+XlzZJUh/oVfj/NXB8RBwXEQcDFwAbejSWJKlFPbnsk5m7IuJDwJ3AAcD1mflwD4bq6LJRH7Ke/raY6llMtYD1tKwnb/hKkvqbv+ErSRUy/CWpRpk5L1/A9cDTwENNbUcBdwE/KN+PLO0BfAaYAB4ETmna5uLS/wfAxU3tpwKbyzaf4dVLXDOO0YNarqBxh9MD5evspnWXl3k9CvxqU/uZpW0CWNPUfhzwndL+FeDg0n5IeTxR1g916disAL4FPAI8DPzOQj0++6hlQR4f4FDgPuBvSj2faHcO3aqzR/XcADzedHxO7vfnWtN4BwDfA27v52PTcaEd/AP9C+AUXhuY/31PQcAa4FNl+WzgG+XAnwF8p+ng/bB8P7Is7wmk+0rfKNueta8xelDLFcB/nqHvieWJfkg5YI+VJ8sBZfmNwMGlz4llm5uBC8ry54DfLsv/AfhcWb4A+EqXjs3SPf+pgNcDf1vmveCOzz5qWZDHp/x7DZTlg2j8hz+j1Tl0s84e1XMDcP4M/fv2udY0x98F/pRXw78vj01XA72Nf6QhXhuYjwJLm/7TPlqWPw9cOL0fcCHw+ab2z5e2pcD3m9p/2m9vY/SgliuYOVwuBy5venwn8Nbydef0fuUJ+yxwYGn/ab8925blA0u/6MFxug34lYV8fGaoZcEfH+AfAd8FTm91Dt2ss0f13MDM4d/XzzUav9O0EXgHcHs7z4/9dWz67Zr/YGY+VZb/Hhgsy8uAHzX1e7K07av9yRna9zVGL3woIh6MiOsj4sjS1motPws8n5m7prW/Zl9l/Y7Sv2siYgj4RRpnZAv6+EyrBRbo8YmIAyLiARqXGu+icTbY6hy6WWdX68nMPcfnynJ8roqIQ6bXM8d57+/n2h8B/wV4pTxu5/mxX45Nv4X/T2XjR1gu4DGuBX4OOBl4CljXo3F6JiIGgK8BH87MF5rXLbTjM0MtC/b4ZObuzDyZxlnmacAJ8zyljkyvJyJOonFGewLwSzQu5Xykx3Po+LkWEb8GPJ2Zm7ozq97qt/DfFhFLAcr3p0v73j4uYl/ty2do39cYXZWZ28qT+hXgCzT+kzLLnGdq/zGwJCIOnNb+mn2V9UeU/h2LiINohOWXM/OW0rwgj89MtSz041NqeJ7Gm9lvbWMO3ayz2/WcmZlPZcPLwB/T/vHZn8+1twH/OiImaXyS8TuAq+nTY9Nv4b+Bxjv2lO+3NbW/LxrOAHaUl2t3Au+KiCPLy/Z30bjW9RTwQkScEREBvG/avmYao6v2PKmKdwMPNY1/QUQcEhHHAcfTeENqxo/EKGck3wLOn2HOzbWcD9xd+nc69wCuA7Zk5qebVi2447O3Whbq8YmIYyJiSVk+jMb7F1vamEM36+x2Pd9vCuUAzuO1x6cvn2uZeXlmLs/MIRr/bndn5kX067Hp9A2ODt4YuYnGy+3/S+Ma1aU0rl1tpHHr1TeBo0rfoPHHYR6jccvWcNN+PkDj9qYJ4P1N7cM0njCPAdfw6u1dM47Rg1r+pMz1wXIwlzb1/1iZ16OUOw9K+9k07kZ5DPhYU/sby8GfAP4XcEhpP7Q8nijr39ilY/N2Gi+BH6TpVsiFeHz2UcuCPD7AP6dxG+GD5d/vv7Y7h27V2aN67i7H5yHgS7x6R1DfPtem1TXCq3f79OWx8eMdJKlC/XbZR5K0Hxj+klQhw1+SKmT4S1KFDH9JqpDhL0kVMvwlqUL/D2A3QUWYq1DNAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# hist of SalePrice\n",
        "label_2.hist('SalePrice',bins=10)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oxemg1yo7xiW"
      },
      "outputs": [],
      "source": [
        "df_reg = label_2[['SalePrice', 'TotalArea', 'OverallQual', 'HouseArea', 'GrLivArea', 'GarageCars', 'GarageArea', 'TotalBsmtSF', 'HouseAge']]\n",
        "df_reg_low = label_2[['SalePrice','TotalArea','TotalBsmtSF','MiscVal','LotArea','BsmtUnfSF','BsmtFinSF1']]\n",
        "df_reg_high= label_2[['SalePrice','KitchenAbvGr','BedroomAbvGr','OverallQual','BsmtFullBath','GarageCars']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "A1AkfuqG7xiX",
        "outputId": "f65a541f-e799-4041-f662-7d5965650c9a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "f, ax = plt.subplots(figsize=(10, 10))\n",
        "mat = df_reg.corr('spearman')\n",
        "mask = np.triu(np.ones_like(mat, dtype=bool))\n",
        "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
        "sns.heatmap(mat, mask=mask, cmap=cmap, vmax=1, center=0, annot = True,\n",
        "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1ieSuTM7xiX"
      },
      "source": [
        "#### do split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6NWN5lQI7xiY"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
        "from sklearn.model_selection import cross_val_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojGyTt7y7xie"
      },
      "source": [
        "# Regression MLP"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_evaluate(true, predicted):  \n",
        "    # mae = mean_absolute_error(true, predicted)\n",
        "    mse = mean_squared_error(true, predicted)\n",
        "    rmse = np.sqrt(mean_squared_error(true, predicted))\n",
        "    r2_square = r2_score(true, predicted)\n",
        "    # print('MAE:', mae)\n",
        "    print('MSE:', mse)\n",
        "    print('RMSE:', rmse)\n",
        "    print('R2 Square', r2_square)\n",
        "    print('__________________________________')"
      ],
      "metadata": {
        "id": "B1A6B5V5qvBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRY-_Pwa7xie"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_reg.drop('SalePrice', 1)\n",
        "y = df_reg['SalePrice']/10000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnhGpSnw9dUr",
        "outputId": "fd923008-7b10-48a8-b354-c3da8d52d221"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_2hzpzt7xie"
      },
      "outputs": [],
      "source": [
        "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, random_state=42)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_valid = scaler.transform(X_valid)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape[0], X_valid.shape[0], X_test.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HHHBA-MG8OB",
        "outputId": "1a9d75f0-23ad-4ba4-9d6c-dc2e904edde8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "735 246 328\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5 hidden neurons\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Input(shape=X_train.shape[1:]),\n",
        "    keras.layers.Dense(100, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
        "    keras.layers.Dense(3, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6pYJSkaNowJ",
        "outputId": "fde715d0-8df1-4106-d88b-ab2c358e71a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 100)               900       \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 3)                 303       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 4         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,207\n",
            "Trainable params: 1,207\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAcVsqNvQL7h",
        "outputId": "c6c615a1-bd03-4277-cb2b-9c4416bd66ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'dense_3/kernel:0' shape=(8, 100) dtype=float32, numpy=\n",
              " array([[ 1.13245890e-01, -7.57160783e-02,  3.26450318e-02,\n",
              "         -2.44593322e-02, -9.76490825e-02, -3.48812938e-02,\n",
              "          6.07658774e-02,  9.00670141e-02, -8.99169892e-02,\n",
              "          1.84963122e-01,  7.72943348e-02, -9.17278379e-02,\n",
              "          1.75558761e-01, -1.87348977e-01,  3.21469754e-02,\n",
              "         -1.15834266e-01,  1.06248274e-01, -1.08051598e-02,\n",
              "         -1.74899846e-02,  1.83588460e-01,  8.45018476e-02,\n",
              "         -1.89727470e-01, -2.28114262e-01, -5.84441423e-03,\n",
              "          3.92664820e-02, -4.14242893e-02,  1.09321073e-01,\n",
              "          2.04678878e-01,  1.40536129e-02,  2.19901577e-01,\n",
              "          1.80977836e-01, -1.85834274e-01, -2.62120813e-02,\n",
              "          1.34421751e-01, -1.25746578e-02,  1.88060299e-01,\n",
              "         -2.15476215e-01,  1.75221249e-01,  5.03709465e-02,\n",
              "         -1.74593881e-01, -2.22805142e-02, -1.19861707e-01,\n",
              "         -7.17607439e-02,  3.87244672e-02,  1.52255163e-01,\n",
              "          1.54917315e-01,  1.77894875e-01,  1.50756389e-02,\n",
              "         -2.18758553e-01, -2.16908932e-01,  1.57229766e-01,\n",
              "          1.28396437e-01,  1.51077107e-01, -6.53489083e-02,\n",
              "         -5.99129200e-02, -7.30210394e-02, -8.70458335e-02,\n",
              "         -1.05175599e-01,  2.23038986e-01, -5.36619276e-02,\n",
              "          7.99579769e-02,  1.79846838e-01, -1.86709970e-01,\n",
              "          1.64579228e-01,  2.18514398e-01, -1.23453289e-01,\n",
              "         -1.72281653e-01,  9.26804096e-02, -2.98080444e-02,\n",
              "         -6.39002919e-02,  7.32712895e-02,  8.09670836e-02,\n",
              "         -1.02548853e-01,  6.57906085e-02, -1.79695904e-01,\n",
              "         -2.32983232e-02, -5.91106713e-02,  1.36370346e-01,\n",
              "         -6.95742667e-03,  2.24859789e-01,  2.24228874e-01,\n",
              "          1.39943555e-01, -8.36417079e-04, -2.12370336e-01,\n",
              "          2.08742902e-01, -4.16650772e-02, -1.20310992e-01,\n",
              "         -1.56042874e-02,  9.25960690e-02,  1.04311809e-01,\n",
              "          3.40028852e-02, -4.15470749e-02, -1.14789531e-01,\n",
              "         -6.23273849e-02, -8.87644142e-02, -2.37577856e-02,\n",
              "          5.60501367e-02,  3.96313518e-02, -2.11328849e-01,\n",
              "          1.18163973e-02],\n",
              "        [-1.67661682e-01,  6.02243692e-02, -1.64329380e-01,\n",
              "         -6.38605058e-02, -5.89036494e-02, -1.32806450e-02,\n",
              "         -1.15764245e-01, -9.78451520e-02,  1.86598301e-03,\n",
              "          2.08286867e-01,  8.14810842e-02, -2.22107485e-01,\n",
              "         -1.96530312e-01,  2.01477334e-01, -2.14310765e-01,\n",
              "         -1.69224545e-01,  5.46746999e-02, -6.49583489e-02,\n",
              "          1.72825113e-01,  4.07833606e-02, -1.26601607e-01,\n",
              "          2.04912648e-01, -5.03811091e-02,  1.85555056e-01,\n",
              "          5.49473614e-02, -1.12152427e-01, -1.13464430e-01,\n",
              "         -7.33722746e-02, -2.21740127e-01,  2.60711461e-02,\n",
              "          7.01673180e-02, -3.01249325e-03, -1.42380923e-01,\n",
              "         -1.38963282e-01,  3.53252888e-03, -1.91757381e-01,\n",
              "          2.73670107e-02, -1.38336569e-02, -3.94787788e-02,\n",
              "          2.07195356e-01,  1.87140986e-01, -8.27135891e-02,\n",
              "          8.84253830e-02,  2.17214122e-01,  1.31588593e-01,\n",
              "         -1.78302526e-01, -2.28049859e-01,  1.80159613e-01,\n",
              "          1.38359234e-01,  3.03127021e-02, -2.09866747e-01,\n",
              "          2.19122022e-02,  4.90757823e-03,  7.14254230e-02,\n",
              "         -1.71092480e-01,  7.94043392e-02,  1.61946788e-01,\n",
              "          1.15270466e-02, -1.76356345e-01,  1.63953766e-01,\n",
              "         -9.91183221e-02, -2.34212458e-01,  1.07792363e-01,\n",
              "          9.98425037e-02, -8.85303617e-02,  1.43386558e-01,\n",
              "         -1.65235147e-01,  1.49882570e-01,  1.75045863e-01,\n",
              "         -1.31679624e-01, -6.40534908e-02, -1.01834819e-01,\n",
              "          5.90707809e-02,  2.12141231e-01,  1.30187973e-01,\n",
              "         -9.27227885e-02,  6.74548596e-02, -9.44331586e-02,\n",
              "         -1.17366947e-01,  7.08301514e-02, -5.27498126e-02,\n",
              "         -2.12254852e-01,  3.38710099e-02, -3.71687412e-02,\n",
              "         -2.35393688e-01,  4.70190793e-02, -1.30993575e-02,\n",
              "         -1.72981620e-01, -4.00752425e-02, -1.48740679e-01,\n",
              "         -2.33468205e-01, -7.35667050e-02,  8.20867270e-02,\n",
              "         -1.99174732e-02,  3.00990194e-02, -5.07725626e-02,\n",
              "         -2.95909047e-02, -1.72852367e-01,  3.26023847e-02,\n",
              "         -1.72367960e-01],\n",
              "        [-1.64675713e-03, -1.75119758e-01, -6.18000925e-02,\n",
              "          2.55790204e-02,  8.99824500e-03,  8.19143653e-03,\n",
              "          1.93278417e-01,  1.34580329e-01,  2.18339846e-01,\n",
              "          2.26197854e-01,  9.78798717e-02, -1.82847247e-01,\n",
              "         -4.28774506e-02,  2.26969272e-02, -1.86868787e-01,\n",
              "         -1.67147040e-01, -2.01557636e-01, -1.07751235e-01,\n",
              "         -2.17534781e-01,  9.09513384e-02, -2.09727660e-01,\n",
              "          1.37187585e-01, -1.96471974e-01, -8.67192745e-02,\n",
              "          1.33838788e-01,  2.32962534e-01,  1.23226807e-01,\n",
              "         -2.51688659e-02, -1.68562680e-02, -7.58169591e-02,\n",
              "          2.05008730e-01,  1.84166148e-01, -9.90784764e-02,\n",
              "          1.73923537e-01, -1.23014569e-01, -9.39994454e-02,\n",
              "         -1.31721795e-02,  1.03362843e-01, -1.84683502e-01,\n",
              "         -3.08723450e-02,  1.77873477e-01,  1.45257697e-01,\n",
              "          1.23633012e-01, -1.66928664e-01,  7.85198659e-02,\n",
              "          1.28975764e-01,  1.75376758e-01,  1.62836537e-01,\n",
              "          1.61948368e-01,  1.18367687e-01,  1.96077362e-01,\n",
              "         -6.56216890e-02,  3.55419368e-02,  1.05260000e-01,\n",
              "         -1.55422300e-01,  1.63187996e-01,  9.89008993e-02,\n",
              "         -6.01945817e-02, -7.41028637e-02,  5.16724437e-02,\n",
              "          7.42603987e-02,  2.11813316e-01, -9.45366770e-02,\n",
              "         -2.07477972e-01, -1.36815816e-01, -1.32329911e-02,\n",
              "          8.96047503e-02,  2.16953024e-01, -6.28823638e-02,\n",
              "         -1.98710084e-01, -2.05763608e-01,  2.23506838e-02,\n",
              "          6.92635626e-02, -2.32732818e-01,  1.93589464e-01,\n",
              "         -3.19374800e-02,  2.14971408e-01, -1.44529581e-01,\n",
              "         -1.51489377e-01, -1.99960947e-01, -1.53407052e-01,\n",
              "          1.07139871e-01, -1.53172821e-01,  5.66623360e-02,\n",
              "          1.68625847e-01, -1.64774507e-02,  1.90097079e-01,\n",
              "          1.24715790e-01, -1.69933110e-01, -1.69191718e-01,\n",
              "         -1.40285671e-01,  2.09358349e-01,  1.26723796e-02,\n",
              "          1.24365091e-04,  1.60381749e-01, -1.82592854e-01,\n",
              "         -1.35668680e-01, -1.94894508e-01, -1.42992511e-01,\n",
              "          9.94807333e-02],\n",
              "        [-1.73205346e-01,  1.47516564e-01, -2.29649022e-01,\n",
              "          1.97493568e-01, -2.07461908e-01,  3.66571397e-02,\n",
              "         -1.62357539e-02, -1.27568007e-01,  1.16328493e-01,\n",
              "          8.89648050e-02,  9.06138271e-02, -5.92965186e-02,\n",
              "         -6.10681474e-02,  1.12149164e-01, -3.16380709e-02,\n",
              "          1.75087050e-01, -2.30089366e-01, -1.36013329e-01,\n",
              "          1.20779052e-01, -1.78915784e-01,  4.44139987e-02,\n",
              "         -4.15349007e-03, -1.63940057e-01,  2.22138688e-01,\n",
              "         -2.31817275e-01,  4.67615873e-02, -1.44711316e-01,\n",
              "          2.17538431e-01,  1.16737172e-01,  1.27846003e-03,\n",
              "         -1.49450362e-01, -4.42860574e-02, -5.06052226e-02,\n",
              "         -1.45651981e-01, -3.96045446e-02, -6.09306246e-02,\n",
              "          4.86156493e-02, -1.36662111e-01,  1.19196966e-01,\n",
              "         -4.87014204e-02, -1.86721265e-01, -2.33375862e-01,\n",
              "          1.06955215e-01,  1.66011140e-01, -1.99714303e-01,\n",
              "          3.32404822e-02,  1.34935036e-01,  2.00712845e-01,\n",
              "         -2.34982371e-03, -7.34755546e-02,  4.36912924e-02,\n",
              "          5.89896888e-02, -2.06182495e-01,  1.92647859e-01,\n",
              "          1.78661957e-01, -1.58580095e-02,  9.11383480e-02,\n",
              "          1.75595134e-02,  3.55446786e-02,  2.20083132e-01,\n",
              "          2.18040153e-01, -4.52939272e-02, -5.76471686e-02,\n",
              "          1.62140891e-01,  1.70159355e-01,  1.23054817e-01,\n",
              "         -1.49781361e-01, -1.18702613e-01, -7.34295845e-02,\n",
              "          1.64856210e-01, -1.10654816e-01,  2.05038115e-01,\n",
              "          1.51762649e-01, -8.72203708e-03, -1.37983784e-01,\n",
              "         -1.37958884e-01, -7.34398216e-02, -3.42158228e-02,\n",
              "         -2.34838277e-02, -1.00746870e-01, -1.08022034e-01,\n",
              "          3.63711566e-02, -2.19103590e-01,  2.23526374e-01,\n",
              "         -2.53663361e-02,  1.54219016e-01,  6.74340576e-02,\n",
              "          2.00690195e-01,  6.03201240e-02, -1.61066040e-01,\n",
              "          5.89756817e-02, -1.62006259e-01,  2.35061303e-01,\n",
              "          1.77698687e-01, -2.08221167e-01,  2.65518874e-02,\n",
              "          5.81800938e-04, -3.36201489e-02, -7.15659559e-03,\n",
              "          6.13215417e-02],\n",
              "        [-1.53063923e-01,  1.95404872e-01, -1.40955746e-01,\n",
              "          7.55903274e-02, -2.30201811e-01,  1.26126245e-01,\n",
              "          8.81357044e-02,  7.99144059e-02, -1.05764255e-01,\n",
              "         -1.56370938e-01,  2.42542177e-02, -2.10161716e-01,\n",
              "          1.27304271e-01, -7.25124776e-02,  1.42347440e-01,\n",
              "         -1.65146247e-01,  1.37463853e-01, -6.34035319e-02,\n",
              "         -7.85019398e-02,  1.69289261e-02, -4.19818014e-02,\n",
              "          1.19614169e-01, -2.26055190e-01,  2.27517173e-01,\n",
              "          4.32450324e-02,  1.71947733e-01, -3.61520499e-02,\n",
              "          1.07724771e-01, -4.62917387e-02,  7.21776038e-02,\n",
              "         -8.69451314e-02, -7.10483491e-02,  1.15313157e-01,\n",
              "         -1.84350312e-01,  4.40599173e-02, -3.63527238e-02,\n",
              "          1.17150918e-01,  1.66497692e-01, -1.69700414e-01,\n",
              "         -2.30399907e-01, -1.91434473e-01,  1.44799277e-01,\n",
              "         -1.60884246e-01,  1.93786159e-01,  1.57953516e-01,\n",
              "          1.59588888e-01, -5.94497621e-02, -1.45545989e-01,\n",
              "         -2.25328296e-01,  1.06179878e-01,  1.68361530e-01,\n",
              "         -1.22233838e-01, -9.63213891e-02, -5.44398427e-02,\n",
              "          1.68293431e-01, -2.21063137e-01, -1.80285394e-01,\n",
              "         -7.19910860e-02,  8.23846012e-02,  1.42353848e-01,\n",
              "         -1.53148562e-01,  1.66835830e-01, -1.87621474e-01,\n",
              "         -4.90500480e-02,  2.14465693e-01, -1.09001845e-02,\n",
              "          1.87116936e-01,  1.97006449e-01,  1.94395334e-02,\n",
              "          1.44841060e-01, -8.09475780e-02,  1.20392740e-02,\n",
              "          2.28659734e-01,  1.78980753e-01, -1.41027272e-02,\n",
              "         -7.64328092e-02, -1.36138082e-01,  1.30206332e-01,\n",
              "          1.09410182e-01,  3.64616960e-02, -2.64927745e-02,\n",
              "          2.72352993e-03, -2.50597298e-02,  1.52928337e-01,\n",
              "          1.05835959e-01, -1.65904731e-01, -2.34967440e-01,\n",
              "         -8.22456926e-02,  2.22463384e-01,  1.22964233e-02,\n",
              "         -4.72806096e-02,  2.50751823e-02, -2.13265523e-01,\n",
              "         -1.95588976e-01, -2.06287026e-01,  1.46904573e-01,\n",
              "          1.49743810e-01, -1.30336210e-01,  1.06911168e-01,\n",
              "          1.76105335e-01],\n",
              "        [-1.04877546e-01, -7.19897896e-02, -2.21685112e-01,\n",
              "          6.38311654e-02, -1.56703055e-01,  2.05198273e-01,\n",
              "          2.02348605e-01,  2.03122571e-01,  7.71415383e-02,\n",
              "          2.04295889e-01,  1.32988587e-01, -9.64317620e-02,\n",
              "         -1.47631466e-02, -1.27124488e-02, -8.56094062e-02,\n",
              "          3.68131846e-02, -6.10458255e-02,  1.80966541e-01,\n",
              "         -1.40083373e-01, -3.38316709e-02, -1.25814855e-01,\n",
              "          5.66095561e-02, -3.55978310e-03,  2.43132263e-02,\n",
              "          3.69752496e-02,  8.78776461e-02,  2.50060111e-02,\n",
              "          2.27111265e-01,  1.04068592e-01, -3.25715840e-02,\n",
              "          6.39047474e-02,  2.27119073e-01, -7.18050748e-02,\n",
              "          7.65406936e-02,  2.35064313e-01,  8.58480185e-02,\n",
              "          2.02517956e-02,  1.95266083e-01, -1.67795479e-01,\n",
              "          5.56498021e-02, -3.88977826e-02, -2.21230388e-01,\n",
              "         -1.75564274e-01,  2.01452777e-01, -1.02415487e-01,\n",
              "         -2.15271771e-01,  1.63927928e-01, -1.19765893e-01,\n",
              "         -1.63283020e-01,  1.93838969e-01, -9.83899087e-02,\n",
              "         -1.38826996e-01, -4.82777506e-02,  2.31694654e-01,\n",
              "          2.24107280e-01,  4.24797386e-02,  2.05470666e-01,\n",
              "          2.01120973e-04, -7.12175667e-03,  2.16484860e-01,\n",
              "         -1.57781959e-01,  7.38055259e-02, -1.92006439e-01,\n",
              "         -1.50036067e-02,  1.61576971e-01, -2.62793899e-03,\n",
              "         -2.19720900e-01,  1.15483031e-01, -1.71159193e-01,\n",
              "         -1.68389976e-01,  7.01668113e-02,  1.97054997e-01,\n",
              "         -1.36677772e-02, -1.10423669e-01,  1.82466015e-01,\n",
              "         -1.01190537e-01,  1.49019912e-01,  1.29286751e-01,\n",
              "          1.49315372e-01, -1.49486497e-01,  5.49248308e-02,\n",
              "         -1.30407512e-01, -8.23908001e-02,  1.58782139e-01,\n",
              "         -4.34292406e-02,  7.05869943e-02, -3.73348594e-02,\n",
              "         -1.23288296e-01, -1.03765324e-01, -5.42368144e-02,\n",
              "         -2.26982757e-01, -6.23021424e-02,  2.11826965e-01,\n",
              "         -1.79007336e-01,  2.22097889e-01,  2.02480152e-01,\n",
              "         -3.76134813e-02, -2.22993642e-01, -9.76818949e-02,\n",
              "         -2.06343830e-01],\n",
              "        [-1.02482870e-01, -1.00502819e-02,  1.29963800e-01,\n",
              "         -6.00844920e-02, -1.61903188e-01, -2.10569933e-01,\n",
              "         -2.73009837e-02, -8.63665938e-02,  6.72829598e-02,\n",
              "          1.37454018e-01, -2.06403971e-01, -5.67771494e-02,\n",
              "         -2.26611301e-01,  1.19648442e-01, -8.06946903e-02,\n",
              "          1.03929624e-01, -1.85651779e-02, -2.09376514e-02,\n",
              "          1.41394690e-01, -1.87140778e-01, -1.57206059e-01,\n",
              "          1.33030728e-01,  1.07320324e-01,  1.26974925e-01,\n",
              "         -2.15708360e-01, -5.34788370e-02,  2.14596793e-01,\n",
              "         -1.11272909e-01, -1.00436956e-01, -7.52066672e-02,\n",
              "         -1.86418101e-01,  5.74636459e-03, -2.12399438e-01,\n",
              "         -1.83761835e-01, -2.94292867e-02,  1.57106653e-01,\n",
              "         -1.11422837e-01,  5.53292483e-02, -1.31599545e-01,\n",
              "          6.39475733e-02,  1.57011554e-01,  1.74363360e-01,\n",
              "         -8.69747996e-02,  1.14367053e-01, -1.86471090e-01,\n",
              "          3.83722931e-02, -1.93609253e-01, -2.14455590e-01,\n",
              "         -7.88533688e-03,  1.12115845e-01,  1.08872786e-01,\n",
              "         -2.98187286e-02, -7.44372606e-04, -2.92955488e-02,\n",
              "         -6.69139624e-02,  9.20007378e-02, -1.32998139e-01,\n",
              "          6.24726862e-02,  1.41808704e-01,  1.31910697e-01,\n",
              "          1.45918861e-01,  9.77280289e-02,  4.46583480e-02,\n",
              "         -2.35272989e-01,  9.36397761e-02, -1.54712260e-01,\n",
              "          8.26970190e-02,  1.57887146e-01, -5.16721457e-02,\n",
              "         -1.24148428e-01,  5.76972514e-02, -1.88005969e-01,\n",
              "          2.21866354e-01,  2.16599852e-02,  1.26429185e-01,\n",
              "         -1.08925894e-01, -1.08614221e-01, -9.90751088e-02,\n",
              "         -9.79792327e-02, -1.55050337e-01,  7.35256821e-02,\n",
              "          2.26555899e-01,  8.34754854e-02,  9.10222381e-02,\n",
              "          1.84341714e-01, -2.04432443e-01, -1.36530608e-01,\n",
              "         -2.64097750e-02, -2.03963608e-01,  1.65625364e-02,\n",
              "          2.21133158e-01,  7.46349245e-02,  8.74466151e-02,\n",
              "         -6.14726394e-02, -9.45693254e-02, -1.08949944e-01,\n",
              "          1.68081060e-01, -1.86467156e-01, -5.39729744e-02,\n",
              "         -1.42887980e-02],\n",
              "        [ 1.05342284e-01, -4.55786139e-02, -1.13058530e-01,\n",
              "         -5.71864694e-02,  2.14168832e-01, -1.11280434e-01,\n",
              "          5.05669564e-02, -9.00342166e-02,  1.59403607e-01,\n",
              "          4.96227294e-02,  1.71305463e-01,  1.28309116e-01,\n",
              "          1.50614902e-01,  1.23680428e-01,  6.66589588e-02,\n",
              "          1.15046456e-01,  2.25149378e-01,  1.59087315e-01,\n",
              "         -2.06064031e-01, -1.87327296e-01, -1.74051821e-02,\n",
              "         -1.89104766e-01, -2.05944166e-01, -1.71628773e-01,\n",
              "         -1.78000331e-03,  1.78235665e-01, -5.00415713e-02,\n",
              "          1.38077840e-01,  1.26220286e-02,  1.40154466e-01,\n",
              "         -1.34248674e-01, -7.96277672e-02, -1.26347244e-02,\n",
              "         -1.68089613e-01,  1.98473230e-01, -1.23977371e-01,\n",
              "          1.76636979e-01,  2.24764660e-01, -1.72847599e-01,\n",
              "          1.01312086e-01,  2.02917174e-01,  1.86872229e-01,\n",
              "          5.88752329e-03,  2.14165941e-01, -9.75843966e-02,\n",
              "          1.32560655e-01, -1.77849814e-01, -1.70784429e-01,\n",
              "          7.58794993e-02, -2.15704709e-01, -1.22361459e-01,\n",
              "          1.08430758e-01,  9.63054448e-02,  6.01793975e-02,\n",
              "         -3.59538496e-02,  4.60611135e-02,  2.37871706e-03,\n",
              "          3.62038761e-02,  1.46865472e-01, -1.58552110e-01,\n",
              "         -1.48938760e-01, -1.95178628e-01, -3.65059674e-02,\n",
              "          1.63803443e-01, -3.26892585e-02,  1.44985452e-01,\n",
              "          5.39445430e-02, -4.16091084e-02,  1.48576051e-02,\n",
              "         -1.34591013e-01, -1.92746520e-02, -1.96926370e-01,\n",
              "         -5.06264567e-02, -1.93695068e-01,  4.06569391e-02,\n",
              "         -1.86911941e-01,  2.32582316e-01, -1.74698412e-01,\n",
              "          8.95700306e-02,  2.34947354e-02,  5.22127599e-02,\n",
              "          1.12663016e-01,  3.55797559e-02, -1.20883234e-01,\n",
              "         -1.72254115e-01, -1.44114912e-01,  1.40956774e-01,\n",
              "          5.52365929e-02, -1.29501641e-01,  2.16242507e-01,\n",
              "          1.29087418e-02,  3.47048491e-02,  1.85117289e-01,\n",
              "         -1.36724830e-01, -1.54509157e-01,  1.51398852e-01,\n",
              "          1.90789506e-01,  2.13230506e-01,  7.08079487e-02,\n",
              "         -4.99199033e-02]], dtype=float32)>,\n",
              " <tf.Variable 'dense_3/bias:0' shape=(100,) dtype=float32, numpy=\n",
              " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       dtype=float32)>,\n",
              " <tf.Variable 'dense_4/kernel:0' shape=(100, 3) dtype=float32, numpy=\n",
              " array([[ 0.14633667, -0.0010729 , -0.06249155],\n",
              "        [ 0.19881281,  0.0664413 , -0.15345523],\n",
              "        [ 0.06657526, -0.10763739, -0.22095066],\n",
              "        [ 0.16518065,  0.19616011, -0.13392521],\n",
              "        [ 0.20266429,  0.0906969 , -0.03521289],\n",
              "        [ 0.18254092,  0.09383699, -0.01656859],\n",
              "        [ 0.01412299, -0.08196902, -0.17978632],\n",
              "        [-0.16338064,  0.00410965, -0.02750596],\n",
              "        [-0.07141283,  0.19159502, -0.1209634 ],\n",
              "        [ 0.12708962,  0.17346597, -0.20042077],\n",
              "        [-0.14279263, -0.10209854,  0.07309288],\n",
              "        [ 0.10169515,  0.17836362, -0.1267352 ],\n",
              "        [ 0.08152559,  0.10212553, -0.13564415],\n",
              "        [ 0.13046673, -0.02386701,  0.21960136],\n",
              "        [ 0.10472861,  0.23626515, -0.16841099],\n",
              "        [-0.2112313 , -0.1679363 ,  0.23904893],\n",
              "        [ 0.13661999, -0.19088377, -0.04531179],\n",
              "        [-0.21872751,  0.15987128,  0.17242637],\n",
              "        [-0.10392272, -0.10358384, -0.07867442],\n",
              "        [ 0.08954015, -0.0188251 ,  0.07124922],\n",
              "        [ 0.07306588, -0.08915783, -0.18862173],\n",
              "        [-0.21579705, -0.21431237, -0.18675755],\n",
              "        [-0.11122748,  0.00311081,  0.10931906],\n",
              "        [-0.02964716,  0.01058936,  0.052223  ],\n",
              "        [-0.20493811, -0.09111644, -0.06998269],\n",
              "        [-0.17854516, -0.04027402, -0.07827416],\n",
              "        [-0.17722717,  0.18483797,  0.19462135],\n",
              "        [-0.12823783, -0.02704504,  0.05063269],\n",
              "        [ 0.23387903,  0.00060715,  0.19512641],\n",
              "        [ 0.16644591, -0.00892283, -0.13488302],\n",
              "        [-0.09509778,  0.02461571, -0.00412604],\n",
              "        [-0.11517745,  0.08260271,  0.06070855],\n",
              "        [-0.22500484,  0.11982289, -0.02435918],\n",
              "        [ 0.14080006,  0.08094585,  0.0124158 ],\n",
              "        [ 0.19632947,  0.12287372, -0.09854233],\n",
              "        [-0.12337488,  0.06054237,  0.1803484 ],\n",
              "        [ 0.22862566, -0.01166771, -0.20245153],\n",
              "        [ 0.13902184,  0.22530848, -0.22535056],\n",
              "        [ 0.0476048 ,  0.20479873,  0.01597923],\n",
              "        [ 0.04839647, -0.18059848,  0.130544  ],\n",
              "        [ 0.15594345,  0.11948246,  0.14363465],\n",
              "        [ 0.11039257, -0.2268559 , -0.09660007],\n",
              "        [-0.07537994, -0.0628313 ,  0.14435643],\n",
              "        [ 0.1941652 ,  0.07729253, -0.22768378],\n",
              "        [-0.20435588,  0.07215676, -0.06088182],\n",
              "        [-0.1409854 ,  0.19529197,  0.1442124 ],\n",
              "        [ 0.16585478, -0.00932534, -0.13106242],\n",
              "        [ 0.03552666, -0.01379471,  0.14106521],\n",
              "        [ 0.17417961, -0.1770549 , -0.23342185],\n",
              "        [ 0.21555364, -0.13205022, -0.19319081],\n",
              "        [-0.03241029,  0.05132279, -0.17695683],\n",
              "        [ 0.12269443, -0.17868418,  0.07512912],\n",
              "        [-0.16275571,  0.06932423, -0.07592954],\n",
              "        [ 0.11657944, -0.05878459,  0.0190078 ],\n",
              "        [-0.00475489,  0.0245488 ,  0.17720881],\n",
              "        [ 0.13163134,  0.1693089 ,  0.10223809],\n",
              "        [-0.07987565, -0.14234108,  0.04940143],\n",
              "        [-0.20112383, -0.1947717 , -0.2324557 ],\n",
              "        [-0.07824607, -0.00384673,  0.03910628],\n",
              "        [ 0.17332739, -0.2242395 , -0.19178382],\n",
              "        [ 0.00649621, -0.00227332,  0.07354978],\n",
              "        [-0.12507057, -0.21951483, -0.01107249],\n",
              "        [-0.06413896, -0.11170021,  0.04849148],\n",
              "        [ 0.11365473, -0.19390027, -0.20763502],\n",
              "        [-0.15489428, -0.13849303, -0.05113423],\n",
              "        [-0.08781143, -0.186272  , -0.06292072],\n",
              "        [-0.06705701,  0.07458365, -0.05547635],\n",
              "        [-0.13818493,  0.22422248, -0.20529632],\n",
              "        [ 0.03738987, -0.05742478, -0.11420438],\n",
              "        [ 0.150089  ,  0.021451  ,  0.03427804],\n",
              "        [-0.15744144, -0.20593914,  0.10461566],\n",
              "        [-0.0679113 , -0.07344182, -0.07740404],\n",
              "        [ 0.05456269,  0.19938204, -0.23938279],\n",
              "        [-0.00705646, -0.22861414,  0.17006984],\n",
              "        [ 0.05934817,  0.02786866,  0.1361278 ],\n",
              "        [ 0.08322462, -0.03748891, -0.18005045],\n",
              "        [-0.13508587,  0.22515899, -0.24101882],\n",
              "        [ 0.21964327,  0.17649505,  0.05214733],\n",
              "        [ 0.02983642,  0.22541565,  0.07973945],\n",
              "        [-0.12826264,  0.20567426, -0.06864141],\n",
              "        [-0.21489747,  0.01181808, -0.13109107],\n",
              "        [ 0.17066795, -0.06690757, -0.22283009],\n",
              "        [-0.07331689,  0.07996479,  0.04632467],\n",
              "        [ 0.02912995,  0.08399513, -0.13110241],\n",
              "        [-0.09818372,  0.04028529,  0.23092192],\n",
              "        [-0.14073497, -0.22703566,  0.2250205 ],\n",
              "        [ 0.16137347,  0.18013123,  0.07259476],\n",
              "        [-0.02134201, -0.02587126,  0.08918437],\n",
              "        [-0.18498418,  0.04001537, -0.0889959 ],\n",
              "        [ 0.13948986,  0.1917251 ,  0.02167207],\n",
              "        [ 0.13275748,  0.20184422, -0.0220533 ],\n",
              "        [-0.0206719 , -0.19966194, -0.15305944],\n",
              "        [ 0.22645086, -0.02084252, -0.16086361],\n",
              "        [ 0.20384404, -0.01313847,  0.03673181],\n",
              "        [-0.19037342, -0.1026956 , -0.07811987],\n",
              "        [ 0.08308923, -0.09006225, -0.11117351],\n",
              "        [ 0.06612387,  0.05458045,  0.13720584],\n",
              "        [ 0.15556473, -0.13669087,  0.13972458],\n",
              "        [ 0.05787039,  0.17303893, -0.13152477],\n",
              "        [-0.03430325, -0.00396182, -0.0516634 ]], dtype=float32)>,\n",
              " <tf.Variable 'dense_4/bias:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>,\n",
              " <tf.Variable 'dense_5/kernel:0' shape=(3, 1) dtype=float32, numpy=\n",
              " array([[ 1.1226462 ],\n",
              "        [-1.1835729 ],\n",
              "        [-0.45167738]], dtype=float32)>,\n",
              " <tf.Variable 'dense_5/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yn2EbPUx7xie",
        "outputId": "fbc15950-5e29-4b17-a3d5-db13005c58fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "23/23 [==============================] - 1s 13ms/step - loss: 209.3608 - val_loss: 53.1341\n",
            "Epoch 2/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 64.3087 - val_loss: 25.6007\n",
            "Epoch 3/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 30.3809 - val_loss: 34.0822\n",
            "Epoch 4/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 27.0881 - val_loss: 60.0395\n",
            "Epoch 5/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 15.3805 - val_loss: 21.0192\n",
            "Epoch 6/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 19.6108 - val_loss: 21.6437\n",
            "Epoch 7/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 15.1084 - val_loss: 14.2977\n",
            "Epoch 8/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.1900 - val_loss: 8.3778\n",
            "Epoch 9/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 9.1850 - val_loss: 7.6831\n",
            "Epoch 10/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 10.5654 - val_loss: 10.6023\n",
            "Epoch 11/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 10.2203 - val_loss: 16.6371\n",
            "Epoch 12/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 13.3620 - val_loss: 13.9492\n",
            "Epoch 13/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.8771 - val_loss: 9.4992\n",
            "Epoch 14/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 11.5713 - val_loss: 28.2529\n",
            "Epoch 15/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.6802 - val_loss: 7.5403\n",
            "Epoch 16/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.8593 - val_loss: 8.3853\n",
            "Epoch 17/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 9.6676 - val_loss: 9.0121\n",
            "Epoch 18/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 10.9126 - val_loss: 9.3950\n",
            "Epoch 19/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.5927 - val_loss: 7.6873\n",
            "Epoch 20/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.5917 - val_loss: 9.0003\n",
            "Epoch 21/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.8413 - val_loss: 11.4586\n",
            "Epoch 22/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.1193 - val_loss: 7.7396\n",
            "Epoch 23/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 9.4599 - val_loss: 8.6213\n",
            "Epoch 24/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.4240 - val_loss: 10.2874\n",
            "Epoch 25/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.0867 - val_loss: 8.9733\n",
            "Epoch 26/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.2521 - val_loss: 7.0639\n",
            "Epoch 27/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.9546 - val_loss: 10.3790\n",
            "Epoch 28/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.2543 - val_loss: 8.0027\n",
            "Epoch 29/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.2294 - val_loss: 8.5649\n",
            "Epoch 30/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.3087 - val_loss: 7.1639\n",
            "Epoch 31/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.0854 - val_loss: 7.4028\n",
            "Epoch 32/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.5176 - val_loss: 7.5257\n",
            "Epoch 33/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.0821 - val_loss: 7.5982\n",
            "Epoch 34/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.9286 - val_loss: 7.2643\n",
            "Epoch 35/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.8045 - val_loss: 7.8783\n",
            "Epoch 36/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.8071 - val_loss: 12.1505\n",
            "Epoch 37/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.6201 - val_loss: 8.1772\n",
            "Epoch 38/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.5559 - val_loss: 7.4752\n",
            "Epoch 39/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.5595 - val_loss: 8.6058\n",
            "Epoch 40/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.3580 - val_loss: 7.5079\n",
            "Epoch 41/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.3739 - val_loss: 7.7723\n",
            "Epoch 42/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.9866 - val_loss: 8.3999\n",
            "Epoch 43/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.1373 - val_loss: 7.4319\n",
            "Epoch 44/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.9410 - val_loss: 7.6281\n",
            "Epoch 45/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.5427 - val_loss: 7.7778\n",
            "Epoch 46/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.4618 - val_loss: 7.4333\n",
            "Epoch 47/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.4784 - val_loss: 7.6359\n",
            "Epoch 48/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 10.2568 - val_loss: 8.5626\n",
            "Epoch 49/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.0095 - val_loss: 9.5198\n",
            "Epoch 50/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.3792 - val_loss: 7.3803\n",
            "Epoch 51/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.4305 - val_loss: 9.9706\n",
            "Epoch 52/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.3165 - val_loss: 12.7145\n",
            "Epoch 53/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.9452 - val_loss: 7.3114\n",
            "Epoch 54/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.1061 - val_loss: 9.2747\n",
            "Epoch 55/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.7940 - val_loss: 7.6516\n",
            "Epoch 56/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.8337 - val_loss: 7.9889\n",
            "Epoch 57/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.2754 - val_loss: 9.0038\n",
            "Epoch 58/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.8440 - val_loss: 7.7443\n",
            "Epoch 59/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.9203 - val_loss: 7.5265\n",
            "Epoch 60/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.1381 - val_loss: 7.2399\n",
            "Epoch 61/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.0324 - val_loss: 7.2394\n",
            "Epoch 62/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.7446 - val_loss: 8.9051\n",
            "Epoch 63/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.1041 - val_loss: 7.2193\n",
            "Epoch 64/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.9064 - val_loss: 7.6512\n",
            "Epoch 65/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.3950 - val_loss: 7.4357\n",
            "Epoch 66/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.3323 - val_loss: 9.1054\n",
            "Epoch 67/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.2545 - val_loss: 10.5585\n",
            "Epoch 68/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.7368 - val_loss: 8.5369\n",
            "Epoch 69/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.5755 - val_loss: 8.2709\n",
            "Epoch 70/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.0013 - val_loss: 7.0629\n",
            "Epoch 71/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.9116 - val_loss: 9.1119\n",
            "Epoch 72/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 6.1102 - val_loss: 7.1642\n",
            "Epoch 73/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.7719 - val_loss: 7.3569\n",
            "Epoch 74/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.9103 - val_loss: 8.3493\n",
            "Epoch 75/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.9640 - val_loss: 7.5261\n",
            "Epoch 76/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.4959 - val_loss: 8.5305\n",
            "Epoch 77/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.4037 - val_loss: 7.7893\n",
            "Epoch 78/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.8622 - val_loss: 7.7054\n",
            "Epoch 79/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.5275 - val_loss: 7.3655\n",
            "Epoch 80/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.4528 - val_loss: 7.2453\n",
            "Epoch 81/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.9776 - val_loss: 7.8883\n",
            "Epoch 82/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.7503 - val_loss: 10.0040\n",
            "Epoch 83/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.9819 - val_loss: 7.1366\n",
            "Epoch 84/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.4085 - val_loss: 7.2638\n",
            "Epoch 85/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.1704 - val_loss: 7.4674\n",
            "Epoch 86/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.0042 - val_loss: 8.0769\n",
            "Epoch 87/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.6284 - val_loss: 7.3839\n",
            "Epoch 88/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.6398 - val_loss: 8.9718\n",
            "Epoch 89/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.4164 - val_loss: 7.2623\n",
            "Epoch 90/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.9650 - val_loss: 8.4219\n",
            "Epoch 91/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.6574 - val_loss: 8.0082\n",
            "Epoch 92/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.9588 - val_loss: 7.5031\n",
            "Epoch 93/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.4941 - val_loss: 7.2598\n",
            "Epoch 94/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.8771 - val_loss: 8.0123\n",
            "Epoch 95/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.2464 - val_loss: 8.0884\n",
            "Epoch 96/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 5.7301 - val_loss: 7.4499\n",
            "Epoch 97/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.7070 - val_loss: 7.2794\n",
            "Epoch 98/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.5518 - val_loss: 8.9322\n",
            "Epoch 99/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.7151 - val_loss: 7.1116\n",
            "Epoch 100/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.0248 - val_loss: 8.2221\n",
            "Epoch 101/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.3721 - val_loss: 7.6607\n",
            "Epoch 102/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.1331 - val_loss: 12.0370\n",
            "Epoch 103/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.2336 - val_loss: 6.8989\n",
            "Epoch 104/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.2392 - val_loss: 7.3208\n",
            "Epoch 105/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.4139 - val_loss: 7.7511\n",
            "Epoch 106/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.6400 - val_loss: 6.9334\n",
            "Epoch 107/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.3819 - val_loss: 7.8740\n",
            "Epoch 108/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.2416 - val_loss: 9.0106\n",
            "Epoch 109/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.7173 - val_loss: 7.2740\n",
            "Epoch 110/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.8033 - val_loss: 10.5604\n",
            "Epoch 111/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.6843 - val_loss: 7.7494\n",
            "Epoch 112/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.9100 - val_loss: 9.8299\n",
            "Epoch 113/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.3702 - val_loss: 7.4118\n",
            "Epoch 114/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.7419 - val_loss: 7.3260\n",
            "Epoch 115/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.4062 - val_loss: 7.4959\n",
            "Epoch 116/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.6018 - val_loss: 7.1593\n",
            "Epoch 117/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.1592 - val_loss: 7.2015\n",
            "Epoch 118/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 4.8941 - val_loss: 7.7902\n",
            "Epoch 119/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.9373 - val_loss: 7.1815\n",
            "Epoch 120/200\n",
            " 1/23 [>.............................] - ETA: 0s - loss: 4.5548"
          ]
        }
      ],
      "source": [
        "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(learning_rate=0.01))\n",
        "history = model.fit(X_train, y_train, epochs=200, validation_data=(X_valid, y_valid))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.weights"
      ],
      "metadata": {
        "id": "zHLBAt13TJ-e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc58fe48-2b19-4543-c435-abeefaf0fb4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'dense_330/kernel:0' shape=(8, 5) dtype=float32, numpy=\n",
              " array([[ 0.30827403, -0.2805076 ,  0.15501592,  0.06491606, -0.47768143],\n",
              "        [ 1.086574  ,  0.72445273,  0.60331315, -0.34870654, -0.10457968],\n",
              "        [-0.46156603,  0.0732405 , -0.49015358, -0.09131881,  0.31920213],\n",
              "        [ 0.51467264, -0.6784652 , -0.18651365, -0.00242529, -0.1349492 ],\n",
              "        [ 0.7575608 ,  0.3484229 ,  0.02978403,  0.43673396,  0.07308689],\n",
              "        [-0.40817246, -0.28157276, -0.24428974,  0.62638956, -0.15643929],\n",
              "        [-0.10464804, -0.4871049 ,  0.24995454, -0.17437242,  0.19905311],\n",
              "        [-0.29597414,  0.13318379,  0.29446608, -0.30484176,  0.58145154]],\n",
              "       dtype=float32)>,\n",
              " <tf.Variable 'dense_330/bias:0' shape=(5,) dtype=float32, numpy=\n",
              " array([ 1.2651005 ,  1.0897661 ,  1.9320151 ,  0.15615962, -0.49098328],\n",
              "       dtype=float32)>,\n",
              " <tf.Variable 'dense_331/kernel:0' shape=(5, 3) dtype=float32, numpy=\n",
              " array([[ 1.053399  ,  0.23422147,  0.42951217],\n",
              "        [-1.295406  ,  0.14897624,  0.8098075 ],\n",
              "        [ 1.2249701 ,  0.6348035 , -0.32800937],\n",
              "        [ 0.5344525 , -0.26372892, -0.18399152],\n",
              "        [-0.82647115,  0.06079764,  0.18965785]], dtype=float32)>,\n",
              " <tf.Variable 'dense_331/bias:0' shape=(3,) dtype=float32, numpy=array([ 2.3418021 ,  0.85858476, -0.7008701 ], dtype=float32)>,\n",
              " <tf.Variable 'dense_332/kernel:0' shape=(3, 1) dtype=float32, numpy=\n",
              " array([[ 3.0586262 ],\n",
              "        [ 0.89933044],\n",
              "        [-1.203248  ]], dtype=float32)>,\n",
              " <tf.Variable 'dense_332/bias:0' shape=(1,) dtype=float32, numpy=array([1.6668137], dtype=float32)>]"
            ]
          },
          "metadata": {},
          "execution_count": 673
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mse_test = model.evaluate(X_valid, y_valid)"
      ],
      "metadata": {
        "id": "BFLapWcgPpKr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44976cb0-63bb-4906-a69d-1c00329abbb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 0s 2ms/step - loss: 8.3016\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mse \n",
        "y_pred = model.predict(X_valid).reshape(-1)\n",
        "dif = y_valid - y_pred\n",
        "np.dot(dif, dif)/len(y_valid)"
      ],
      "metadata": {
        "id": "gjXjzh-0UsZz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4196b509-29ef-4681-be08-5be44a4f03fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8.301560946175533"
            ]
          },
          "metadata": {},
          "execution_count": 675
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keras.utils.plot_model(model, show_shapes=True)"
      ],
      "metadata": {
        "id": "ntXWopf1IVY1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "outputId": "34231aa2-28d2-472d-cd7e-ec1a3e168d78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAS8AAAGVCAYAAACvj3fLAAAABmJLR0QA/wD/AP+gvaeTAAAgAElEQVR4nOzdaVgUV7oH8H8DvdPNomyCIN24L1GjGUGNMU7IqOOCYCTRJOqYQbMQIjIMLkQRNQyOMhi8My7xmWgioDJojCS56kXHJ8SYKwyKoyJGBREBBQFppIH3fvDSY9stdEHTTZHze57+wKlTdd6uU/1Sy6kqARERGIZh+OWAjbUjYBiG6QiWvBiG4SWWvBiG4SWWvBiG4SW7pwtycnKwZcsWa8TCMAxj1IEDBwzKDPa8iouLcfDgQYsExHTODz/8gB9++MHaYfBKSUkJ2755pK3+MtjzamUs0zHdy9y5cwGwvuIiPT0d8+bNY+uMJ1r7yxh2zothGF5iyYthGF5iyYthGF5iyYthGF5iyYthGF4ya/I6duwYHBwc8NVXX5lzsVbT0tKCrVu3IiAgwOj0uLg4DBkyBEqlEmKxGH5+fvjDH/6Auro6g7pnzpzB+PHjIZPJ4OHhgejoaDx69Kirv4JJelq/mdvSpUshEAh0nwULFhjUOX78OGJiYnDo0CGoVCpd3TfffNOgbmBgIBQKBWxtbTF06FCcP3/eEl+jU7788kuMHTsWCoUCPj4+WLRoEcrKynTTjxw5goSEBDQ3N+vNl5mZqbfuevfubbaYzJq8etIDKgoLC/Hiiy9i+fLlqK+vN1rn5MmTeP/993Hjxg1UVlZi48aNSEpK0g1haFVQUIDAwEBMmTIFFRUVyMjIwGeffYZly5ZZ4qu0qyf1W1dxdnZGVlYWrly5gt27d+tN+/jjj5GcnIyVK1ciODgY169fh1qtRq9evbBv3z58/fXXevW/++47HDhwADNmzEBBQQFGjx5tya/CWVpaGubPn4+5c+eipKQEhw8fxunTpzF16lQ0NTUBAGbOnAmJRIIpU6agurpaN++sWbNQUlKC06dPY9q0aeYNjJ6SlpZGRop5p76+nvz9/Ts0b15eHs2ZM4f27dtHI0eOpOeee85ovenTp1NTU5Ne2WuvvUYA6NatW7qyefPmka+vL7W0tOjKEhMTSSAQ0L///e8OxUhEFBISQiEhIR2evzvqTL+ZoiPbd1hYGHl6ehqdtmnTJhowYABpNBq9crVaTV988QXZ2NiQp6cnVVdX603PysqiWbNmcQveSiZPnkx9+vTR234//fRTAkBnzpzRqxseHk7+/v6k1WoNlvPhhx9Sr169OLXdRn+l99hzXrt370Z5eXmH5n3uuedw6NAhzJ8/H2Kx+Jn1jh49CltbW72y1t3i1r21pqYmfP3115g0aRIEAoGu3tSpU0FEOHz4cIdi7Kk602+Wdu3aNaxZswbr1q2DRCIxmB4QEICIiAjcvn0bK1assEKE5lFcXAwPDw+97bdv374AgJs3b+rVXbt2LfLy8pCUlNTlcZkteZ05cwbe3t4QCAT49NNPAQDbt2+HXC6HTCbD4cOHMXXqVCiVSnh5eWH//v26eZOTkyGRSODq6oqlS5fCw8MDEokEAQEBOHv2rK5eeHg4RCIR3N3ddWXvvfce5HI5BAIBKisrAQARERGIjIxEUVERBAIB/Pz8zPU123X79m1IpVL4+voCAK5fv466ujp4e3vr1VOr1QCA/Px8i8VmDB/67ZtvvoFSqcSGDRsssUpMlpycDCLCzJkzn1knPj4eAwYMwK5du3D8+PE2l0dE2LJlCwYPHgyxWAwnJyfMnj0bly9f1tUxtW8AoLm5GbGxsfD29oZUKsWIESOQlpbG+XuqVCqDfyit57tUKpVeuZOTEyZNmoSkpKSuPx3BYTetXcXFxQSAtm3bpitbtWoVAaATJ07QgwcPqLy8nCZOnEhyuZwaGxt19cLCwkgul9OlS5eooaGBCgoKaOzYsaRQKPQOwebPn09ubm567SYmJhIAqqio0JUFBweTWq3u0Pd40q9+9atnHjY+7eHDh6RQKCg8PFxXdurUKQJAiYmJBvWlUilNmTKlw7GZ67Cxu/fb0aNHSaFQUFxcXKe/qzkPG1UqFQ0ZMsToPGq1mn7++WciIvr+++/JxsaG+vXrR3V1dURk/LAxNjaWRCIR7d27l6qrqyk/P59Gjx5NvXv3prKyMl09U/tmxYoVJBaL6eDBg1RVVUUrV64kGxsbOnfuHKfvn52dTUKhkJKTk6mmpoYuXrxIgwcPpldffdVo/ZiYGAJAubm5euW8PWwMCAiAUqmEi4sLQkND8fDhQ9y6dUuvjp2dne6/zpAhQ7B9+3bU1tZiz549lgqzUzZu3AgPDw/Ex8frylqvKD59eAkAQqEQGo3GYvF1RHfot+nTp6OmpgZr1qwxy/LM4eHDh/j55591e9Bt8ff3x0cffYQbN27gj3/8o9E6Go0GW7ZswZw5c7BgwQI4ODhg+PDh+Otf/4rKykrs2LHDYJ62+qahoQHbt29HUFAQgoOD4ejoiNWrV0MoFHLul0mTJiE6Ohrh4eFQKpUYNmwYamtrsWvXLqP1+/fvDwC4cOECp3a4sso5L5FIBADQarVt1hszZgxkMpnebnN3lZGRgfT0dHz77bdQKBS68tZzIa1XZZ7U2NgIqVRqsRg7qyf2W0eVl5eDiCCTyUyqHx8fj4EDByIlJQVnzpwxmF5QUIC6ujqMGTNGr3zs2LEQiUR6h+HGPN03V65cQX19PYYNG6arI5VK4e7uzrlfVq1ahR07duDEiROoq6vD9evXERAQAH9/fxQXFxvUb10nd+/e5dQOV93+hL1YLEZFRYW1w2hTamoqPvnkE2RnZ6Nfv35601rP89TU1OiV19fXo6GhAR4eHpYK06L40G+d0dDQAABtXtB5kkQiwZ49eyAQCLB48WKDPe7W4QX29vYG8zo6OqK2tpZTfA8fPgQArF69Wm+c1c2bN5859MeYO3fuICEhAb///e/x8ssvQy6Xw9fXFzt37kRpaSkSExMN5mn9h9y6jrpKt05eWq0W1dXV8PLysnYoz7Rt2zbs27cPJ0+eRJ8+fQym+/r6QqFQGFyVuXbtGgBgxIgRFonTkvjQb53V+gN9elBmW/z9/bF8+XIUFhZi/fr1etMcHR0BwGiS6si6dHFxAQBs3boVRKT3ycnJMXk5hYWFaG5uNti2lUolnJ2dUVBQYDBPY2MjAHT5UUW3Tl7Z2dkgIowbN05XZmdn1+5hiyUQEaKjo3HhwgVkZmYa/Y8JPI532rRpOH36NFpaWnTlWVlZEAgEbV6p4qvu3G/m4urqCoFAgAcPHnCab/369Rg0aBByc3P1yocNGwZ7e3v89NNPeuVnz55FY2Mjnn/+eU7t9O3bFxKJBHl5eZzme1pr0rxz545eeW1tLe7fv68bMvGk1nXi5ubWqbbb062SV0tLC6qqqtDU1IT8/HxERETA29sbCxcu1NXx8/PD/fv3kZmZCa1Wi4qKCoO9GuDxiOjS0lLcuHEDtbW1Zv/hXLp0CX/605+wc+dOCIVCvV1zgUCAzZs36+quWbMGd+/exccff4yHDx8iJycHiYmJWLhwIQYOHGjWuKyhq/stKyur2w2VkMlkUKlUKCkp4TRf6+Hj0xdwJBIJIiMjkZGRgX379qGmpgYXLlzAsmXL4OHhgbCwMM7tLFq0CPv378f27dtRU1OD5uZmlJSU6BJRaGgo3Nzc2rw9ydfXF5MnT8bOnTtx+vRpaDQaFBcX6+L53e9+ZzBP6zoZPnw4p5g543Bpsk3btm0jd3d3AkAymYxmzpxJKSkpJJPJCAD179+fioqKaMeOHaRUKgkA+fj40NWrV4no8eVooVBInp6eZGdnR0qlkmbPnk1FRUV67dy7d48mT55MEomEfH196YMPPqCoqCgCQH5+frrL8+fPnycfHx+SSqU0YcIEvUvN7cnJyaHx48eTh4cHASAA5O7uTgEBAXTq1CkiIrpw4YJumrHP00MjTp06RS+88AKJxWLy8PCgqKgoamho4Lyen2SOoRJ86Ldjx46RQqGg+Pj4Tn1XIvMOlQgPDyehUEj19fW6soyMDFKr1QSAevfuTe+//77RZUZFRRkMlWhpaaHExETq378/CYVCcnJyoqCgILpy5YquDpe+efToEUVHR5O3tzfZ2dmRi4sLBQcHU0FBARERBQUFEQCKjY1t8/tXVlZSREQE+fn5kVgsJnt7exo/fjz94x//MFp/+vTp5OnpqTcin8j8QyW6ze1BYWFh5OzsbPF2+aw73B7Et34zZ/IqLCwkOzs72rt3r7nCs6jm5maaOHEi7d6922zLrKysJIlEQps3bzaYxttxXqbgcvKT6T5+Cf2m0Wjw7bfforCwUHdC2s/PD3FxcYiLizP6JJHurLm5GZmZmaitrUVoaKjZlrt27VqMHDkS4eHhAB6fGy4tLcWZM2d0F6nMpVslr65y+fJlg3NSxj7m7ESmZ7l//z5+85vfYMCAAVi8eLGuPCYmBnPnzkVoaCjnk/fWlJ2djUOHDiErK8vksWrt2bJlC/Ly8nDs2DEIhUIAwOHDh+Hp6YmJEycaPF2j0zjspnWZmJgYEolEBID69etHBw4csGj7fGXtw0Y+9ltXbd/ffvstRUdHm325fJGZmUkbN240eMpKZ7V12Cgg0r97svVVQ8Se8dTtsVefcce2b35po78O/CIOGxmG6XlY8mIYhpdY8mIYhpdY8mIYhpdY8mIYhpfsnjXhyedVM90b6yvu2Drjv2cmr44865qxrK1btwIAPvroIytHwh85OTlISkpi2zdPtPaXMc9MXq+99lqXBcSYR+v4LtZX3CQlJbF1xiPPSl7snBfDMLzEkhfDMLzEkhfDMLzEkhfDMLzEkhfDMLzU6eT1ww8/YPDgwbCxsYFAIICbm5veS1e7g0OHDkGlUume2+Xu7o4FCxZYOyyGJ5YuXar33Ddj287x48cRExNjsK29+eabBnUDAwOhUChga2uLoUOHtvkM+e7iyy+/xNixY6FQKODj44NFixahrKxMN/3IkSNISEgweDBlZmam3rrr3bu3+YLi8PycNr366qsEgKqqqjjPaylqtZocHBysHYbZWPt5XnzU0cdAOzs7U1ZWFl25csXg3QOxsbE0Y8YMqqmp0ZWp1Wrq1asXAaCjR48aLDMrK8vgGfbdVWpqKgGghIQEqq6uptzcXFKpVDRy5EjSarW6eklJSTRp0iS9HNDS0kIlJSV0+vRpmjZtWs99DLS5aDQaBAQEWDuMXwRLrOvu0J9SqVT3JNUnXzT7ySefIDU1Fenp6XpvSgeA5ORk2NjYICwsjFdPWX3a3/72N/Tp0wdRUVFwcHDAyJEjsXz5cuTl5em9yfvDDz/Ec889h2nTpuneEC8QCHRPUu3fv79Z4+qRyWv37t0oLy+3dhi/CJZY1921P69du4Y1a9Zg3bp1kEgkBtMDAgIQERGB27dvY8WKFVaI0DyKi4vh4eGhd0tV6/san3593dq1a5GXl/fMgaXm1GXJa/v27ZDL5ZDJZDh8+DCmTp0KpVIJLy8v7N+/X1cvOTkZEokErq6uWLp0KTw8PCCRSBAQEKCX1cPDwyESieDu7q4re++99yCXyyEQCFBZWQkAiIiIQGRkJIqKiiAQCODn59eh+P/5z39iyJAhcHBwgEQiwfDhw/Htt98CAJYsWaI7hler1boXiC5atAgymQwODg44cuQIgMcvOoiNjYW3tzekUilGjBihuzXlT3/6E2QyGRQKBcrLyxEZGQlPT09cuXKlQzGbgoiwZcsWDB48GGKxGE5OTpg9ezYuX76sq9OZdW2p/vzmm2+s/i7H5ORkEFGbLw6Oj4/HgAEDsGvXLhw/frzN5ZnSN6b+roC2tz0uVCqVwT+P1vNdKpVKr9zJyQmTJk1CUlJS1z+tlsMxZpuMnfNatWoVAaATJ07QgwcPqLy8nCZOnEhyuZwaGxt19cLCwkgul9OlS5eooaGBCgoKaOzYsaRQKHTv8yMimj9/Prm5uem1m5iYSACooqJCVxYcHExqtdogRi7nvA4cOEBr166l+/fv071792jcuHF6x+vBwcFka2tLt2/f1pvvjTfeoCNHjuj+XrFiBYnFYjp48CBVVVXRypUrycbGhs6dO6e3jj788EPatm0bzZkzh/7973+bFGNHznnFxsaSSCSivXv3UnV1NeXn59Po0aOpd+/eeu+27My6tkR/Hj16lBQKBcXFxXH6/uZ89ZlKpaIhQ4YYnUetVtPPP/9MRETff/892djYUL9+/aiuro6IjJ/zMrVvTP1dtbftmSo7O5uEQiElJydTTU0NXbx4kQYPHkyvvvqq0foxMTEEgHJzc/XKefnqs4CAACiVSri4uCA0NBQPHz7ErVu39OrY2dnp/uMMGTIE27dvR21tLfbs2WOJEA2EhITg448/hpOTE5ydnTFz5kzcu3cPFRUVAIBly5ahublZL76amhqcO3cO06ZNAwA0NDRg+/btCAoKQnBwMBwdHbF69WoIhUKD7/XJJ5/g/fffx6FDhzBo0KAu+U4ajQZbtmzBnDlzsGDBAjg4OGD48OH461//isrKSuzYscNsbXV1f06fPh01NTVYs2aNWZbH1cOHD/Hzzz9DrVa3W9ff3x8fffQRbty4gT/+8Y9G63Skb9r6XXHZ9tozadIkREdHIzw8HEqlEsOGDUNtbS127dpltH7rua0LFy5waocri5/zEolEAACtVttmvTFjxkAmk+ntMltT66ucWi8Fv/zyyxgwYAA+++wz3e5xamoqQkNDda9yv3LlCurr6zFs2DDdcqRSKdzd3a3yvQoKClBXV4cxY8bolY8dOxYikUjvsM7cult/dlZ5eTmIyOTXhsXHx2PgwIFISUnBmTNnDKZ3tm+e/l2Zc9tbtWoVduzYgRMnTqCurg7Xr19HQEAA/P39UVxcbFC/dZ3cvXuXUztcdesT9mKxWLenY2lff/01XnrpJbi4uEAsFuMPf/iD3nSBQIClS5fi+vXrOHHiBADg888/x+9+9ztdnYcPHwIAVq9erTfW5ebNm6ivr7fcl/l/1dXVAAB7e3uDaY6Ojqitre3S9q3Zn+bW0NAAAHpXHtsikUiwZ88eCAQCLF68GBqNRm+6ufvGXNvenTt3kJCQgN///vd4+eWXIZfL4evri507d6K0tBSJiYkG80ilUgD/WUddpdsmL61Wi+rqanh5eVmkvdOnT+uej3Xr1i0EBQXB3d0dZ8+exYMHD5CQkGAwz8KFCyGRSLBr1y5cuXIFSqUSPj4+uukuLi4AHj93i4j0Pjk5ORb5Xk9ydHQEAKM/hK5e15buz67W+gPl8rZwf39/LF++HIWFhVi/fr3eNHP3jbm2vcLCQjQ3N6NPnz565UqlEs7OzigoKDCYp/WN4q3rqKs883le1padnQ0iwrhx43RldnZ27R5udtT//u//Qi6XA3h8rK7VavHuu+/qrqYYe/Kmk5MT5s2bh9TUVCgUCrzzzjt60/v27QuJRIK8vLwuiZmrYcOGwd7eHj/99JNe+dmzZ9HY2Ijnn39eV2budW3p/uxqrq6uEAgEnMdvrV+/HkePHkVubi68vb115Vz6xhTm2vZak+adO3f0ymtra3H//n3dkIknta4TNze3TrXdnm6z59XS0oKqqio0NTUhPz8fERER8Pb2xsKFC3V1/Pz8cP/+fWRmZkKr1aKiosJgnAkAODs7o7S0FDdu3EBtbW2bPxCtVou7d+8iOztbl7xaN6rjx4+joaEBhYWFzzznsGzZMjx69AhHjx7FjBkz9KZJJBIsWrQI+/fvx/bt21FTU4Pm5maUlJQYbAyWIJFIEBkZiYyMDOzbtw81NTW4cOECli1bBg8PD4SFhenqdnZdd3V/ZmVlWXWohEwmg0qlQklJCaf5Wg8fW8+LPlluat+Y2k57215oaCjc3NzavD3J19cXkydPxs6dO3H69GloNBoUFxfr4nnyNEmr1nUyfPhwTjFzxuHSpFE//PADDR06lGxsbAgAubu704YNGyglJYVkMhkBoP79+1NRURHt2LGDlEolASAfHx+6evUqET2+FC0UCsnT05Ps7OxIqVTS7NmzqaioSK+te/fu0eTJk0kikZCvry998MEHFBUVRQDIz89Pdxn+/Pnz5OPjQ1KplCZMmED/9V//RWq1mgC0+cnIyNC1FR0dTc7OzuTo6Ehz586lTz/9lACQWq3Wu9xPRDRq1CiKiYkxun4ePXpE0dHR5O3tTXZ2duTi4kLBwcFUUFBACQkJJJVKCQD17duX9u7da/J6J+rYUImWlhZKTEyk/v37k1AoJCcnJwoKCqIrV67o1evoui4rK+vy/iwrK6Njx46RQqGg+Ph4Tt/fnEMlwsPDSSgUUn19va4sIyNDt6317t2b3n//faPLjIqKMhgqYUrfcPldtbXtEREFBQURAIqNjW3z+1dWVlJERAT5+fmRWCwme3t7Gj9+PP3jH/8wWn/69Onk6elJLS0teuXmHiphtnFendF67xhfTZs2ja5fv27xdrvrvY3duT/NmbwKCwvJzs6O8z+d7qK5uZkmTpxIu3fvNtsyKysrSSKR0ObNmw2m8XKclym4nPi0ticPQ/Pz8yGRSODr62vFiLofPvWnKTQaDb799lsUFhbqTkj7+fkhLi4OcXFxqKurs3KE3DQ3NyMzMxO1tbUIDQ0123LXrl2LkSNHIjw8HMDjuwZKS0tx5swZXLt2zWztAN3onBefREdHo7CwEFevXsWiRYsMrhwxPc/9+/d1N2YvXrxYVx4TE4O5c+ciNDSUVzdfZ2dn49ChQ8jKyjJ5rFp7tmzZgry8PBw7dkw3LvLw4cO6G7O//vprs7Sjw2E3rUvExMSQSCQiANSvXz86cOCAxdruqFWrVpGNjQ317dtX71YgS+uOh43dvT+7avv+9ttvKTo62uzL5YvMzEzauHEjNTU1mXW5bR02Coj0755MT0/HvHnzuv6mSqbT5s6dC+A/r0Bj2se2b35po78OsMNGhmF4iSUvhmF4iSUvhmF4iSUvhmF46Zn3Nqanp1syDqYDWm/DYH1lutabktk644e2biJ/5tVGhmGY7sLY1UaD5MUw5sCGJDBdjA2VYBiGn1jyYhiGl1jyYhiGl1jyYhiGl1jyYhiGl1jyYhiGl1jyYhiGl1jyYhiGl1jyYhiGl1jyYhiGl1jyYhiGl1jyYhiGl1jyYhiGl1jyYhiGl1jyYhiGl1jyYhiGl1jyYhiGl1jyYhiGl1jyYhiGl1jyYhiGl1jyYhiGl1jyYhiGl1jyYhiGl1jyYhiGl1jyYhiGl1jyYhiGl1jyYhiGl1jyYhiGl1jyYhiGl1jyYhiGl1jyYhiGl1jyYhiGl1jyYhiGl+ysHQDDfyUlJXj77bfR3NysK6uqqoJCocBLL72kV3fgwIH429/+ZuEImZ6IJS+m07y8vHDz5k0UFRUZTDt16pTe3y+++KKlwmJ6OHbYyJjFW2+9BaFQ2G690NBQC0TD/BKw5MWYxfz589HU1NRmnaFDh2LIkCEWiojp6VjyYsxCrVZjxIgREAgERqcLhUK8/fbbFo6K6clY8mLM5q233oKtra3RaU1NTZg7d66FI2J6Mpa8GLN5/fXX0dLSYlBuY2ODcePGoV+/fpYPiumxWPJizMbDwwPjx4+HjY3+ZmVjY4O33nrLSlExPRVLXoxZvfnmmwZlRIQ5c+ZYIRqmJ2PJizGrkJAQvfNetra2+PWvfw1XV1crRsX0RCx5MWbl5OSEV155RZfAiAgLFiywclRMT8SSF2N2CxYs0J24FwqFmD17tpUjYnoilrwYs5s5cybEYjEAYMaMGbC3t7dyRExPxJIXY3ZyuVy3t8UOGZkuQxyEhIQQAPZhH/ZhH7N/0tLSuKSjdM5PlRg3bhw++ugjrrMxFpKTk4OkpCSkpaVZNY7m5makpaXhjTfesGocppo3bx4iIiLg7+9v7VB+kebNm8d5Hs7Jy8vLC6+99hrnhhjLSUpK6hZ9FBQUBIlEYu0wTDJv3jz4+/t3i/X2S9SR5MXOeTFdhi+Ji+EnlrwYhuEllrwYhuEllrwYhuEllrwYhuEliyevJUuWQKFQQCAQIC8vz9LNm0VCQgIGDRoEqVQKuVyOQYMGYc2aNaipqelQPQA4c+YMxo8fD5lMBg8PD0RHR+PRo0eW+koGjh07BgcHB3z11VdWi4Evjh8/jpiYGBw6dAgqlQoCgQACgcDoEzYCAwOhUChga2uLoUOH4vz581aImJsvv/wSY8eOhUKhgI+PDxYtWoSysjLd9CNHjiAhIUHv7VEWwXWQakhICJdZjNq/fz8BoNzc3E4vyxqmT59OmzdvpvLycqqtraX09HQSCoX0yiuvdKjexYsXSSqV0po1a6iuro6+//576t27Ny1atIhzbGlpacSxW406evQoKZVKOnLkSKeXxQfgPkiSiIhiY2NpxowZVFNToytTq9XUq1cvAkBHjx41mCcrK4tmzZrVqXgtJTU1lQBQQkICVVdXU25uLqlUKho5ciRptVpdvaSkJJo0aRJVVVV1qJ0OrP90lrw6ICgoiDQajV7Z3LlzCQCVlpZyrjdv3jzy9fWllpYWXVliYiIJBAL697//zSk2cyWv7qS+vp78/f27tI2OJK9NmzbRgAEDDPpYrVbTF198QTY2NuTp6UnV1dV60/mUvCZPnkx9+vTR2zY//fRTAkBnzpzRqxseHk7+/v56Sc1UHUleVjnn9ayXNPBFRkaGwRgmT09PAEBdXR2nek1NTfj6668xadIkvfUydepUEBEOHz7cJd+BT3bv3o3y8nJrh6Hn2rVrWLNmDdatW2d0PFtAQAAiIiJw+/ZtrFixwgoRmkdxcTE8PDz0ts2+ffsCAG7evKlXd+3atcjLy0NSUpJFYuvy5EVESExMxMCBAyEWi+Hg4ICoqCiDes3NzYiNjYW3tzekUilGjBihu8Vl+/btkMvlkMlkOHz4MKZOnQqlUgkvLy/s379fbzmnTp3CCy+8AJlMBqVSieHDh+vOMbXVRmcVFhbC0dERPj4+nOpdv34ddcz74CwAACAASURBVHV18Pb21qunVqsBAPn5+WaJj4szZ87A29sbAoEAn376KQDT+yA5ORkSiQSurq5YunQpPDw8IJFIEBAQgLNnz+rqhYeHQyQSwd3dXVf23nvvQS6XQyAQoLKyEgAQERGByMhIFBUVQSAQwM/PDwDwzTffQKlUYsOGDZZYJQaSk5NBRJg5c+Yz68THx2PAgAHYtWsXjh8/3ubyiAhbtmzB4MGDIRaL4eTkhNmzZ+Py5cu6Olx+B+ba1lUqlcE/jtbzXSqVSq/cyckJkyZNQlJSEh7vTHUxLvtpHTlsXLVqFQkEAvrzn/9MVVVVVF9fTykpKQaHjStWrCCxWEwHDx6kqqoqWrlyJdnY2NC5c+d0ywFAJ06coAcPHlB5eTlNnDiR5HI5NTY2EhFRXV0dKZVKSkhIII1GQ2VlZTRnzhyqqKgwqQ2uGhsbqaSkhLZt20ZisZj27t3Lud6pU6cIACUmJhrMJ5VKacqUKZxiMtdhY3FxMQGgbdu26cpM6QMiorCwMJLL5XTp0iVqaGiggoICGjt2LCkUCrp165au3vz588nNzU2v3cTERAKg6zMiouDgYFKr1Xr1jh49SgqFguLi4jr9XYm4H7aoVCoaMmSI0WlqtZp+/vlnIiL6/vvvycbGhvr160d1dXVEZPywMTY2lkQiEe3du5eqq6spPz+fRo8eTb1796aysjJdPVP7wFzbenZ2NgmFQkpOTqaamhq6ePEiDR48mF599VWj9WNiYjp0Sojr+qeuPudVX19PMpnM4AT10+e8NBoNyWQyCg0N1ZtXLBbTu+++S0T/6bQnzy+0JsFr164R0eMT33jGSVJT2uDKzc2NAFCvXr3oL3/5i97GY2q97777jgDQli1bDOZTKpUUEBDAKSZLJK+2+oDocfJycHDQW965c+cIAK1bt05X1pnkZW5cfjx1dXUkEAhoxowZRqc/mbyIiCIjIwkAvf/++0RkmLzq6+vJ3t5eb9skIvrxxx8JgF6CNqUPzL2tr169Wu/pD15eXlRcXGy07meffUYA6PPPP+fURkeSV5ceNl67dg319fWYMmVKm/WuXLmC+vp6DBs2TFcmlUrh7u6ut9v8NJFIBADQarUAHu/Gurq6YsGCBVi7di1u3LjR6TbaUlxcjPLycnz55Zf4+9//jlGjRhk9N9NWvdbzJcbeNt3Y2AipVNqh2Czl6T54ljFjxkAmk3V4XXcn5eXlICLIZDKT6sfHx2PgwIFISUnBmTNnDKYXFBSgrq4OY8aM0SsfO3YsRCKR3uG2MU/3gTm39VWrVmHHjh04ceIE6urqcP36dQQEBMDf3x/FxcUG9VvXyd27dzm10xFdmrxKSkoAAC4uLm3We/jwIQBg9erVujEyAoEAN2/eRH19vcntSaVSnDx5EhMmTMCGDRugUqkQGhoKjUZjtjaeJBQK4eLigsDAQKSmpqKgoAAbN27kVK/1nM/TY7/q6+vR0NAADw+PDsXWHYnFYlRUVFg7jE5raGgAAN3TYtsjkUiwZ88eCAQCLF68GBqNRm96dXU1ABh94qyjoyNqa2s5xWeubf3OnTtISEjA73//e7z88suQy+Xw9fXFzp07UVpaisTERIN5Wv/Ztq6jrtSlyat1r6K9wZatyW3r1q0gIr1PTk4OpzaHDh2Kr776CqWlpYiOjkZaWho2b95s1jaM8fPzg62tLQoKCjjV8/X1hUKhMLhyc+3aNQDAiBEjOh1bd6DValFdXQ0vLy9rh9JprT9QLoMy/f39sXz5chQWFmL9+vV60xwdHQHAaJLqyDoz17ZeWFiI5uZm9OnTR69cqVTC2dnZ6Lbe2NgIABY5YujS5DVs2DDY2Njg1KlTbdbr27cvJBJJp0fcl5aW4tKlSwAed+CmTZswevRoXLp0yWxt3Lt3z+gD9lo7uvUysqn17OzsMG3aNJw+fVrvbdNZWVkQCARtXs3ik+zsbBARxo0bpyuzs7Nr93CzO3J1dYVAIMCDBw84zbd+/XoMGjQIubm5euXDhg2Dvb09fvrpJ73ys2fPorGxEc8//zyndsy1rbcmzTt37uiV19bW4v79+7pt+Emt68TNza1TbZuiS5OXi4sLgoODcfDgQezevRs1NTXIz8/Hjh079OpJJBIsWrQI+/fvx/bt21FTU4Pm5maUlJQYrLi2lJaWYunSpbh8+TIaGxuRm5uLmzdvYty4cWZrQy6X47vvvsPJkydRU1MDrVaL3NxcvP3225DL5Vi+fDmnegCwZs0a3L17Fx9//DEePnyInJwcJCYmYuHChRg4cKDJsXUnLS0tqKqqQlNTE/Lz8xEREQFvb28sXLhQV8fPzw/3799HZmYmtFotKioqDPZAAcDZ2RmlpaW4ceMGamtrodVqkZWVZbWhEjKZDCqVSndaxFSth49PvteytTwyMhIZGRnYt28fampqcOHCBSxbtgweHh4ICwvj3E5723poaCjc3NzavD3J19cXkydPxs6dO3H69GloNBoUFxfr4vnd735nME/rOhk+fDinmDuEy+n9jgyVqK2tpSVLllCvXr3I3t6eJkyYQLGxsbqrFv/617+IiOjRo0cUHR1N3t7eZGdnRy4uLhQcHEwFBQWUkpJCMpmMAFD//v2pqKiIduzYQUqlkgCQj48PXb16lW7cuEEBAQHk5OREtra21KdPH1q1ahU1NTW12wYXM2fOJF9fX7K3tyexWExqtZpCQ0PpwoULHapH9HjIxAsvvEBisZg8PDwoKiqKGhoaOMVFZJ6rjdu2bSN3d3cCQDKZjGbOnGlyHxA9vtooFArJ09OT7OzsSKlU0uzZs6moqEivnXv37tHkyZNJIpGQr68vffDBBxQVFUUAyM/PTzes4vz58+Tj40NSqZQmTJhAZWVldOzYMVIoFBQfH9+p79oKHK92hYeHk1AopPr6el1ZRkYGqdVqAkC9e/fWXV18WlRUlMFQiZaWFkpMTKT+/fuTUCgkJycnCgoKoitXrujqcOmD9rb1oKAgAkCxsbFtfs/KykqKiIggPz8/EovFZG9vT+PHj6d//OMfRutPnz6dPD099Ubkm4Lr+idr3R7EdJ3ucHtQWFgYOTs7WzUGrrj+eAoLC8nOzu6ZY/u6u+bmZpo4cSLt3r3bbMusrKwkiURCmzdv5jxvR5IXeyQO0yUs/oQBC/Pz80NcXBzi4uL0bgnjg+bmZmRmZqK2thahoaFmW+7atWsxcuRIhIeHm22ZbWHJC8Dly5f1Lik/62POjmb4LyYmBnPnzkVoaCjnk/fWlJ2djUOHDiErK8vksWrt2bJlC/Ly8nDs2DEIhUKzLLM9LHkBGDRokMElZWOf1NRUa4fa7a1cuRJ79uzBgwcP4Ovri4MHD1o7pC61YcMGhIeHY9OmTdYOxWRTpkzBF198oXdfaWccPnwYjx49QnZ2NpycnMyyTFNwfvUZw7Rl48aNRgfq9mSBgYEIDAy0dhhWM2vWLMyaNcvi7bI9L4ZheIklL4ZheIklL4ZheIklL4ZheInzCfuSkhKkp6d3RSyMGbTeeMv6iDtz3KDPWBCXIa0hISF6DyVjH/ZhH/Yx14frCHvOe14hISE4cOAA19kYC0lPT8e8efMs8wzxHkQgECAtLQ2vvfaatUP5RerIS3nYOS+GYXiJJS+GYXiJJS+GYXiJJS+GYXiJJS+GYXiJJS+GYXiJF8nr0KFDUKlUBs/XEolEcHV1xUsvvYTExERUVVVZO1TmF+j48eOIiYkx2E7ffPNNg7qBgYFQKBSwtbXF0KFD23yGfHcQHx9v9Nl2T74T8siRI0hISLD4Ayh5kbyCg4Nx/fp1qNVqODg4gIjQ0tKC8vJypKenw9fXF9HR0Rg6dKjBG1gYpit9/PHHSE5OxsqVK/W20169emHfvn34+uuv9ep/9913OHDgAGbMmIGCggKMHj3aSpGbz8yZMyGRSDBlyhTdOygtgRfJyxiBQABHR0e89NJL2LNnD9LT03H37l1Mnz6dV0+17Ik0Gg0CAgJ430Z7PvnkE6SmpiI9PR0KhUJvWnJyMmxsbBAWFsb77XHv3r0GD+a8ePGiXp0PP/wQzz33HKZNm2b07e9dgbfJ62khISFYuHAhysvL8de//tXa4fyi7d69G+Xl5bxvoy3Xrl3DmjVrsG7dOt3LlZ8UEBCAiIgI3L59GytWrLBChJa3du1a5OXlISkpySLt9ZjkBUD3TsCsrCxdWXNzM2JjY+Ht7Q2pVIoRI0YgLS0NALB9+3bI5XLIZDIcPnwYU6dOhVKphJeXF/bv36+37FOnTuGFF16ATCaDUqnE8OHDUVNT024bfEBE2LJlCwYPHgyxWAwnJyfMnj0bly9f1tUJDw+HSCTSe3Twe++9B7lcDoFAgMrKSgBAREQEIiMjUVRUBIFAAD8/PyQnJ0MikcDV1RVLly6Fh4cHJBIJAgICcPbsWbO0AQDffPONxd7lmJycDCJq86XA8fHxGDBgAHbt2oXjx4+3uTxT+oDL9mqNbdLJyQmTJk1CUlKSZW5P43pjtjVffaZWq8nBweGZ02tqaggA9e3bV1e2YsUKEovFdPDgQaqqqqKVK1eSjY0NnTt3joiIVq1aRQDoxIkT9ODBAyovL6eJEyeSXC6nxsZGIiKqq6sjpVJJCQkJpNFoqKysjObMmUMVFRUmtWFJHXn1WWxsLIlEItq7dy9VV1dTfn4+jR49mnr37k1lZWW6evPnzyc3Nze9eRMTEwmAbl0QEQUHB5NardarFxYWRnK5nC5dukQNDQ1UUFBAY8eOJYVCoXs/Y2fbOHr0KCkUCoqLi+P0/Ym4v3pLpVLRkCFDjE5Tq9X0888/ExHR999/TzY2NtSvXz+qq6sjIqKsrCyD9zaa2gembK9E5tsm169fT15eXuTo6EhCoZD69etHs2bNoh9//NFo/ZiYGAJAubm5nNrhuv6Jb+9tbC95EREJBAJydHQkIiKNRkMymYxCQ0N10+vr60ksFtO7775LRP/ZGDQaja5OSkoKAaBr164REdHFixcJAB09etSgPVPasCSuyau+vp7s7e314ici+vHHHwmAXiLobPJ6uu/OnTtHAGjdunVmaaMzuPx46urqSCAQ0IwZM4xOfzJ5ERFFRkYSAN1LaJ9OXlz6wJTt1Zzb5K1bt+j8+fNUW1tLjx49opycHBo1ahRJpVK6ePGiQf3PPvuMANDnn3/OqZ2OJK8eddj48OFDEBGUSiUA4MqVK6ivr9e7rCuVSuHu7q63O/40kUgEANBqtQAAlUoFV1dXLFiwAGvXrsWNGzd0dTvaRndRUFCAuro6jBkzRq987NixEIlEeod15jZmzBjIZDJerKcnlZeXg4hMfm1YfHw8Bg4ciJSUFJw5c8Zgemf74Ont1ZzbZN++fTFq1CjY29tDJBJh3Lhx2LNnDzQaDVJSUgzqt66Tu3fvcmqnI3pU8rp69SqAx68yAx4nMwBYvXq13hiVmzdvor6+3uTlSqVSnDx5EhMmTMCGDRugUqkQGhoKjUZjtjaspfXStr29vcE0R0dH1NbWdmn7YrEYFRUVXdqGuTU0NAB4HLspJBIJ9uzZA4FAgMWLF0Oj0ehNN3cfdPU2OXz4cNja2up+b0+SSqUA/rOOulKPSl7ffPMNAGDq1KkAABcXFwDA1q1bDS71cn1q5tChQ/HVV1+htLQU0dHRSEtLw+bNm83ahjU4OjoCgNEfSHV1Nby8vLqsba1W2+VtdIXWHyiXQZn+/v5Yvnw5CgsLsX79er1p5u6Drt4mW1pa0NLSYjR5NzY2AvjPOupKPSZ5lZWVYevWrfDy8sLixYsBPN7llUgkyMvL69SyS0tLcenSJQCPN4xNmzZh9OjRuHTpktnasJZhw4bB3t7eYHDv2bNn0djYiOeff15XZmdnpzs0MYfs7GwQEcaNG9dlbXQFV1dXCAQCzuO31q9fj0GDBiE3N1evnEsfmMKc2+Srr75qUHbu3DkQEfz9/Q2mta4TNze3TrfdHt4lLyJCXV0dWlpaQESoqKhAWloaxo8fD1tbW2RmZurOeUkkEixatAj79+/H9u3bUVNTg+bmZpSUlODOnTsmt1laWoqlS5fi8uXLaGxsRG5uLm7evIlx48aZrQ1rkUgkiIyMREZGBvbt24eamhpcuHABy5Ytg4eHB8LCwnR1/fz8cP/+fWRmZkKr1aKiogI3b940WKazszNKS0tx48YN1NbW6pJRS0sLqqqq0NTUhPz8fERERMDb21s3xKWzbWRlZVlkqIRMJoNKpUJJSQmn+VoPH21tbQ3KTe0DU9tpb5sMDQ2Fm5tbu7cn3b59G6mpqaiuroZWq0VOTg6WLFkCb29vLFu2zKB+6zoZPnw4p5g7hMvpfWtdbTxy5AiNGDGCZDIZiUQisrGxIQC6K4svvPACxcXF0b179wzmffToEUVHR5O3tzfZ2dmRi4sLBQcHU0FBAaWkpJBMJiMA1L9/fyoqKqIdO3aQUqkkAOTj40NXr16lGzduUEBAADk5OZGtrS316dOHVq1aRU1NTe22YWkdGSrR0tJCiYmJ1L9/fxIKheTk5ERBQUF05coVvXr37t2jyZMnk0QiIV9fX/rggw8oKiqKAJCfn59uyMP58+fJx8eHpFIpTZgwgcrKyigsLIyEQiF5enqSnZ0dKZVKmj17NhUVFZmtjWPHjpFCoaD4+HjO6w0cr3aFh4eTUCik+vp6XVlGRgap1WoCQL1799ZdXXxaVFSUwVAJU/rA1O2VqP1tMigoiABQbGxsm98zMjKS1Go1yeVysrOzIy8vL3rnnXeotLTUaP3p06eTp6cntbS0tL8Sn8B1/RPfhkow7etI8rKEsLAwcnZ2tnYYz8T1x1NYWEh2dna0d+/eLoyq6zQ3N9PEiRNp9+7dZltmZWUlSSQS2rx5M+d5O5K8eHfYyPCXpZ860JX8/PwQFxeHuLg41NXVWTscTpqbm5GZmYna2lqEhoaabblr167FyJEjER4ebrZltoUlL4bpoJiYGMydOxehoaG8uvk6Ozsbhw4dQlZWlslj1dqzZcsW5OXl4dixYxAKhWZZZntY8mK63MqVK7Fnzx48ePAAvr6+OHjwoLVDMpsNGzYgPDwcmzZtsnYoJpsyZQq++OILvXtIO+Pw4cN49OgRsrOz4eTkZJZlmoLzexsZhquNGzdi48aN1g6jywQGBiIwMNDaYVjNrFmzMGvWLIu3y/a8GIbhJZa8GIbhJZa8GIbhJZa8GIbhJc4n7H/44QfMnTu3K2JhzKD19gzWR9xt3boVBw4csHYYjIk4JS9jN2Iy3YuXlxdCQkKsHQbKysqQm5ure8JHd9cd1tkvWUhICPr27ctpHsH/D81nGLNKT0/HvHnzLPMsc+aX6AA758UwDC+x5MUwDC+x5MUwDC+x5MUwDC+x5MUwDC+x5MUwDC+x5MUwDC+x5MUwDC+x5MUwDC+x5MUwDC+x5MUwDC+x5MUwDC+x5MUwDC+x5MUwDC+x5MUwDC+x5MUwDC+x5MUwDC+x5MUwDC+x5MUwDC+x5MUwDC+x5MUwDC+x5MUwDC+x5MUwDC+x5MUwDC+x5MUwDC+x5MUwDC+x5MUwDC+x5MUwDC+x5MUwDC+x5MUwDC+x5MUwDC+x5MUwDC/ZWTsAhv+0Wi3q6ur0yh4+fAgAqKqq0isXCARwdHS0WGxMz8WSF9Np9+/fh6enJ5qbmw2mOTs76/09efJknDx50lKhMT0YO2xkOs3NzQ0vvvgibGza3pwEAgFef/11C0XF9HQseTFm8eabb7Zbx9bWFnPmzLFANMwvAUtejFkEBwfDzu7ZZyFsbW3xm9/8Br169bJgVExPxpIXYxZKpRJTp059ZgIjIixYsMDCUTE9GUtejNksWLDA6El7ABCJRPjtb39r4YiYnowlL8Zsfvvb30ImkxmUC4VCBAUFQS6XWyEqpqdiyYsxG4lEgjlz5kAoFOqVa7VazJ8/30pRMT0VS16MWb3xxhvQarV6ZUqlEq+88oqVImJ6Kpa8GLP69a9/rTcwVSgU4vXXX4dIJLJiVExPxJIXY1Z2dnZ4/fXXdYeOWq0Wb7zxhpWjYnoilrwYs3v99dd1h45ubm6YMGGClSNieiKWvBizCwgIgKenJwDgrbfeave2IYbpCE43Zufk5KC4uLirYmF6kLFjx+L27dvo1asX0tPTrR0OwwMBAQHw8vIyfQbiICQkhACwD/uwD/uY/ZOWlsYlHaVz3p8PCQkBEbFPN/2kpaUBgNXjICIcOHDA6jGY+gGAtLQ0q8fxS/10BDsZwXSZkJAQa4fA9GAseTEMw0sseTEMw0sseTEMw0sseTEMw0sseTEMw0sWT15LliyBQqGAQCBAXl6epZs3i4SEBAwaNAhSqRRyuRyDBg3CmjVrUFNT06F6rVpaWrB161YEBARY4mu06dixY3BwcMBXX31l7VC6vePHjyMmJgaHDh2CSqWCQCCAQCAw+lz/wMBAKBQK2NraYujQoTh//rwVIjZdfHy87vs8+Rk2bJiuzpEjR5CQkPDMB1F2FYsnr127dmHnzp2Wbtas/vnPf+Kdd97BrVu3cPfuXaxfvx4JCQkGQwNMrQcAhYWFePHFF7F8+XLU19db6qs8U0fH3vzSfPzxx0hOTsbKlSsRHByM69evQ61Wo1evXti3bx++/vprvfrfffcdDhw4gBkzZqCgoACjR4+2UuTmM3PmTEgkEkyZMgXV1dUWa5cdNnaASCTCe++9BxcXF9jb22Pu3LmYPXs2/vu//xt37tzhXO9f//oX/vjHP2LZsmUYOXKkNb6SgenTp+PBgweYMWOGtUOBRqPpFnujT/vkk0+QmpqK9PR0KBQKvWnJycmwsbFBWFgYHjx4YKUIzWPv3r0Gg0ovXryoV+fDDz/Ec889h2nTpqGpqckicVkleQkEAms0azYZGRmQSCR6Za03Ij/55mhT6z333HM4dOgQ5s+fD7FY3FVh89bu3btRXl5u7TD0XLt2DWvWrMG6desM+hh4fJ9eREQEbt++jRUrVlghQstbu3Yt8vLykJSUZJH2ujx5ERESExMxcOBAiMViODg4ICoqyqBec3MzYmNj4e3tDalUihEjRuhuddm+fTvkcjlkMhkOHz6MqVOnQqlUwsvLC/v379dbzqlTp/DCCy9AJpNBqVRi+PDhunNMbbXRWYWFhXB0dISPj49Z6lnTmTNn4O3tDYFAgE8//RSA6X2QnJwMiUQCV1dXLF26FB4eHpBIJAgICMDZs2d19cLDwyESieDu7q4re++99yCXyyEQCFBZWQkAiIiIQGRkJIqKiiAQCODn5wcA+Oabb6BUKrFhwwZLrBIDycnJICLMnDnzmXXi4+MxYMAA7Nq1C8ePH29zeUSELVu2YPDgwRCLxXBycsLs2bNx+fJlXR0uv4Ou3NafxcnJCZMmTUJSUpJlTjsQByEhIRQSEsJlFlq1ahUJBAL685//TFVVVVRfX08pKSkEgHJzc3X1VqxYQWKxmA4ePEhVVVW0cuVKsrGxoXPnzumWA4BOnDhBDx48oPLycpo4cSLJ5XJqbGwkIqK6ujpSKpWUkJBAGo2GysrKaM6cOVRRUWFSG1w1NjZSSUkJbdu2jcRiMe3du7dT9YiIfvWrX9Fzzz3XoXiIiNLS0ohjtxpVXFxMAGjbtm26MlP6gIgoLCyM5HI5Xbp0iRoaGqigoIDGjh1LCoWCbt26pas3f/58cnNz02s3MTGRAOj6jIgoODiY1Gq1Xr2jR4+SQqGguLi4Tn9XIuJ8Y7BKpaIhQ4YYnaZWq+nnn38mIqLvv/+ebGxsqF+/flRXV0dERFlZWTRr1iy9eWJjY0kkEtHevXupurqa8vPzafTo0dS7d28qKyvT1TO1D8y1ra9fv568vLzI0dGRhEIh9evXj2bNmkU//vij0foxMTEGv21TcF3/RJTepcmrvr6eZDIZvfLKK3rl+/fv1/uCGo2GZDIZhYaG6s0rFovp3XffJaL/dJpGo9HVaU2C165dIyKiixcvEgA6evSoQSymtMGVm5sbAaBevXrRX/7yF72NpyP1iPiRvNrqA6LHycvBwUFveefOnSMAtG7dOl1ZZ5KXuXH58dTV1ZFAIKAZM2YYnf5k8iIiioyMJAD0/vvvE5Fh8qqvryd7e3u9bZOI6McffyQAegnalD4w57Z+69YtOn/+PNXW1tKjR48oJyeHRo0aRVKplC5evGhQ/7PPPiMA9Pnnn3NqpyPJq0sPG69du4b6+npMmTKlzXpXrlxBfX293uVXqVQKd3d3vd3mp7U+F731qZ0qlQqurq5YsGAB1q5dixs3bnS6jbYUFxejvLwcX375Jf7+979j1KhRRs/NmFqPj57ug2cZM2YMZDJZh9d1d1JeXg4iMvqaN2Pi4+MxcOBApKSk4MyZMwbTCwoKUFdXhzFjxuiVjx07FiKRSO9w25in+8Cc23rfvn0xatQo2NvbQyQSYdy4cdizZw80Gg1SUlIM6reuk7t373JqpyO6NHmVlJQAAFxcXNqs9/DhQwDA6tWr9caS3Lx5k9OwAalUipMnT2LChAnYsGEDVCoVQkNDodFozNbGk4RCIVxcXBAYGIjU1FQUFBRg48aNHa7X04nFYlRUVFg7jE5raGgAAJMvrkgkEuzZswcCgQCLFy+GRqPRm946vMDe3t5gXkdHR9TW1nKKryu29ScNHz4ctra2uHr1qsE0qVQK4D/rqCt1afJqvQrz6NGjNuu1JretW7caXJLNycnh1ObQoUPx1VdfobS0FNHR0UhLS8PmzZvN2oYxfn5+sLW1RUFBgVnq9TRarRbV1dXcnpTZTbX+QLkMyvT398fy5ctRWFiI9evX601zdHQEAKNJqiPrrKu39ZaWFrS0tBhN3o2NjQD+s466Upcmr2HDhsHGxganTp1qs17fvn0hkUg6PeK+tLQUly5dAvC4Azdt2oTRo0fj0qVLZmvj3r17Rt+G7JZwJQAAIABJREFUU1hYiObmZvTt25dTvV+K7OxsEBHGjRunK7Ozs2v3cLM7cnV1hUAg4Dx+a/369Rg0aBByc3P1yocNGwZ7e3v89NNPeuVnz55FY2Mjnn/+eU7tmGtbB4BXX33VoOzcuXMgIvj7+xtMa10nbm5unW67PV2avFxcXBAcHIyDBw9i9+7dqKmpQX5+Pnbs2KFXTyKRYNGiRdi/fz+2b9+OmpoaNDc3o6SkRG8wZ3tKS0uxdOlSXL58GY2NjcjNzcXNmzcxbtw4s7Uhl8vx3Xff4eTJk6ipqYFWq0Vubi7efvttyOVyLF++nFO9nqqlpQVVVVVoampCfn4+IiIi4O3tjYULF+rq+Pn54f79+8jMzIRWq0VFRQVu3rxpsCxnZ2eUlpbixo0bqK2thVarRVZWltWGSshkMqhUKt1pEVO1Hj7a2toalEdGRiIjIwP79u1DTU0NLly4gGXLlsHDwwNhYWGc22lvWw8NDYWbm1u7tyfdvn0bqampqK6uhlarRU5ODpYsWQJvb28sW7bMoH7rOhk+fDinmDuEy+n9jgyVqK2tpSVLllCvXr3I3t6eJkyYQLGxsQSAvLy86F//+hcRET169Iiio6PJ29ub7OzsyMXFhYKDg6mgoIBSUlJIJpMRAOrfvz8VFRXRjh07SKlUEgDy8fGhq1ev0o0bNyggIICcnJzI1taW+vTpQ6tWraKmpqZ22+Bi5syZ5OvrS/b29iQWi0mtVlNoaChduHChQ/VycnJo/Pjx5OHhoXuet7u7OwUEBNCpU6c4xWaOq43btm0jd3d3AkAymYxmzpxpch8QPb7aKBQKydPTk+zs7EipVNLs2bOpqKhIr5179+7R5MmTSSKRkK+vL33wwQcUFRVFAMjPz083rOL8+fPk4+NDUqmUJkyYQGVlZXTs2DFSKBQUHx/fqe/aChyvdoWHh5NQKKT6+npdWUZGBqnVagJAvXv31l1dfFpUVJTBUImWlhZKTEyk/v37k1AoJCcnJwoKCqIrV67o6nDpg/a29aCgIAJAsbGxbX7PyMhIUqvVJJfLyc7Ojry8vOidd96h0tJSo/WnT59Onp6e1NLS0v5KfALX9U9dPVSCsTxzDZXojLCwMHJ2drZqDFxx/fEUFhaSnZ1dm2P2urPm5maaOHEi7d6922zLrKysJIlEQps3b+Y8b0eSF7u3kekSln7CgKX5+fkhLi4OcXFxerd68UFzczMyMzNRW1uL0NBQsy137dq1GDlyJMLDw822zLaw5AXg8uXLRh/78fTHnB3N8F9MTAzmzp2L0NBQXt18nZ2djUOHDiErK8vksWrt2bJlC/Ly8nDs2DEIhUKzLLM9LHkBGDRokEmvZ0pNTbV2qN3eypUrsWfPHjx48AC+vr44ePCgtUPqUhs2bEB4eDg2bdpk7VBMNmXKFHzxxRd695V2xuHDh/Ho0SNkZ2fDycnJLMs0Bac3ZjNMezZu3PiLG4AbGBiIwMBAa4dhNbNmzcKsWbMs3i7b82IYhpdY8mIYhpdY8mIYhpdY8mIYhpc4n7D/4YcfMHfu3K6IhTGD1tszWB9xt3XrVhw4cMDaYTAmYnteDMPwEuc9r3HjxrH/Tt1Yeno65s2bx/qII4FAgI8++givvfaatUP5RerIS3nYnhfDMLzEkhfDMLzEkhfDMLzEkhfDMLzEkhfDMLzEi+R16NAhqFQqg0fUiEQiuLq64qWXXkJiYiKqqqqsHSrzC3T8+HHExMQYbKdvvvmmQd3AwEAoFArY2tpi6NCh7T6G2doSEhIwaNAgSKVSyOVyDBo0CGvWrNG9hR4Ajhw5goSEBMs/w43Lowut/SRVtVqte5lpS0sLVVVV0f/8z//QwoULSSAQkIeHR4ffft1TdIcnqfIRuD/Jk4gev+l6xowZVFNToytTq9XUq1evZ74A2dgbs7ur6dOn0+bNm6m8vJxqa2spPT2dhEKhwYukk5KSaNKkSVRVVdWhdjqw/vn7JFWBQABHR0e89NJL2LNnD9LT03H37l1Mnz6dVw+G64k0Gg0CAgJ430Z7PvnkE6SmpiI9PR0KhUJvWnJyMmxsbPB/7d19UFNX+gfwb4C8kwjKiwqCkPhS30vVAtWfdZ1l1jq+IFpStWt1OoPWllJfluILiwhaFxYpLkzHrWVbtQpFFl9WXNc6uOOUtXaESmFUZIWKFEEKhgiSAM/vD5fUGIRcSIiXns8Mf3jvueecnHPymHvvufdERETwejyKRCJs2LAB7u7ucHZ2xvLly7FkyRL861//Mlm45v3338fUqVPx2muvob29fUDqxtvg9bRly5bhrbfeQl1dHT755BN7V+dX7eDBgzZfEXwgyujJrVu3sGPHDuzcudO4PumTgoODERUVhbt372Lz5s12qKF15Obmmn0+Ly8vADB7/XVcXByKi4uRmpo6IHUbNMELgHFZrfz8fOO2jo4OxMbGwsfHB1KpFFOmTEFWVhYAICMjA3K5HDKZDCdOnMD8+fOhVCrh7e2No0ePmuR98eJFzJw5EzKZDEqlEpMnTzae9/dUBh8QEVJSUvDCCy9ALBbD1dUVS5YsMVkaPjIyEiKRyOTtmxs2bIBcLodAIMD9+/cBAFFRUdi0aRMqKiogEAigVquRlpYGiUQCDw8PrFu3DiNGjIBEIkFwcLDJUvb9KQMAzp49O2DLoaWlpYGIsGjRomemSUhIwNixY/Hpp5/i/PnzPeZnSR9wGa+2HJPl5eVwcXGBr6+vyXZXV1fMmTMHqampeHwmaGNcTjKfp2te3dFqtQSARo0aZdy2efNmEovFlJOTQ42NjbR161ZycHAwXhvbtm0bAaCvv/6aHjx4QHV1dTR79mySy+Wk1+uJiEin05FSqaS9e/dSa2sr1dbW0tKlS6m+vt6iMgZSX655xcbGkkgkokOHDlFTUxNdu3aNAgICyM3NjWpra43pVq5cSZ6enibHJiUlEQBjWxARhYWFkUqlMkkXERFBcrmcysrK6NGjR1RaWkozZswghUJhXOKsv2WcPn2aFAoFxcfHc/r8RNyvufj7+9OECRO63adSqej27dtERPTNN9+Qg4MDjR49mnQ6HRF1f83L0j6wZLwSWX9M6vV6qq6upv3795NYLH7mqkkxMTEEgIqKijjlz7X9iW9Ln/UWvIiIBAIBubi4EBFRa2sryWQy0mg0xv0tLS0kFovpnXfeIaJfBkNra6sxTXp6OgGgW7duERHRDz/88MyLr5aUMZC4Bq+WlhZydnY2qT8R0bfffksATAJBf4PX03135coVAkA7d+60Shn9weXLo9PpSCAQ0MKFC7vd/2TwInq89iEA4zqOTwcvLn1gyXi1xZj09PQkADRs2DD6+OOPTQLlkz777DMCQF988QWn/PsSvAbVaePDhw9BRFAqlQCAGzduoKWlBZMmTTKmkUqlGD58uMnP8aeJRCIAMC5F7+/vDw8PD6xatQpxcXGorKw0pu1rGc+L0tJS6HQ6TJ8+3WT7jBkzIBKJTE7rrG369OmQyWS8aKcn1dXVgYgsXnknISEB48aNQ3p6Oi5dumS2v7998PR4tcWYvHPnDurq6vDll1/i888/x4svvtjtNceuNrl3716fyuFiUAWvmzdvAni8GhDwOJgBwPbt203mh1VVVaGlpcXifKVSKS5cuIBZs2YhMTER/v7+0Gg0aG1ttVoZ9tLU1AQAcHZ2Ntvn4uKC5uZmm5YvFotRX19v0zKs7dGjRwAe190SEokEmZmZEAgEWLt2LVpbW032W7sPbDEmhUIh3N3dERISgmPHjqG0tLTbhVakUimAX9rIlgZV8Dp79iwAYP78+QAAd3d3AI9fMkdPLWNWWFjIKe+JEyfi1KlTqKmpQXR0NLKyspCcnGzVMuzBxcUFALr9gjQ1NcHb29tmZRsMBpuXYQtdX1AukzKDgoKwceNGlJeXY9euXSb7rN0Hth6TarUajo6OKC0tNdun1+sB/NJGtjRogldtbS327dsHb29vrF27FgAwatQoSCQSFBcX9yvvmpoalJWVAXg8MPbs2YOAgACUlZVZrQx7mTRpEpydnfHdd9+ZbL98+TL0ej1eeukl4zYnJyfjqYk1FBQUgIgQGBhoszJswcPDAwKBgPP8rV27dmH8+PEoKioy2c6lDyxhrTHZ0NCAFStWmG0vLy9HR0cHRo0aZbavq008PT37VbYleBe8iAg6nQ6dnZ0gItTX1yMrKwuvvPIKHB0dkZeXZ7zmJZFIsGbNGhw9ehQZGRnQarXo6OhAdXW1yQS73tTU1GDdunW4fv069Ho9ioqKUFVVhcDAQKuVYS8SiQSbNm1Cbm4uDh8+DK1Wi5KSEqxfvx4jRoxARESEMa1arcbPP/+MvLw8GAwG1NfXo6qqyizPoUOHoqamBpWVlWhubjYGo87OTjQ2NqK9vR3Xrl1DVFQUfHx8jFNc+ltGfn7+gEyVkMlk8Pf3N75y21Jdp4+Ojo5m2y3tA0vL6W1MajQaeHp69vh4klwux7lz53DhwgVotVoYDAYUFRVh9erVkMvl2Lhxo9kxXW0yefJkTnXuEy6X9+11t/HkyZM0ZcoUkslkJBKJyMHBgQAY7yzOnDmT4uPjqaGhwezYtrY2io6OJh8fH3JyciJ3d3cKCwuj0tJSSk9PJ5lMRgBozJgxVFFRQQcOHCClUkkAyNfXl27evEmVlZUUHBxMrq6u5OjoSCNHjqRt27ZRe3t7r2UMtL5Mlejs7KSkpCQaM2YMCYVCcnV1pdDQULpx44ZJuoaGBpo7dy5JJBLy8/Oj9957j7Zs2UIASK1WG6c8XL16lXx9fUkqldKsWbOotraWIiIiSCgUkpeXFzk5OZFSqaQlS5ZQRUWF1co4c+YMKRQKSkhI4Nxu4Hi3KzIykoRCIbW0tBi35ebmkkqlIgDk5uZmvLv4tC1btphNlbCkDywdr0S9j8nQ0FACQLGxsT1+zkWLFpGfnx85OzuTWCwmlUpFGo2GSkpKuk2/YMEC8vLyos7Ozt4b8Qlc25/4NlWC6d3z+mxjREQEDR061N7VeCauX57y8nJycnJ65nyn511HRwfNnj2bDh48aLU879+/TxKJhJKTkzkf25fgxbvTRoa/BvytAzakVqsRHx+P+Ph4s8dknncdHR3Iy8tDc3MzNBqN1fKNi4vDtGnTEBkZabU8e8KCF8P0UUxMDJYvXw6NRsOrh68LCgpw/Phx5OfnWzxXrTcpKSkoLi7GmTNnIBQKrZJnb1jwYmxu69atyMzMxIMHD+Dn54ecnBx7V8lqEhMTERkZiT179ti7KhabN28ejhw5YvIMaX+cOHECbW1tKCgogKurq1XytATnpc8Yhqvdu3d3O6FxsAgJCUFISIi9q2E3ixcvxuLFiwe8XPbLi2EYXmLBi2EYXmLBi2EYXmLBi2EYXmLBi2EYXuJ8tzEnJwcCgcAWdWGsiPURd+Hh4QgPD7d3NRgLCf43Nd8ihYWFuHPnji3rwwwShYWFSE1N5dW7/Bn7Cg4O5vL6n684BS+GsVR2djbCw8MHZiEG5tfoK3bNi2EYXmLBi2EYXmLBi2EYXmLBi2EYXmLBi2EYXmLBi2EYXmLBi2EYXmLBi2EYXmLBi2EYXmLBi2EYXmLBi2EYXmLBi2EYXmLBi2EYXmLBi2EYXmLBi2EYXmLBi2EYXmLBi2EYXmLBi2EYXmLBi2EYXmLBi2EYXmLBi2EYXmLBi2EYXmLBi2EYXmLBi2EYXmLBi2EYXmLBi2EYXmLBi2EYXmLBi2EYXmLBi2EYXmLBi2EYXmLBi2EYXmLBi2EYXnKydwUY/quvr8ff//53k23fffcdAODAgQMm2xUKBd54440BqxszeAmIiOxdCYbf2tra4OHhAZ1OB0dHRwBA17ASCATGdAaDAatXr8bf/vY3e1STGVy+YqeNTL+JxWIsW7YMTk5OMBgMMBgMaG9vR3t7u/HfBoMBALBixQo715YZLFjwYqxixYoV0Ov1PaZxcXHBb37zmwGqETPYseDFWMXcuXPh7u7+zP1CoRCrVq2CkxO7zMpYBwtejFU4ODhg5cqVEAqF3e43GAzsQj1jVSx4MVbzxhtvGK9tPW3kyJEICgoa4BoxgxkLXozVzJw5E76+vmbbRSIRVq9ebXLnkWH6iwUvxqrefPNNs1NHvV7PThkZq2PBi7GqlStXmp06qtVqTJ482U41YgYrFrwYqxo/fjwmTJhgPEUUCoVYs2aNnWvFDEYseDFW9/vf/9440769vZ2dMjI2wYIXY3VvvPEGOjo6AAABAQHw8/Ozc42YwYgFL8bqfHx88PLLLwMAVq9ebefaMIMVp+nOKSkpKCwstFVdmEGkra0NAoEA586dw7///W97V4fhgY0bN3KaC8jpl1dhYSH+85//cK4UM3Cqq6uRk5Nj72rA29sbnp6ekEgk9q6KRXJyclBdXW3vavxq5eTk4M6dO5yO4fygWWBgIL766iuuhzEDJDs7G+Hh4c9FH926dQtqtdre1bCIQCDABx98gNdff93eVflV6ssEZnbNi7EZvgQuhp9Y8GIYhpdY8GIYhpdY8GIYhpdY8GIYhpcGPHi9/fbbUCgUEAgEKC4uHujirWLv3r0YP348pFIp5HI5xo8fjx07dkCr1fYpXXx8PCZMmAClUgmxWAy1Wo0//OEP0Ol0A/mxTJw5cwZDhgzBqVOn7FYHvjh//jxiYmJw/Phx+Pv7QyAQQCAQ4M033zRLGxISAoVCAUdHR0ycOBFXr161Q40tZ8kYPnnyJPbu3Wt8qmLAEAfLli2jZcuWcTmkW0ePHiUAVFRU1O+87GHBggWUnJxMdXV11NzcTNnZ2SQUCum3v/1tn9LNmTOH0tPTqaGhgbRaLWVlZZFQKKTf/e53nOuWlZVFHLu1W6dPnyalUkknT57sd158AICysrI4HxcbG0sLFy4krVZr3KZSqWjYsGEEgE6fPm12TH5+Pi1evLhf9R0olo7h1NRUmjNnDjU2NvapnD60fzYLXn0QGhpKra2tJtuWL19OAKimpoZzugULFlB7e7tJutdff50A0I8//sipbtYKXs+TlpYWCgoKsmkZfQlee/bsobFjx5r1sUqloiNHjpCDgwN5eXlRU1OTyX4+BS9LxzARUWRkJAUFBZHBYOBcTl+Cl12uefH9jZq5ublmM8e9vLwAwORUz9J0p0+fNr6FoYubmxsAoKWlxXoV56mDBw+irq7O3tUwcevWLezYsQM7d+7s9imC4OBgREVF4e7du9i8ebMdamgdlo5hAIiLi0NxcTFSU1MHpG42D15EhKSkJIwbNw5isRhDhgzBli1bzNJ1dHQgNjYWPj4+kEqlmDJlCrKysgAAGRkZkMvlkMlkOHHiBObPnw+lUglvb28cPXrUJJ+LFy9i5syZkMlkUCqVmDx5svH8vKcy+qu8vBwuLi7dvga5L+nu3r0LqVRqlzcyXLp0CT4+PhAIBPjLX/4CwPI+SEtLg0QigYeHB9atW4cRI0ZAIpEgODgYly9fNqaLjIyESCTC8OHDjds2bNgAuVwOgUCA+/fvAwCioqKwadMmVFRUQCAQGCe+nj17FkqlEomJiQPRJGbS0tJARFi0aNEz0yQkJGDs2LH49NNPcf78+R7zIyKkpKTghRdegFgshqurK5YsWYLr168b03D5HthjrLu6umLOnDlITU01LjpsU1x+p/XltHHbtm0kEAjoz3/+MzU2NlJLSwulp6ebnTZu3ryZxGIx5eTkUGNjI23dupUcHBzoypUrxnwA0Ndff00PHjyguro6mj17NsnlctLr9UREpNPpSKlU0t69e6m1tZVqa2tp6dKlVF9fb1EZXOn1eqqurqb9+/eTWCymQ4cO9Stdl4cPH5JCoaDIyEjOdbLWaeOdO3cIAO3fv9+4zZI+ICKKiIgguVxOZWVl9OjRIyotLaUZM2aQQqEwOQ1euXIleXp6mpSblJREAIx9RkQUFhZGKpXKJN3p06dJoVBQfHx8vz8rEffTFn9/f5owYUK3+1QqFd2+fZuIiL755htycHCg0aNHk06nI6LuTxtjY2NJJBLRoUOHqKmpia5du0YBAQHk5uZGtbW1xnSW9oG9xnpMTEyfLglxbX+y9TWvlpYWkslkZhf3nr7m1draSjKZjDQajcmxYrGY3nnnHSL6pdOePP/uCoK3bt0iIqIffvjhmRdJLSmDK09PTwJAw4YNo48//thk8PQlXZdt27bR2LFjTS4CW2oggldPfUD0OHgNGTLEJL8rV64QANq5c6dxW3+Cl7Vx+fLodDoSCAS0cOHCbvc/GbyIiDZt2kQA6N133yUi8+DV0tJCzs7OJmOTiOjbb78lACYB2pI+sOdY/+yzzwgAffHFF5zy70vwsulp461bt9DS0oJ58+b1mO7GjRtoaWnBpEmTjNukUimGDx9u8rP5aSKRCACM70z39/eHh4cHVq1ahbi4OFRWVva7jJ7cuXMHdXV1+PLLL/H555/jxRdf7PbajKXpgMfXGLKzs/HPf/4TCoWiT/UaSE/3wbNMnz4dMpmsz239PKmrqwMRQSaTWZQ+ISEB48aNQ3p6Oi5dumS2v7S0FDqdDtOnTzfZPmPGDIhEIpPT7e483Qf2HOtdbXLv3r0+lcOFTYNX1ytGelpJGQAePnwIANi+fbtxjoxAIEBVVRWnC9ZSqRQXLlzArFmzkJiYCH9/f2g0GrS2tlqtjCcJhUK4u7sjJCQEx44dQ2lpKXbv3t3ndMeOHcNHH32EgoICjB49uk91ep6JxWLU19fbuxr99ujRIwCPP48lJBIJMjMzIRAIsHbtWrS2tprsb2pqAgA4OzubHevi4oLm5mZO9bPnWJdKpQB+aSNbsmnw6rpL0dbW1mO6ruC2b98+EJHJH9eXH06cOBGnTp1CTU0NoqOjkZWVheTkZKuW0R21Wg1HR0eUlpb2Kd3+/ftx+PBhXLhwASNHjux3fZ43BoMBTU1N8Pb2tndV+q3rC8plUmZQUBA2btyI8vJy7Nq1y2Sfi4sLAHQbpPrSZvYc63q9HsAvbWRLNg1ekyZNgoODAy5evNhjulGjRkEikfR7xn1NTQ3KysoAPO7APXv2ICAgAGVlZVYro6GhAStWrDDbXl5ejo6ODowaNYpTOiJCdHQ0SkpKkJeX1+3/voNBQUEBiAiBgYHGbU5OTr2ebj6PPDw8IBAI8ODBA07H7dq1C+PHj0dRUZHJ9kmTJsHZ2RnfffedyfbLly9Dr9fjpZde4lTOQI/1J3W1iaenZ7/KtoRNg5e7uzvCwsKQk5ODgwcPQqvV4tq1azhw4IBJOolEgjVr1uDo0aPIyMiAVqtFR0cHqqur8dNPP1lcXk1NDdatW4fr169Dr9ejqKgIVVVVCAwMtFoZcrkc586dw4ULF6DVamEwGFBUVITVq1dDLpdj48aNnNKVlZXhT3/6E/76179CKBSa/MwXCARITk62uG7Pk87OTjQ2NqK9vR3Xrl1DVFQUfHx88NZbbxnTqNVq/Pzzz8jLy4PBYEB9fT2qqqrM8ho6dChqampQWVmJ5uZmGAwG5Ofn222qhEwmg7+/P+c3r3adPj49p08ikWDTpk3Izc3F4cOHodVqUVJSgvXr12PEiBGIiIjgXE5vY12j0cDT07PHx5MsHcNP6mqTAVmnk8vl/b5MlWhubqa3336bhg0bRs7OzjRr1iyKjY0lAOTt7U3ff/89ERG1tbVRdHQ0+fj4kJOTE7m7u1NYWBiVlpZSeno6yWQyAkBjxoyhiooKOnDgACmVSgJAvr6+dPPmTaqsrKTg4GBydXUlR0dHGjlyJG3bts04e72nMrhYtGgR+fn5kbOzM4nFYlKpVKTRaKikpIRzupKSEgLwzL+kpCROdbPG3cb9+/fT8OHDCQDJZDJatGiRxX1A9Phuo1AoJC8vL3JyciKlUklLliyhiooKk3IaGhpo7ty5JJFIyM/Pj9577z3asmULASC1Wm2cVnH16lXy9fUlqVRKs2bNotraWjpz5gwpFApKSEjo12ftAo53uyIjI0koFFJLS4txW25uLqlUKgJAbm5uxruLT9uyZYvZVInOzk5KSkqiMWPGkFAoJFdXVwoNDaUbN24Y03Dpg97GemhoKAGg2NjYHj+npWO9y4IFC8jLy4s6Ozt7b8QncG1/stfjQYztPA+PB0VERNDQoUPtWgeuuH55ysvLycnJqdc5e8+rjo4Omj17Nh08eNBqed6/f58kEgklJydzPrYvwYu9EoexiQF/w8AAU6vViI+PR3x8vF3f/tEXHR0dyMvLQ3NzMzQajdXyjYuLw7Rp0xAZGWm1PHvCgheA69evm11r6u7Pmh3N8F9MTAyWL18OjUbD+eK9PRUUFOD48ePIz8+3eK5ab1JSUlBcXIwzZ85AKBRaJc/esOAFYPz48Wa3lLv7O3bsmL2r+tzbunUrMjMz8eDBA/j5+T0Xy7DZUmJiIiIjI7Fnzx57V8Vi8+bNw5EjR0yeK+2PEydOoK2tDQUFBXB1dbVKnpbgvPQZw/Rk9+7d3U5eHMxCQkIQEhJi72rYzeLFi7F48eIBL5f98mIYhpdY8GIYhpdY8GIYhpdY8GIYhpdY8GIYhpc4323Mycnh/Tvofw1YH3EXHh6O8PBwe1eDsRDn4BUYGIgPPvjAFnVhrKCwsBCpqalWe1/5r0V4eDiioqIQFBRk76r8KvXlPw3Owcvb2xuvv/4654KYgZOamsr6iKPw8HAEBQWxdrOTvgQvds2LYRheYsGLYRheYsGLYRheYsGLYRheYsGLYRhe4kXwOn78OPz9/c3eryUSieDh4YFXX30VSUlJaGxstHdVmV+h8+fPIyYmxmycvvnmm2ZpQ0JCoFAo4OjoiIkTJ/b4DvnnSWdnJ/bt24fg4GCzfSdPnsTevXsH/AWUvAheYWFh+O9//wuVSoUhQ4aAiNDZ2Ym6ujpkZ2fDz88P0dHRmDhxotkKLAxjS39Mn4e1AAAJ6klEQVT84x+RlpaGrVu3mozTYcOG4fDhw/jHP/5hkv7cuXP46quvsHDhQpSWliIgIMBONbdceXk5/u///g8bN27sdt3HRYsWQSKRYN68ecY1KAcCL4JXdwQCAVxcXPDqq68iMzMT2dnZuHfvHhYsWMCrt1oORq2trd3+D823Mnrz0Ucf4dixY8jOzjZb3TwtLQ0ODg6IiIjg9Xj8/vvv8eGHH2L9+vWYNm3aM9O9//77mDp1Kl577TW0t7cPSN14G7yetmzZMrz11luoq6vDJ598Yu/q/KodPHiw26Xg+VZGT27duoUdO3Zg586dxsWVnxQcHIyoqCjcvXsXmzdvtkMNrWPq1Kk4fvw4Vq5c2esK4XFxcSguLkZqauqA1G3QBC8AxjUB8/Pzjds6OjoQGxsLHx8fSKVSTJkyxfjoTEZGBuRyOWQyGU6cOIH58+dDqVTC29sbR48eNcn74sWLmDlzJmQyGZRKJSZPngytVttrGXxAREhJScELL7wAsVgMV1dXLFmyBNevXzemiYyMhEgkMnl18IYNGyCXyyEQCHD//n0AQFRUFDZt2oSKigoIBAKo1WqkpaVBIpHAw8MD69atw4gRIyCRSBAcHIzLly9bpQwAOHv27ICt5ZiWlgYiwqJFi56ZJiEhAWPHjsWnn36K8+fP95ifJX3AZbzaY0y6urpizpw5SE1NxeMFgWyMy1pD9l76TKVS0ZAhQ565X6vVEgAaNWqUcdvmzZtJLBZTTk4ONTY20tatW8nBwYGuXLlCRETbtm0jAPT111/TgwcPqK6ujmbPnk1yuZz0ej0REel0OlIqlbR3715qbW2l2tpaWrp0KdXX11tUxkDqy9JnsbGxJBKJ6NChQ9TU1ETXrl2jgIAAcnNzo9raWmO6lStXkqenp8mxSUlJBMDYFkREYWFhpFKpTNJFRESQXC6nsrIyevToEZWWltKMGTNIoVAY12fsbxmnT58mhUJB8fHxnD4/Efelt/z9/WnChAnd7lOpVHT79m0iIvrmm2/IwcGBRo8eTTqdjoiI8vPzzdZttLQPLBmvRLYZky+//DJNnTq1xzQxMTEEgIqKijjlzbX9abAtfaZQKCAQCNDc3AwAePToETIyMhAaGoqwsDC4uLhg+/btEAqFyMzMNDk2ODgYSqUS7u7u0Gg0ePjwIX788UcAQGVlJbRaLSZOnAiJRAJPT08cP34cbm5unMp4HrW2tiIlJQVLly7FqlWrMGTIEEyePBmffPIJ7t+/b7a6eX84OTkZf1lMmDABGRkZaG5utlo7LViwAFqtFjt27LBKfs/y8OFD3L59GyqVqte0QUFB+OCDD1BZWYkPP/yw2zR96YOexqs9x+SYMWMAACUlJTYtBxhkp40PHz4EEUGpVAIAbty4gZaWFkyaNMmYRiqVYvjw4SY/x58mEokAAAaDAQDg7+8PDw8PrFq1CnFxcaisrDSm7WsZz4vS0lLodDpMnz7dZPuMGTMgEolMTuusbfr06ZDJZLxopyfV1dWBiCxeNiwhIQHjxo1Deno6Ll26ZLa/v33w9Hi155jsapN79+7ZtBxgkAWvmzdvAni8lBnwOJgBwPbt203mh1VVVXV7y/dZpFIpLly4gFmzZiExMRH+/v7QaDRobW21Whn20nVr29nZ2Wyfi4uL8VesrYjFYtTX19u0DGt79OgRAPR6AbuLRCJBZmYmBAIB1q5di9bWVpP91u4De45JqVQK4Jc2sqVBFbzOnj0LAJg/fz4AwN3dHQCwb98+szUYCwsLOeU9ceJEnDp1CjU1NYiOjkZWVhaSk5OtWoY9uLi4AEC3X5CmpiZ4e3vbrGyDwWDzMmyh6wvKZVJmUFAQNm7ciPLycuzatctkn7X7wJ5jUq/XA/iljWxp0ASv2tpa7Nu3D97e3li7di0AYNSoUZBIJCguLu5X3jU1NSgrKwPweGDs2bMHAQEBKCsrs1oZ9jJp0iQ4OzubTe69fPky9Ho9XnrpJeM2Jycn46mJNRQUFICIEBgYaLMybMHDwwMCgYDz/K1du3Zh/PjxKCoqMtnOpQ8sYc8x2dUmnp6eNi+Ld8GLiKDT6dDZ2QkiQn19PbKysvDKK6/A0dEReXl5xmteEokEa9aswdGjR5GRkQGtVouOjg5UV1fjp59+srjMmpoarFu3DtevX4der0dRURGqqqoQGBhotTLsRSKRYNOmTcjNzcXhw4eh1WpRUlKC9evXY8SIEYiIiDCmVavV+Pnnn5GXlweDwYD6+npUVVWZ5Tl06FDU1NSgsrISzc3NxmDU2dmJxsZGtLe349q1a4iKioKPj49xikt/y8jPzx+QqRIymQz+/v6orq7mdFzX6aOjo6PZdkv7wNJyehuTGo0Gnp6eVn88qatNJk+ebNV8u8Xl3qS9pkqcPHmSpkyZQjKZjEQiETk4OBAAEggE5OLiQjNnzqT4+HhqaGgwO7atrY2io6PJx8eHnJycyN3dncLCwqi0tJTS09NJJpMRABozZgxVVFTQgQMHSKlUEgDy9fWlmzdvUmVlJQUHB5Orqys5OjrSyJEjadu2bdTe3t5rGQOtL1MlOjs7KSkpicaMGUNCoZBcXV0pNDSUbty4YZKuoaGB5s6dSxKJhPz8/Oi9996jLVu2EABSq9XGKQ9Xr14lX19fkkqlNGvWLKqtraWIiAgSCoXk5eVFTk5OpFQqacmSJVRRUWG1Ms6cOUMKhYISEhI4txs43qqPjIwkoVBILS0txm25ubmkUqkIALm5udG7777b7bFbtmwxmyphSR9YOl6Jeh+ToaGhBIBiY2N7/JyFhYX0yiuv0IgRIwgAAaDhw4dTcHAwXbx40Sz9ggULyMvLizo7Oy1ryP/h2v5ElM2L4MVYri/BayBERETQ0KFD7V2NZ+L65SkvLycnJyc6dOiQDWtlOx0dHTR79mw6ePCg1fK8f/8+SSQSSk5O5nxsX4IX704bGf4a6LcO2JJarUZ8fDzi4+Oh0+nsXR1OOjo6kJeXh+bmZmg0GqvlGxcXh2nTpiEyMtJqefaEBS+G6aOYmBgsX74cGo2GVw9fFxQU4Pjx48jPz7d4rlpvUlJSUFxcjDNnzkAoFFolz96w4MXY3NatW5GZmYkHDx7Az88POTk59q6S1SQmJiIyMhJ79uyxd1UsNm/ePBw5csTkGdL+OHHiBNra2lBQUABXV1er5GkJzkufMQxXu3fvxu7du+1dDZsJCQlBSEiIvathN4sXL8bixYsHvFz2y4thGF5iwYthGF5iwYthGF5iwYthGF7ifMG+uroa2dnZtqgLYwVdD96yPuKODw/SM0/gMqV12bJlxkcE2B/7Y3/sz5p/XGfYC/43NZ9hGIZPvmLXvBiG4SUWvBiG4SUWvBiG4SUWvBiG4aX/B75KW2vGQu5TAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 676
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(pd.DataFrame(history.history))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0, 250)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4U1eTGjO8XvS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "43a780f6-d1e1-4d20-e6dc-2b81623b0cf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5,3,1 model, epoch 30, learning rate=0.01"
      ],
      "metadata": {
        "id": "r_h0gdoeriB2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = keras.models.Sequential([\n",
        "    keras.layers.Input(shape=X_train.shape[1:]),\n",
        "    keras.layers.Dense(5, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
        "    keras.layers.Dense(3, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
        "    keras.layers.Dense(1)\n",
        "])"
      ],
      "metadata": {
        "id": "SZXrtYXNsgdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "nkl6n0al8i8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(learning_rate=0.01))\n",
        "history1 = model1.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid))\n",
        "mse_test1 = model1.evaluate(X_valid, y_valid)"
      ],
      "metadata": {
        "id": "kEHnCmZjrKiZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a5a9191-594a-44ba-836b-bb8e9a6515cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "23/23 [==============================] - 1s 8ms/step - loss: 197.6280 - val_loss: 12.5959\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 46.0671 - val_loss: 41.5261\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 52.3859 - val_loss: 15.4588\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 38.3484 - val_loss: 12.9077\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 14.4487 - val_loss: 10.6921\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 17.4314 - val_loss: 17.1010\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 12.0516 - val_loss: 12.6342\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 11.3241 - val_loss: 8.3122\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 24.6048 - val_loss: 12.2009\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 11.7432 - val_loss: 9.1477\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 10.8394 - val_loss: 9.4082\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 12.5674 - val_loss: 14.7675\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 10.0871 - val_loss: 10.4398\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 12.7975 - val_loss: 32.0686\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 11.4485 - val_loss: 9.5075\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 11.2738 - val_loss: 10.2735\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 11.7440 - val_loss: 9.6948\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 13.5650 - val_loss: 9.1557\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.5742 - val_loss: 8.2196\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 10.7836 - val_loss: 8.8081\n",
            "Epoch 21/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 8.6143 - val_loss: 13.8120\n",
            "Epoch 22/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 8.8823 - val_loss: 8.2543\n",
            "Epoch 23/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 11.1285 - val_loss: 20.8147\n",
            "Epoch 24/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 9.7101 - val_loss: 14.2649\n",
            "Epoch 25/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 9.8372 - val_loss: 10.0571\n",
            "Epoch 26/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 9.8513 - val_loss: 10.0927\n",
            "Epoch 27/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 9.7962 - val_loss: 8.6411\n",
            "Epoch 28/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.7151 - val_loss: 8.2404\n",
            "Epoch 29/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 10.5079 - val_loss: 10.9330\n",
            "Epoch 30/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 8.3589 - val_loss: 8.2767\n",
            "Epoch 31/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 9.4370 - val_loss: 8.7346\n",
            "Epoch 32/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 9.3477 - val_loss: 8.6493\n",
            "Epoch 33/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.6792 - val_loss: 11.6871\n",
            "Epoch 34/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 9.0754 - val_loss: 8.2863\n",
            "Epoch 35/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 9.1119 - val_loss: 9.8509\n",
            "Epoch 36/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.4115 - val_loss: 17.7663\n",
            "Epoch 37/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.9366 - val_loss: 9.1991\n",
            "Epoch 38/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.4505 - val_loss: 7.9689\n",
            "Epoch 39/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.3080 - val_loss: 9.1535\n",
            "Epoch 40/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 8.6214 - val_loss: 8.6002\n",
            "Epoch 41/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 9.4148 - val_loss: 8.9386\n",
            "Epoch 42/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.1880 - val_loss: 9.9796\n",
            "Epoch 43/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.1798 - val_loss: 8.9216\n",
            "Epoch 44/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 8.2226 - val_loss: 8.0918\n",
            "Epoch 45/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 9.1695 - val_loss: 8.2144\n",
            "Epoch 46/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.8586 - val_loss: 9.7477\n",
            "Epoch 47/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 9.4290 - val_loss: 10.0703\n",
            "Epoch 48/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.2065 - val_loss: 9.2260\n",
            "Epoch 49/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 8.1510 - val_loss: 11.6413\n",
            "Epoch 50/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 9.4100 - val_loss: 7.9783\n",
            "Epoch 51/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.1779 - val_loss: 12.8912\n",
            "Epoch 52/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.4914 - val_loss: 11.8599\n",
            "Epoch 53/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 8.0427 - val_loss: 8.4340\n",
            "Epoch 54/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 7.9891 - val_loss: 12.3704\n",
            "Epoch 55/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 9.6471 - val_loss: 8.6269\n",
            "Epoch 56/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 8.8978 - val_loss: 9.8880\n",
            "Epoch 57/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.8678 - val_loss: 8.0844\n",
            "Epoch 58/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.9255 - val_loss: 8.4167\n",
            "Epoch 59/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.7146 - val_loss: 8.0389\n",
            "Epoch 60/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.5101 - val_loss: 10.2168\n",
            "Epoch 61/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 8.0346 - val_loss: 7.7171\n",
            "Epoch 62/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.6049 - val_loss: 10.1713\n",
            "Epoch 63/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.4556 - val_loss: 7.5893\n",
            "Epoch 64/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.6689 - val_loss: 9.2715\n",
            "Epoch 65/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.6412 - val_loss: 8.9009\n",
            "Epoch 66/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.7364 - val_loss: 8.7695\n",
            "Epoch 67/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 9.0594 - val_loss: 10.2505\n",
            "Epoch 68/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 8.5527 - val_loss: 9.4848\n",
            "Epoch 69/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 9.1177 - val_loss: 16.6344\n",
            "Epoch 70/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 8.7195 - val_loss: 7.8095\n",
            "Epoch 71/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.4137 - val_loss: 11.1688\n",
            "Epoch 72/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.3958 - val_loss: 7.8544\n",
            "Epoch 73/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.8856 - val_loss: 9.2344\n",
            "Epoch 74/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.9308 - val_loss: 8.5847\n",
            "Epoch 75/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.1702 - val_loss: 8.5748\n",
            "Epoch 76/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 8.5913 - val_loss: 9.3362\n",
            "Epoch 77/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 9.1384 - val_loss: 12.0360\n",
            "Epoch 78/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.9544 - val_loss: 9.2344\n",
            "Epoch 79/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.3968 - val_loss: 8.2241\n",
            "Epoch 80/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.0532 - val_loss: 7.8636\n",
            "Epoch 81/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.9483 - val_loss: 9.0296\n",
            "Epoch 82/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.9936 - val_loss: 10.3454\n",
            "Epoch 83/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.0627 - val_loss: 8.1856\n",
            "Epoch 84/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.7177 - val_loss: 9.4361\n",
            "Epoch 85/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.9237 - val_loss: 8.4102\n",
            "Epoch 86/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.3627 - val_loss: 8.9538\n",
            "Epoch 87/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.8545 - val_loss: 9.8351\n",
            "Epoch 88/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.0077 - val_loss: 9.8055\n",
            "Epoch 89/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.1545 - val_loss: 8.1661\n",
            "Epoch 90/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.6086 - val_loss: 9.7268\n",
            "Epoch 91/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 7.3275 - val_loss: 9.4451\n",
            "Epoch 92/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.1949 - val_loss: 8.2172\n",
            "Epoch 93/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.7331 - val_loss: 8.3607\n",
            "Epoch 94/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.2150 - val_loss: 9.0407\n",
            "Epoch 95/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 7.6959 - val_loss: 8.8433\n",
            "Epoch 96/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.3178 - val_loss: 8.4578\n",
            "Epoch 97/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.7110 - val_loss: 8.9691\n",
            "Epoch 98/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.1461 - val_loss: 7.9866\n",
            "Epoch 99/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 8.0897 - val_loss: 8.0143\n",
            "Epoch 100/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.5456 - val_loss: 8.7023\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 8.7023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7,5,3,1 model, 30 epoch and rate=0.001"
      ],
      "metadata": {
        "id": "TGMCZFmTwDD7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "UHs3j6ffwhud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = keras.models.Sequential([\n",
        "    keras.layers.Input(shape=X_train.shape[1:]),\n",
        "    keras.layers.Dense(7, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
        "    keras.layers.Dense(5, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
        "    keras.layers.Dense(3, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "model2.summary()"
      ],
      "metadata": {
        "id": "VNlnB5tQrrMN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cde9073a-d7a6-431f-f2aa-ee5aa53948d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_123\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_336 (Dense)           (None, 7)                 63        \n",
            "                                                                 \n",
            " dense_337 (Dense)           (None, 5)                 40        \n",
            "                                                                 \n",
            " dense_338 (Dense)           (None, 3)                 18        \n",
            "                                                                 \n",
            " dense_339 (Dense)           (None, 1)                 4         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 125\n",
            "Trainable params: 125\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(learning_rate=0.01))\n",
        "history2 = model2.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid))\n",
        "mse_test2 = model2.evaluate(X_valid, y_valid)"
      ],
      "metadata": {
        "id": "4Z8WUj3PwRLm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6a69d06-b598-4f09-be7e-274a58f6dd44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "23/23 [==============================] - 1s 10ms/step - loss: 260.1095 - val_loss: 190.0417\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 146.4185 - val_loss: 96.5372\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 82.7788 - val_loss: 59.9609\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 57.7447 - val_loss: 45.8986\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 47.8003 - val_loss: 40.4694\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 43.7160 - val_loss: 37.5799\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 36.1455 - val_loss: 29.3410\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 30.0303 - val_loss: 25.8824\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 26.8713 - val_loss: 23.6140\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 24.9182 - val_loss: 22.0898\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 23.3663 - val_loss: 20.8982\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 22.1960 - val_loss: 19.5216\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 20.6710 - val_loss: 18.3844\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 19.7362 - val_loss: 16.9493\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 17.8086 - val_loss: 23.3896\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 19.0002 - val_loss: 15.1245\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 17.3521 - val_loss: 14.0658\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 16.0112 - val_loss: 14.1966\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 15.8206 - val_loss: 19.0919\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 17.8267 - val_loss: 12.5216\n",
            "Epoch 21/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 14.9060 - val_loss: 25.0517\n",
            "Epoch 22/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 16.0842 - val_loss: 12.5626\n",
            "Epoch 23/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 16.2866 - val_loss: 12.5909\n",
            "Epoch 24/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 13.5257 - val_loss: 11.3998\n",
            "Epoch 25/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 13.0290 - val_loss: 14.7069\n",
            "Epoch 26/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 12.4659 - val_loss: 10.4886\n",
            "Epoch 27/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 11.9475 - val_loss: 10.5202\n",
            "Epoch 28/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 13.4418 - val_loss: 11.0908\n",
            "Epoch 29/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 11.4610 - val_loss: 10.1910\n",
            "Epoch 30/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 12.6671 - val_loss: 11.6901\n",
            "Epoch 31/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 11.3545 - val_loss: 10.2133\n",
            "Epoch 32/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 13.3969 - val_loss: 10.3328\n",
            "Epoch 33/100\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 11.6809 - val_loss: 22.0139\n",
            "Epoch 34/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 11.6200 - val_loss: 10.9816\n",
            "Epoch 35/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 11.5109 - val_loss: 12.2771\n",
            "Epoch 36/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 9.9490 - val_loss: 14.3636\n",
            "Epoch 37/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 9.5459 - val_loss: 10.0318\n",
            "Epoch 38/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 10.5607 - val_loss: 10.1894\n",
            "Epoch 39/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 10.2297 - val_loss: 9.9891\n",
            "Epoch 40/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 10.5332 - val_loss: 10.3921\n",
            "Epoch 41/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 11.2338 - val_loss: 9.2531\n",
            "Epoch 42/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 9.0524 - val_loss: 11.7927\n",
            "Epoch 43/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 10.6161 - val_loss: 9.5800\n",
            "Epoch 44/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 9.3321 - val_loss: 11.1667\n",
            "Epoch 45/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 10.3105 - val_loss: 10.9509\n",
            "Epoch 46/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 10.4097 - val_loss: 10.3004\n",
            "Epoch 47/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 10.2836 - val_loss: 10.3989\n",
            "Epoch 48/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 9.8203 - val_loss: 9.7648\n",
            "Epoch 49/100\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 9.0764 - val_loss: 10.7937\n",
            "Epoch 50/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 9.2302 - val_loss: 9.1964\n",
            "Epoch 51/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 8.8630 - val_loss: 11.2226\n",
            "Epoch 52/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 9.9994 - val_loss: 9.1523\n",
            "Epoch 53/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.7876 - val_loss: 9.5784\n",
            "Epoch 54/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 9.6789 - val_loss: 11.8532\n",
            "Epoch 55/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 9.3257 - val_loss: 8.9460\n",
            "Epoch 56/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 9.0932 - val_loss: 10.8022\n",
            "Epoch 57/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 9.0906 - val_loss: 9.3601\n",
            "Epoch 58/100\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 9.8551 - val_loss: 9.0571\n",
            "Epoch 59/100\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 8.6664 - val_loss: 8.6329\n",
            "Epoch 60/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 8.3340 - val_loss: 9.5717\n",
            "Epoch 61/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 9.5070 - val_loss: 8.4808\n",
            "Epoch 62/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 8.7916 - val_loss: 10.1749\n",
            "Epoch 63/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 8.0862 - val_loss: 9.0748\n",
            "Epoch 64/100\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 8.0630 - val_loss: 10.3082\n",
            "Epoch 65/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 8.7431 - val_loss: 9.7277\n",
            "Epoch 66/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 8.6087 - val_loss: 8.5882\n",
            "Epoch 67/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 8.8458 - val_loss: 8.6156\n",
            "Epoch 68/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 8.0786 - val_loss: 9.3847\n",
            "Epoch 69/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.1976 - val_loss: 10.7340\n",
            "Epoch 70/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 8.3768 - val_loss: 8.4169\n",
            "Epoch 71/100\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 8.1051 - val_loss: 9.5733\n",
            "Epoch 72/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 9.1179 - val_loss: 8.5101\n",
            "Epoch 73/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 8.4611 - val_loss: 8.1854\n",
            "Epoch 74/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 8.7211 - val_loss: 8.4163\n",
            "Epoch 75/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 8.3691 - val_loss: 8.1947\n",
            "Epoch 76/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 8.4238 - val_loss: 9.2131\n",
            "Epoch 77/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.3499 - val_loss: 11.7008\n",
            "Epoch 78/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 7.9206 - val_loss: 8.5857\n",
            "Epoch 79/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 7.8668 - val_loss: 9.3382\n",
            "Epoch 80/100\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 8.4457 - val_loss: 13.7039\n",
            "Epoch 81/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 8.0890 - val_loss: 8.7353\n",
            "Epoch 82/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 7.8596 - val_loss: 9.4468\n",
            "Epoch 83/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 8.6673 - val_loss: 9.5445\n",
            "Epoch 84/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 7.9139 - val_loss: 8.0176\n",
            "Epoch 85/100\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 7.7374 - val_loss: 7.9848\n",
            "Epoch 86/100\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 7.5419 - val_loss: 8.0679\n",
            "Epoch 87/100\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 7.4234 - val_loss: 8.4385\n",
            "Epoch 88/100\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 7.7626 - val_loss: 8.4496\n",
            "Epoch 89/100\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 7.2363 - val_loss: 7.9154\n",
            "Epoch 90/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 7.5238 - val_loss: 9.6798\n",
            "Epoch 91/100\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 7.5454 - val_loss: 9.2236\n",
            "Epoch 92/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 8.2680 - val_loss: 8.5931\n",
            "Epoch 93/100\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 7.1363 - val_loss: 7.9906\n",
            "Epoch 94/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.2439 - val_loss: 8.4200\n",
            "Epoch 95/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.6602 - val_loss: 8.8916\n",
            "Epoch 96/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.1930 - val_loss: 8.6216\n",
            "Epoch 97/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.8571 - val_loss: 10.0918\n",
            "Epoch 98/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 7.8332 - val_loss: 9.2171\n",
            "Epoch 99/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.9804 - val_loss: 8.1699\n",
            "Epoch 100/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 7.7406 - val_loss: 7.8510\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 7.8510\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7,1 model, 100 epoch, rate=0.01"
      ],
      "metadata": {
        "id": "PrcVXraxwpLL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = keras.models.Sequential([\n",
        "    keras.layers.Input(shape=X_train.shape[1:]),\n",
        "    keras.layers.Dense(7, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "model3.summary()"
      ],
      "metadata": {
        "id": "MYMM7XP9wo70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaf1459b-5e54-4c2f-a327-606fc0ded95b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_124\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_340 (Dense)           (None, 7)                 63        \n",
            "                                                                 \n",
            " dense_341 (Dense)           (None, 1)                 8         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 71\n",
            "Trainable params: 71\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model3.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(learning_rate=0.01))\n",
        "history3 = model3.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid))\n",
        "mse_test3 = model3.evaluate(X_valid, y_valid)"
      ],
      "metadata": {
        "id": "QHciL6A9yZs0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4146116-f648-4eb1-c78a-4ad7bc741e50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "23/23 [==============================] - 1s 8ms/step - loss: 94.9746 - val_loss: 13.5518\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 16.8801 - val_loss: 10.0385\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 27.5915 - val_loss: 10.0685\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 19.9669 - val_loss: 8.5495\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 18.2493 - val_loss: 8.4609\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 13.0260 - val_loss: 8.8107\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 9.2262 - val_loss: 8.3336\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 15.9910 - val_loss: 8.1515\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 14.9251 - val_loss: 8.8092\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 17.1419 - val_loss: 9.4891\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 11.5596 - val_loss: 14.5843\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 16.3321 - val_loss: 10.2519\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 11.9278 - val_loss: 9.1527\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 14.2148 - val_loss: 9.7782\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 10.0979 - val_loss: 10.5571\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.3777 - val_loss: 8.6894\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 10.0039 - val_loss: 12.5423\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 9.6479 - val_loss: 9.3844\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.8700 - val_loss: 8.1437\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 8.3689 - val_loss: 8.4425\n",
            "Epoch 21/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 8.6712 - val_loss: 13.7865\n",
            "Epoch 22/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 31.9878 - val_loss: 8.5587\n",
            "Epoch 23/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 12.2961 - val_loss: 111.9246\n",
            "Epoch 24/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 21.1533 - val_loss: 20.1474\n",
            "Epoch 25/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 9.0630 - val_loss: 7.8731\n",
            "Epoch 26/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.2549 - val_loss: 11.2251\n",
            "Epoch 27/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.5401 - val_loss: 11.1894\n",
            "Epoch 28/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.8052 - val_loss: 7.7163\n",
            "Epoch 29/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.2817 - val_loss: 10.1419\n",
            "Epoch 30/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.5728 - val_loss: 7.5049\n",
            "Epoch 31/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.7491 - val_loss: 8.1467\n",
            "Epoch 32/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.5764 - val_loss: 7.8712\n",
            "Epoch 33/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.3329 - val_loss: 8.1428\n",
            "Epoch 34/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.2078 - val_loss: 7.6049\n",
            "Epoch 35/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.0499 - val_loss: 7.9019\n",
            "Epoch 36/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.9573 - val_loss: 8.4854\n",
            "Epoch 37/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.6495 - val_loss: 7.6793\n",
            "Epoch 38/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.3615 - val_loss: 7.4940\n",
            "Epoch 39/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.0884 - val_loss: 7.6723\n",
            "Epoch 40/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 7.3366 - val_loss: 7.9573\n",
            "Epoch 41/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 9.5739 - val_loss: 7.5563\n",
            "Epoch 42/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.4810 - val_loss: 11.6167\n",
            "Epoch 43/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 7.8064 - val_loss: 8.1558\n",
            "Epoch 44/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.1491 - val_loss: 7.4961\n",
            "Epoch 45/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.5148 - val_loss: 8.0628\n",
            "Epoch 46/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.6794 - val_loss: 7.1545\n",
            "Epoch 47/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.4074 - val_loss: 7.5336\n",
            "Epoch 48/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.8048 - val_loss: 7.4000\n",
            "Epoch 49/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.5303 - val_loss: 9.2104\n",
            "Epoch 50/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.2263 - val_loss: 7.5884\n",
            "Epoch 51/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 9.7115 - val_loss: 9.0627\n",
            "Epoch 52/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.7732 - val_loss: 8.4760\n",
            "Epoch 53/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 9.0941 - val_loss: 7.6043\n",
            "Epoch 54/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 10.1040 - val_loss: 8.3095\n",
            "Epoch 55/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.0594 - val_loss: 7.5211\n",
            "Epoch 56/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.4721 - val_loss: 7.9848\n",
            "Epoch 57/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 9.5086 - val_loss: 7.5938\n",
            "Epoch 58/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.9810 - val_loss: 7.2064\n",
            "Epoch 59/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 8.4591 - val_loss: 7.6942\n",
            "Epoch 60/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 10.0288 - val_loss: 7.6297\n",
            "Epoch 61/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 12.6051 - val_loss: 7.1611\n",
            "Epoch 62/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.9928 - val_loss: 8.9298\n",
            "Epoch 63/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 7.0887 - val_loss: 7.3782\n",
            "Epoch 64/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.7880 - val_loss: 7.6215\n",
            "Epoch 65/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 9.4420 - val_loss: 7.5841\n",
            "Epoch 66/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.2787 - val_loss: 7.9834\n",
            "Epoch 67/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.8488 - val_loss: 8.2399\n",
            "Epoch 68/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.2712 - val_loss: 7.2698\n",
            "Epoch 69/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.3845 - val_loss: 14.6694\n",
            "Epoch 70/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.3028 - val_loss: 7.6155\n",
            "Epoch 71/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 7.5283 - val_loss: 8.2244\n",
            "Epoch 72/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.5587 - val_loss: 7.7903\n",
            "Epoch 73/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.8546 - val_loss: 7.3900\n",
            "Epoch 74/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.6247 - val_loss: 7.4775\n",
            "Epoch 75/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.8713 - val_loss: 7.5606\n",
            "Epoch 76/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 7.7209 - val_loss: 8.8435\n",
            "Epoch 77/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 9.5558 - val_loss: 8.2444\n",
            "Epoch 78/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.9356 - val_loss: 8.2552\n",
            "Epoch 79/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.2115 - val_loss: 7.3565\n",
            "Epoch 80/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.1782 - val_loss: 7.4744\n",
            "Epoch 81/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.2737 - val_loss: 8.3334\n",
            "Epoch 82/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.5287 - val_loss: 10.3294\n",
            "Epoch 83/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 10.3029 - val_loss: 7.1398\n",
            "Epoch 84/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 8.0882 - val_loss: 7.5285\n",
            "Epoch 85/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 10.6257 - val_loss: 7.1010\n",
            "Epoch 86/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 8.9286 - val_loss: 8.0493\n",
            "Epoch 87/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 9.6424 - val_loss: 7.5838\n",
            "Epoch 88/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 8.3345 - val_loss: 8.8660\n",
            "Epoch 89/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 11.1587 - val_loss: 7.2400\n",
            "Epoch 90/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.1712 - val_loss: 8.0019\n",
            "Epoch 91/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 10.1207 - val_loss: 8.3581\n",
            "Epoch 92/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 10.5525 - val_loss: 7.6262\n",
            "Epoch 93/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 9.2017 - val_loss: 7.3634\n",
            "Epoch 94/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.9929 - val_loss: 7.2329\n",
            "Epoch 95/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 8.2118 - val_loss: 8.7004\n",
            "Epoch 96/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 6.5954 - val_loss: 7.6579\n",
            "Epoch 97/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 6.9940 - val_loss: 7.2116\n",
            "Epoch 98/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 6.7623 - val_loss: 7.1292\n",
            "Epoch 99/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 6.6647 - val_loss: 7.4414\n",
            "Epoch 100/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 7.5380 - val_loss: 7.6757\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 7.6757\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(pd.DataFrame(history3.history))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0, 250)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Px7VnNeCHaIl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "5bd74816-db6f-46fd-a498-3c8ac96dcbb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5,1 model, 100 epoch, rate=0.01"
      ],
      "metadata": {
        "id": "tZP_m-qE0_69"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model4 = keras.models.Sequential([\n",
        "    keras.layers.Input(shape=X_train.shape[1:]),\n",
        "    keras.layers.Dense(5, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "model4.summary()"
      ],
      "metadata": {
        "id": "Vi6kSnjiyy7D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28433ac5-bcb5-4448-d7cf-4d28d47535f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_125\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_342 (Dense)           (None, 5)                 45        \n",
            "                                                                 \n",
            " dense_343 (Dense)           (None, 1)                 6         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51\n",
            "Trainable params: 51\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model4.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(learning_rate=0.01))\n",
        "history4 = model4.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid))\n",
        "mse_test4 = model4.evaluate(X_valid, y_valid)"
      ],
      "metadata": {
        "id": "n5l1-9dn1Kku",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a69c6d85-5bf6-458b-e33e-4de9aad90cc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "23/23 [==============================] - 1s 11ms/step - loss: 135.9763 - val_loss: 14.9428\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 45.9359 - val_loss: 10.2226\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 26.9668 - val_loss: 10.2746\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 22.6689 - val_loss: 9.0373\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 18.9893 - val_loss: 9.5918\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 14.7491 - val_loss: 9.2869\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 10.9936 - val_loss: 8.8058\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 19.9912 - val_loss: 9.2441\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 17.6140 - val_loss: 9.4067\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 21.1250 - val_loss: 10.4741\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 11.1954 - val_loss: 10.2390\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 14.2929 - val_loss: 10.7864\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 17.9750 - val_loss: 9.8297\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 21.8849 - val_loss: 9.8747\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 17.6141 - val_loss: 17.1621\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 15.9937 - val_loss: 11.0408\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 18.3185 - val_loss: 20.0087\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 17.5400 - val_loss: 15.2076\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 14.9978 - val_loss: 9.3354\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 16.9930 - val_loss: 9.4924\n",
            "Epoch 21/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 17.2550 - val_loss: 21.8169\n",
            "Epoch 22/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 10.3768 - val_loss: 8.7298\n",
            "Epoch 23/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 12.3898 - val_loss: 98.1146\n",
            "Epoch 24/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 18.7455 - val_loss: 17.1891\n",
            "Epoch 25/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 14.6284 - val_loss: 9.2288\n",
            "Epoch 26/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 12.6882 - val_loss: 16.7205\n",
            "Epoch 27/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 12.7657 - val_loss: 11.8258\n",
            "Epoch 28/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 12.2287 - val_loss: 9.1157\n",
            "Epoch 29/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 11.9523 - val_loss: 10.8955\n",
            "Epoch 30/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 11.2411 - val_loss: 8.2328\n",
            "Epoch 31/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 11.1078 - val_loss: 8.7678\n",
            "Epoch 32/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 10.0242 - val_loss: 8.7279\n",
            "Epoch 33/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 9.7564 - val_loss: 8.8917\n",
            "Epoch 34/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 10.7696 - val_loss: 8.1557\n",
            "Epoch 35/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.6974 - val_loss: 8.6160\n",
            "Epoch 36/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 11.5040 - val_loss: 9.5950\n",
            "Epoch 37/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 9.1020 - val_loss: 8.6921\n",
            "Epoch 38/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 9.9668 - val_loss: 8.1292\n",
            "Epoch 39/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.7116 - val_loss: 8.3403\n",
            "Epoch 40/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.4978 - val_loss: 8.3317\n",
            "Epoch 41/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.8739 - val_loss: 8.8392\n",
            "Epoch 42/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.1696 - val_loss: 9.8743\n",
            "Epoch 43/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.2849 - val_loss: 8.8193\n",
            "Epoch 44/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.8018 - val_loss: 8.2820\n",
            "Epoch 45/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 8.8591 - val_loss: 8.7610\n",
            "Epoch 46/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.2252 - val_loss: 7.8260\n",
            "Epoch 47/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 9.1169 - val_loss: 8.0111\n",
            "Epoch 48/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 8.9907 - val_loss: 8.3932\n",
            "Epoch 49/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.3530 - val_loss: 8.6088\n",
            "Epoch 50/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 9.6532 - val_loss: 7.7363\n",
            "Epoch 51/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 9.2846 - val_loss: 11.9421\n",
            "Epoch 52/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.3841 - val_loss: 10.3841\n",
            "Epoch 53/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 7.9838 - val_loss: 7.9405\n",
            "Epoch 54/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.2521 - val_loss: 9.9274\n",
            "Epoch 55/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 9.2629 - val_loss: 9.4834\n",
            "Epoch 56/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 9.0284 - val_loss: 8.9361\n",
            "Epoch 57/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.3109 - val_loss: 8.4590\n",
            "Epoch 58/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 9.4604 - val_loss: 8.1028\n",
            "Epoch 59/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.9465 - val_loss: 7.7859\n",
            "Epoch 60/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.8042 - val_loss: 8.9647\n",
            "Epoch 61/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 8.4222 - val_loss: 7.6365\n",
            "Epoch 62/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 9.3414 - val_loss: 10.6710\n",
            "Epoch 63/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.7448 - val_loss: 7.9617\n",
            "Epoch 64/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.5732 - val_loss: 8.9212\n",
            "Epoch 65/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 9.1434 - val_loss: 8.5228\n",
            "Epoch 66/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 8.4462 - val_loss: 9.4499\n",
            "Epoch 67/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.2505 - val_loss: 9.4760\n",
            "Epoch 68/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.6717 - val_loss: 8.8123\n",
            "Epoch 69/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 8.8917 - val_loss: 19.4196\n",
            "Epoch 70/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 9.0050 - val_loss: 7.9721\n",
            "Epoch 71/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.5543 - val_loss: 9.2989\n",
            "Epoch 72/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.8515 - val_loss: 7.8093\n",
            "Epoch 73/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 9.2634 - val_loss: 9.6757\n",
            "Epoch 74/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 8.1753 - val_loss: 8.4206\n",
            "Epoch 75/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.3321 - val_loss: 8.7914\n",
            "Epoch 76/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.4961 - val_loss: 9.3122\n",
            "Epoch 77/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 8.4968 - val_loss: 9.8427\n",
            "Epoch 78/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 8.1723 - val_loss: 8.2512\n",
            "Epoch 79/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.7394 - val_loss: 8.0327\n",
            "Epoch 80/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.2384 - val_loss: 8.1398\n",
            "Epoch 81/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 9.7003 - val_loss: 9.2496\n",
            "Epoch 82/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.1332 - val_loss: 13.2600\n",
            "Epoch 83/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.4121 - val_loss: 7.8127\n",
            "Epoch 84/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.0020 - val_loss: 8.3920\n",
            "Epoch 85/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.2478 - val_loss: 8.4363\n",
            "Epoch 86/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.9683 - val_loss: 8.6208\n",
            "Epoch 87/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.0788 - val_loss: 8.4239\n",
            "Epoch 88/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.8760 - val_loss: 9.7947\n",
            "Epoch 89/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.9294 - val_loss: 8.6645\n",
            "Epoch 90/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.7606 - val_loss: 8.6563\n",
            "Epoch 91/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.0520 - val_loss: 9.7083\n",
            "Epoch 92/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.2223 - val_loss: 8.0382\n",
            "Epoch 93/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.5649 - val_loss: 8.0861\n",
            "Epoch 94/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.1438 - val_loss: 8.9079\n",
            "Epoch 95/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 9.0484 - val_loss: 10.2899\n",
            "Epoch 96/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.6155 - val_loss: 9.0517\n",
            "Epoch 97/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.7522 - val_loss: 8.5355\n",
            "Epoch 98/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 8.7979 - val_loss: 8.4006\n",
            "Epoch 99/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 8.0375 - val_loss: 8.6599\n",
            "Epoch 100/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.7685 - val_loss: 8.6454\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 8.6454\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3,1 model, 30 epoch, rate=0.01"
      ],
      "metadata": {
        "id": "yzrlLvyd1S3j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model5 = keras.models.Sequential([\n",
        "    keras.layers.Input(shape=X_train.shape[1:]),\n",
        "    keras.layers.Dense(3, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "model5.summary()"
      ],
      "metadata": {
        "id": "1fMRk0bY1WLi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d6f343e-40e2-4c7f-837d-0d44a7af1ebd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_126\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_344 (Dense)           (None, 3)                 27        \n",
            "                                                                 \n",
            " dense_345 (Dense)           (None, 1)                 4         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31\n",
            "Trainable params: 31\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model5.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(learning_rate=0.01))\n",
        "history5 = model5.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid))\n",
        "mse_test5 = model5.evaluate(X_valid, y_valid)"
      ],
      "metadata": {
        "id": "Q8SQMhlc1ZVj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "362402f3-e672-4be3-ee7a-4574943cd75a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 102.0863 - val_loss: 13.2835\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 16.1648 - val_loss: 8.9313\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 30.3199 - val_loss: 9.6918\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 21.8503 - val_loss: 8.9449\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 19.8067 - val_loss: 9.3799\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 15.8692 - val_loss: 9.1619\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 11.1626 - val_loss: 8.7751\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 19.1785 - val_loss: 8.7798\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 17.0806 - val_loss: 9.5139\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 21.6065 - val_loss: 10.4362\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 11.3401 - val_loss: 10.3803\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 14.8593 - val_loss: 10.1980\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 17.5456 - val_loss: 9.6683\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 19.4151 - val_loss: 10.0684\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 14.9104 - val_loss: 14.1919\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 14.0371 - val_loss: 10.3806\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 15.5351 - val_loss: 14.8338\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 13.9518 - val_loss: 10.0003\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 11.0055 - val_loss: 8.7557\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 11.3230 - val_loss: 9.1516\n",
            "Epoch 21/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 11.3945 - val_loss: 14.8478\n",
            "Epoch 22/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.5729 - val_loss: 8.5591\n",
            "Epoch 23/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 10.4110 - val_loss: 38.2039\n",
            "Epoch 24/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 10.9804 - val_loss: 11.6127\n",
            "Epoch 25/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 10.3207 - val_loss: 8.5365\n",
            "Epoch 26/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 9.6637 - val_loss: 13.4383\n",
            "Epoch 27/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 9.4953 - val_loss: 9.3638\n",
            "Epoch 28/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 8.6349 - val_loss: 8.4809\n",
            "Epoch 29/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 9.6883 - val_loss: 9.6010\n",
            "Epoch 30/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.6166 - val_loss: 7.9830\n",
            "Epoch 31/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 9.2952 - val_loss: 9.5143\n",
            "Epoch 32/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.4095 - val_loss: 8.5721\n",
            "Epoch 33/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.5745 - val_loss: 9.6891\n",
            "Epoch 34/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.8346 - val_loss: 7.7736\n",
            "Epoch 35/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.9292 - val_loss: 9.1029\n",
            "Epoch 36/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 9.1752 - val_loss: 11.2574\n",
            "Epoch 37/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.0095 - val_loss: 9.2974\n",
            "Epoch 38/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 8.8487 - val_loss: 8.2608\n",
            "Epoch 39/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.1783 - val_loss: 8.2081\n",
            "Epoch 40/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.9941 - val_loss: 9.0287\n",
            "Epoch 41/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.9999 - val_loss: 8.8975\n",
            "Epoch 42/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.6303 - val_loss: 9.7486\n",
            "Epoch 43/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.6523 - val_loss: 9.1999\n",
            "Epoch 44/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.6268 - val_loss: 8.2572\n",
            "Epoch 45/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.7796 - val_loss: 8.7664\n",
            "Epoch 46/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.3177 - val_loss: 8.0951\n",
            "Epoch 47/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.8050 - val_loss: 8.5788\n",
            "Epoch 48/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.8787 - val_loss: 8.2916\n",
            "Epoch 49/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 6.9244 - val_loss: 9.2166\n",
            "Epoch 50/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 8.8353 - val_loss: 7.8080\n",
            "Epoch 51/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 9.9062 - val_loss: 12.9090\n",
            "Epoch 52/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.8990 - val_loss: 10.0465\n",
            "Epoch 53/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.6921 - val_loss: 8.0943\n",
            "Epoch 54/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.8172 - val_loss: 9.9382\n",
            "Epoch 55/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 9.1469 - val_loss: 9.5819\n",
            "Epoch 56/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.2555 - val_loss: 9.1018\n",
            "Epoch 57/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.1218 - val_loss: 9.1366\n",
            "Epoch 58/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 9.2444 - val_loss: 9.5668\n",
            "Epoch 59/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.7268 - val_loss: 7.9415\n",
            "Epoch 60/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.9708 - val_loss: 9.8008\n",
            "Epoch 61/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.9868 - val_loss: 7.8513\n",
            "Epoch 62/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.6137 - val_loss: 10.4348\n",
            "Epoch 63/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 8.0988 - val_loss: 8.0142\n",
            "Epoch 64/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.3646 - val_loss: 9.0057\n",
            "Epoch 65/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 9.2568 - val_loss: 9.3553\n",
            "Epoch 66/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.0330 - val_loss: 10.7387\n",
            "Epoch 67/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.6496 - val_loss: 8.8612\n",
            "Epoch 68/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 8.1727 - val_loss: 9.3201\n",
            "Epoch 69/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.2745 - val_loss: 16.0222\n",
            "Epoch 70/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.5913 - val_loss: 7.8913\n",
            "Epoch 71/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.9924 - val_loss: 9.4714\n",
            "Epoch 72/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.9019 - val_loss: 7.7536\n",
            "Epoch 73/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.8584 - val_loss: 9.5243\n",
            "Epoch 74/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.9361 - val_loss: 9.6433\n",
            "Epoch 75/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.8059 - val_loss: 8.7752\n",
            "Epoch 76/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 8.4001 - val_loss: 9.0487\n",
            "Epoch 77/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.6611 - val_loss: 11.0230\n",
            "Epoch 78/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.8277 - val_loss: 7.9783\n",
            "Epoch 79/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.4887 - val_loss: 8.9347\n",
            "Epoch 80/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.8093 - val_loss: 7.9449\n",
            "Epoch 81/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 8.7419 - val_loss: 9.8622\n",
            "Epoch 82/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.9378 - val_loss: 11.9395\n",
            "Epoch 83/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.2261 - val_loss: 8.0002\n",
            "Epoch 84/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.9279 - val_loss: 8.0344\n",
            "Epoch 85/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 8.1450 - val_loss: 7.9655\n",
            "Epoch 86/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.5552 - val_loss: 8.4757\n",
            "Epoch 87/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.8151 - val_loss: 8.3861\n",
            "Epoch 88/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.4016 - val_loss: 11.0467\n",
            "Epoch 89/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.8022 - val_loss: 8.7389\n",
            "Epoch 90/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.4190 - val_loss: 8.7181\n",
            "Epoch 91/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.5485 - val_loss: 9.2397\n",
            "Epoch 92/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.4189 - val_loss: 8.3205\n",
            "Epoch 93/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.2304 - val_loss: 8.0947\n",
            "Epoch 94/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 8.1777 - val_loss: 10.0556\n",
            "Epoch 95/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 9.0387 - val_loss: 9.8343\n",
            "Epoch 96/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.1472 - val_loss: 9.2760\n",
            "Epoch 97/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.4320 - val_loss: 9.0806\n",
            "Epoch 98/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 9.0720 - val_loss: 9.1758\n",
            "Epoch 99/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 7.8884 - val_loss: 9.4096\n",
            "Epoch 100/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 8.1835 - val_loss: 8.0379\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 8.0379\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1 model, 30 epoch rate=0.01"
      ],
      "metadata": {
        "id": "lGYg_tYY2dDm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model6 = keras.models.Sequential([\n",
        "    keras.layers.Input(shape=X_train.shape[1:]),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "model6.summary()"
      ],
      "metadata": {
        "id": "q4gwujUi2cy8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ba26d0f-2a69-426e-83e1-13d0d4cbee13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_127\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_346 (Dense)           (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9\n",
            "Trainable params: 9\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model6.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(learning_rate=0.01))\n",
        "history6 = model6.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid))\n",
        "mse_test6 = model6.evaluate(X_valid, y_valid)"
      ],
      "metadata": {
        "id": "yqC_lP8x3vNU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ee8d96f-244d-41a8-e8ab-4be16264d682"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "23/23 [==============================] - 1s 14ms/step - loss: 251.0940 - val_loss: 152.3804\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 104.6612 - val_loss: 67.7527\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 49.4551 - val_loss: 33.6629\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 27.2780 - val_loss: 19.7616\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 18.4333 - val_loss: 14.0679\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 14.9303 - val_loss: 11.5077\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 13.3850 - val_loss: 10.4169\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 13.0742 - val_loss: 9.8793\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 12.7002 - val_loss: 9.5862\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 12.6347 - val_loss: 9.6311\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 12.1781 - val_loss: 10.3905\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 12.1900 - val_loss: 9.3888\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 12.6775 - val_loss: 9.4209\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 12.7846 - val_loss: 9.3117\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 12.6013 - val_loss: 9.8584\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 12.5049 - val_loss: 9.8015\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 12.6289 - val_loss: 9.6133\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 12.4705 - val_loss: 9.9877\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 12.6689 - val_loss: 9.3509\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 12.5526 - val_loss: 9.3632\n",
            "Epoch 21/100\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 12.4745 - val_loss: 9.6576\n",
            "Epoch 22/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 11.9808 - val_loss: 9.2254\n",
            "Epoch 23/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 12.5251 - val_loss: 10.7385\n",
            "Epoch 24/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 12.6153 - val_loss: 9.5906\n",
            "Epoch 25/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 12.4666 - val_loss: 9.5935\n",
            "Epoch 26/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 12.4206 - val_loss: 9.4502\n",
            "Epoch 27/100\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 12.4214 - val_loss: 9.4043\n",
            "Epoch 28/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 12.4742 - val_loss: 9.3183\n",
            "Epoch 29/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 12.3576 - val_loss: 9.3444\n",
            "Epoch 30/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 12.4363 - val_loss: 9.3585\n",
            "Epoch 31/100\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 12.5084 - val_loss: 9.3607\n",
            "Epoch 32/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 12.4684 - val_loss: 9.3952\n",
            "Epoch 33/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 12.3204 - val_loss: 9.2823\n",
            "Epoch 34/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 12.4865 - val_loss: 9.4358\n",
            "Epoch 35/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 12.1769 - val_loss: 9.2978\n",
            "Epoch 36/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 12.9665 - val_loss: 9.2957\n",
            "Epoch 37/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 12.5334 - val_loss: 9.3189\n",
            "Epoch 38/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 12.3867 - val_loss: 9.2943\n",
            "Epoch 39/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 12.2276 - val_loss: 9.6004\n",
            "Epoch 40/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 12.5385 - val_loss: 9.4942\n",
            "Epoch 41/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 12.5066 - val_loss: 9.5125\n",
            "Epoch 42/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 12.3998 - val_loss: 9.4656\n",
            "Epoch 43/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 12.2756 - val_loss: 9.8034\n",
            "Epoch 44/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 12.4795 - val_loss: 9.8711\n",
            "Epoch 45/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 12.4686 - val_loss: 9.4967\n",
            "Epoch 46/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 12.8679 - val_loss: 9.3649\n",
            "Epoch 47/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 12.5464 - val_loss: 9.3163\n",
            "Epoch 48/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 12.3161 - val_loss: 9.2549\n",
            "Epoch 49/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 12.4108 - val_loss: 9.2271\n",
            "Epoch 50/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 12.5998 - val_loss: 9.6222\n",
            "Epoch 51/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 12.2887 - val_loss: 9.2806\n",
            "Epoch 52/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 12.4865 - val_loss: 9.7885\n",
            "Epoch 53/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 11.9931 - val_loss: 9.2753\n",
            "Epoch 54/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 12.4263 - val_loss: 9.2848\n",
            "Epoch 55/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 12.3587 - val_loss: 9.9739\n",
            "Epoch 56/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 12.4479 - val_loss: 9.4328\n",
            "Epoch 57/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 12.3599 - val_loss: 9.3267\n",
            "Epoch 58/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 12.4286 - val_loss: 9.2776\n",
            "Epoch 59/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 12.1505 - val_loss: 9.2542\n",
            "Epoch 60/100\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 12.2459 - val_loss: 9.2652\n",
            "Epoch 61/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 12.3667 - val_loss: 9.1794\n",
            "Epoch 62/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 12.4563 - val_loss: 9.2021\n",
            "Epoch 63/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 12.4855 - val_loss: 9.1907\n",
            "Epoch 64/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 12.3447 - val_loss: 9.2564\n",
            "Epoch 65/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 12.2423 - val_loss: 9.2498\n",
            "Epoch 66/100\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 12.3936 - val_loss: 9.5984\n",
            "Epoch 67/100\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 12.3850 - val_loss: 9.3851\n",
            "Epoch 68/100\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 12.4385 - val_loss: 9.4343\n",
            "Epoch 69/100\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 12.3475 - val_loss: 9.3938\n",
            "Epoch 70/100\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 12.3944 - val_loss: 9.3031\n",
            "Epoch 71/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 12.4525 - val_loss: 9.3523\n",
            "Epoch 72/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 12.5041 - val_loss: 9.3953\n",
            "Epoch 73/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 12.4460 - val_loss: 9.3455\n",
            "Epoch 74/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 12.5383 - val_loss: 9.4932\n",
            "Epoch 75/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 12.3361 - val_loss: 9.8144\n",
            "Epoch 76/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 12.3786 - val_loss: 10.0773\n",
            "Epoch 77/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 12.3250 - val_loss: 9.3698\n",
            "Epoch 78/100\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 12.5326 - val_loss: 9.4698\n",
            "Epoch 79/100\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 12.4100 - val_loss: 9.5740\n",
            "Epoch 80/100\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 12.3471 - val_loss: 9.6714\n",
            "Epoch 81/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 12.4538 - val_loss: 9.9777\n",
            "Epoch 82/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 12.5505 - val_loss: 9.5518\n",
            "Epoch 83/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 12.8558 - val_loss: 9.6111\n",
            "Epoch 84/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 12.4298 - val_loss: 9.4399\n",
            "Epoch 85/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 12.5163 - val_loss: 9.4383\n",
            "Epoch 86/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 12.4538 - val_loss: 9.3559\n",
            "Epoch 87/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 12.4573 - val_loss: 9.6175\n",
            "Epoch 88/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 12.4447 - val_loss: 9.4347\n",
            "Epoch 89/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 12.2409 - val_loss: 9.2848\n",
            "Epoch 90/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 12.4039 - val_loss: 9.5897\n",
            "Epoch 91/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 12.2289 - val_loss: 9.2795\n",
            "Epoch 92/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 12.4800 - val_loss: 9.2391\n",
            "Epoch 93/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 12.2880 - val_loss: 9.2051\n",
            "Epoch 94/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 12.3095 - val_loss: 9.3119\n",
            "Epoch 95/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 12.4216 - val_loss: 9.2464\n",
            "Epoch 96/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 12.4370 - val_loss: 9.3809\n",
            "Epoch 97/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 12.4382 - val_loss: 9.3076\n",
            "Epoch 98/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 12.1895 - val_loss: 9.8574\n",
            "Epoch 99/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 12.4576 - val_loss: 9.4001\n",
            "Epoch 100/100\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 12.4366 - val_loss: 9.2843\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 9.2843\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### table of different approach"
      ],
      "metadata": {
        "id": "QEFLaeM1ISfU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tabulate import tabulate\n",
        "\n",
        "table = [['model_name','describe','MSE'], \n",
        "         ['model', 'Dense 5,3,1; epochs=100, rate=0.001',mse_test], \n",
        "         ['model1','Dense 5,3,1; epochs=100, rate=0.01', mse_test1],\n",
        "         ['model2', 'Dense 7,5,3,1; epochs=100, rate=0.01', mse_test2],\n",
        "         ['model3', 'Dense 7,1; epochs=100, rate=0.01', mse_test3],\n",
        "         ['model4', 'Dense 5,1; epochs=100, rate=0.01', mse_test4],\n",
        "         ['model5', 'Dense 3,1; epochs=100, rate=0.01', mse_test5],\n",
        "         ['model6', 'Dense 1; epochs=100, rate=0.01', mse_test6]]\n",
        "         \n",
        "print(tabulate(table))"
      ],
      "metadata": {
        "id": "E7RpgBlJ56wA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3583d0dc-59e4-41a9-ac4a-90c227774525"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------  ------------------------------------  -----------------\n",
            "model_name  describe                              MSE\n",
            "model       Dense 5,3,1; epochs=100, rate=0.001   8.301560401916504\n",
            "model1      Dense 5,3,1; epochs=100, rate=0.01    8.702272415161133\n",
            "model2      Dense 7,5,3,1; epochs=100, rate=0.01  7.851003170013428\n",
            "model3      Dense 7,1; epochs=100, rate=0.01      7.675676345825195\n",
            "model4      Dense 5,1; epochs=100, rate=0.01      8.64540958404541\n",
            "model5      Dense 3,1; epochs=100, rate=0.01      8.037948608398438\n",
            "model6      Dense 1; epochs=100, rate=0.01        9.284250259399414\n",
            "----------  ------------------------------------  -----------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model3 selected!!!"
      ],
      "metadata": {
        "id": "4F9kvbN9Ik0x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier1 = keras.models.Sequential([\n",
        "    keras.layers.Input(shape=X_train.shape[1:]),\n",
        "    keras.layers.Dense(7, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "classifier1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trhnkROJIkGX",
        "outputId": "bc4247e7-c564-4a33-bf45-3a29f7d833db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_139\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_369 (Dense)           (None, 7)                 63        \n",
            "                                                                 \n",
            " dense_370 (Dense)           (None, 1)                 8         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 71\n",
            "Trainable params: 71\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier1.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(learning_rate=0.01))\n",
        "history_classifier1 = classifier1.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eip1q-27Iuuz",
        "outputId": "2bcc96c2-3dac-4940-c3e8-b09345d26e11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 125.8434 - val_loss: 7.9819\n",
            "Epoch 2/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 14.7802 - val_loss: 7.4775\n",
            "Epoch 3/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 11.6408 - val_loss: 9.2444\n",
            "Epoch 4/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 23.3761 - val_loss: 14.3189\n",
            "Epoch 5/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 14.2866 - val_loss: 6.1585\n",
            "Epoch 6/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 14.1177 - val_loss: 6.9787\n",
            "Epoch 7/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 14.1139 - val_loss: 4.9897\n",
            "Epoch 8/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 14.4934 - val_loss: 5.9006\n",
            "Epoch 9/100\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 14.0620 - val_loss: 8.0020\n",
            "Epoch 10/100\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 13.2713 - val_loss: 17.5337\n",
            "Epoch 11/100\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 11.2144 - val_loss: 6.1105\n",
            "Epoch 12/100\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 13.0608 - val_loss: 4.9757\n",
            "Epoch 13/100\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 10.1229 - val_loss: 5.7226\n",
            "Epoch 14/100\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 9.4780 - val_loss: 6.2941\n",
            "Epoch 15/100\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 10.0222 - val_loss: 42.3829\n",
            "Epoch 16/100\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 11.7968 - val_loss: 5.2680\n",
            "Epoch 17/100\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 8.2384 - val_loss: 60.9069\n",
            "Epoch 18/100\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 11.6228 - val_loss: 13.8538\n",
            "Epoch 19/100\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 7.9340 - val_loss: 5.6626\n",
            "Epoch 20/100\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 8.3779 - val_loss: 5.0530\n",
            "Epoch 21/100\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 7.6121 - val_loss: 5.2861\n",
            "Epoch 22/100\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 8.6436 - val_loss: 5.2298\n",
            "Epoch 23/100\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 7.4995 - val_loss: 5.0009\n",
            "Epoch 24/100\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 7.8560 - val_loss: 6.5827\n",
            "Epoch 25/100\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 10.2329 - val_loss: 5.9450\n",
            "Epoch 26/100\n",
            "30/30 [==============================] - 0s 4ms/step - loss: 10.0329 - val_loss: 5.1910\n",
            "Epoch 27/100\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 7.2517 - val_loss: 5.1872\n",
            "Epoch 28/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 9.5869 - val_loss: 5.0836\n",
            "Epoch 29/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 10.7891 - val_loss: 5.9572\n",
            "Epoch 30/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 7.7980 - val_loss: 21.7108\n",
            "Epoch 31/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 10.3387 - val_loss: 5.8054\n",
            "Epoch 32/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 7.4714 - val_loss: 5.2723\n",
            "Epoch 33/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 10.0077 - val_loss: 8.4436\n",
            "Epoch 34/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 14.9642 - val_loss: 5.7814\n",
            "Epoch 35/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 11.3365 - val_loss: 5.6600\n",
            "Epoch 36/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 16.0126 - val_loss: 6.3535\n",
            "Epoch 37/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 8.2045 - val_loss: 5.6097\n",
            "Epoch 38/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 8.2983 - val_loss: 9.7006\n",
            "Epoch 39/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 8.5854 - val_loss: 4.9768\n",
            "Epoch 40/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 8.7224 - val_loss: 4.8608\n",
            "Epoch 41/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 8.2797 - val_loss: 4.9272\n",
            "Epoch 42/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 7.7383 - val_loss: 8.5469\n",
            "Epoch 43/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 6.8728 - val_loss: 4.9125\n",
            "Epoch 44/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 6.9278 - val_loss: 5.0441\n",
            "Epoch 45/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 7.5523 - val_loss: 5.0645\n",
            "Epoch 46/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 7.0807 - val_loss: 4.7729\n",
            "Epoch 47/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 10.8178 - val_loss: 4.8071\n",
            "Epoch 48/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 7.7609 - val_loss: 5.1909\n",
            "Epoch 49/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 8.8476 - val_loss: 5.2822\n",
            "Epoch 50/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 8.3083 - val_loss: 6.0293\n",
            "Epoch 51/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 7.2926 - val_loss: 6.4208\n",
            "Epoch 52/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 8.6998 - val_loss: 4.9733\n",
            "Epoch 53/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 7.4773 - val_loss: 5.2502\n",
            "Epoch 54/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 8.7728 - val_loss: 5.4854\n",
            "Epoch 55/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 6.8117 - val_loss: 5.1004\n",
            "Epoch 56/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 7.5053 - val_loss: 6.0491\n",
            "Epoch 57/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 7.5236 - val_loss: 5.6920\n",
            "Epoch 58/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 7.5937 - val_loss: 12.4547\n",
            "Epoch 59/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 7.1312 - val_loss: 14.9831\n",
            "Epoch 60/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 7.6874 - val_loss: 5.8146\n",
            "Epoch 61/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 7.9188 - val_loss: 5.1929\n",
            "Epoch 62/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 6.7962 - val_loss: 6.0205\n",
            "Epoch 63/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 7.8447 - val_loss: 8.9636\n",
            "Epoch 64/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 10.1789 - val_loss: 5.2547\n",
            "Epoch 65/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 14.9961 - val_loss: 6.0539\n",
            "Epoch 66/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 7.3440 - val_loss: 5.5140\n",
            "Epoch 67/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 7.2697 - val_loss: 6.2667\n",
            "Epoch 68/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 7.5064 - val_loss: 4.8437\n",
            "Epoch 69/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 7.6494 - val_loss: 7.8361\n",
            "Epoch 70/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 7.0162 - val_loss: 5.6995\n",
            "Epoch 71/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 6.8641 - val_loss: 5.5092\n",
            "Epoch 72/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 7.4385 - val_loss: 5.9111\n",
            "Epoch 73/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 7.0865 - val_loss: 5.0282\n",
            "Epoch 74/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 7.5601 - val_loss: 5.6597\n",
            "Epoch 75/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 15.3391 - val_loss: 5.7183\n",
            "Epoch 76/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 22.5977 - val_loss: 6.6409\n",
            "Epoch 77/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 8.2843 - val_loss: 5.2109\n",
            "Epoch 78/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 7.4879 - val_loss: 9.5713\n",
            "Epoch 79/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 7.3762 - val_loss: 4.8395\n",
            "Epoch 80/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 7.5694 - val_loss: 5.1551\n",
            "Epoch 81/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 8.2642 - val_loss: 5.4800\n",
            "Epoch 82/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 7.4496 - val_loss: 4.6995\n",
            "Epoch 83/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 7.2658 - val_loss: 5.1648\n",
            "Epoch 84/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 6.8645 - val_loss: 4.6944\n",
            "Epoch 85/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 6.5924 - val_loss: 10.3514\n",
            "Epoch 86/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 11.5114 - val_loss: 5.0249\n",
            "Epoch 87/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 12.4164 - val_loss: 6.1390\n",
            "Epoch 88/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 8.1677 - val_loss: 7.1672\n",
            "Epoch 89/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 9.7829 - val_loss: 4.9417\n",
            "Epoch 90/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 7.7447 - val_loss: 5.3561\n",
            "Epoch 91/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 7.8749 - val_loss: 4.8796\n",
            "Epoch 92/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 7.3198 - val_loss: 5.2913\n",
            "Epoch 93/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 7.5207 - val_loss: 5.2744\n",
            "Epoch 94/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 6.9407 - val_loss: 4.8866\n",
            "Epoch 95/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 7.5896 - val_loss: 5.0544\n",
            "Epoch 96/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 7.1196 - val_loss: 4.8641\n",
            "Epoch 97/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 7.9755 - val_loss: 5.9789\n",
            "Epoch 98/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 7.3135 - val_loss: 4.9561\n",
            "Epoch 99/100\n",
            "30/30 [==============================] - 0s 2ms/step - loss: 8.2367 - val_loss: 4.9699\n",
            "Epoch 100/100\n",
            "30/30 [==============================] - 0s 3ms/step - loss: 7.6481 - val_loss: 4.7869\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred1 = classifier1.predict(X_test)\n",
        "mse_class1 = mean_squared_error(y_test, y_pred1)\n",
        "r2_square_class1 = r2_score(y_test, y_pred1)\n",
        "print_evaluate(y_test,y_pred1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UNlpdHcJ4zc",
        "outputId": "228afd6c-a10a-4790-c018-d491ed6181bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 2ms/step\n",
            "MSE: 4.786880449982313\n",
            "RMSE: 2.1878940673584526\n",
            "R2 Square 0.8329478089785853\n",
            "__________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### classifier2"
      ],
      "metadata": {
        "id": "Hi6PAGlFKex9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.55,random_state=42)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full,test_size=0.55, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_valid = scaler.transform(X_valid)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "M6CrKSQWKgob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier2 = keras.models.Sequential([\n",
        "    keras.layers.Input(shape=X_train.shape[1:]),\n",
        "    keras.layers.Dense(7, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "classifier2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMfauydsLs5l",
        "outputId": "665dae75-3df8-4e05-ce0b-b35052598897"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_140\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_371 (Dense)           (None, 7)                 63        \n",
            "                                                                 \n",
            " dense_372 (Dense)           (None, 1)                 8         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 71\n",
            "Trainable params: 71\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier2.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(learning_rate=0.01))\n",
        "history_classifier2 = classifier2.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esfTH8XHL2YM",
        "outputId": "82b79b68-d928-4a34-c973-e309e59fee75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "9/9 [==============================] - 1s 26ms/step - loss: 153.0630 - val_loss: 31.6223\n",
            "Epoch 2/100\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 19.3224 - val_loss: 17.7397\n",
            "Epoch 3/100\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 11.9201 - val_loss: 14.1358\n",
            "Epoch 4/100\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 9.3397 - val_loss: 10.9906\n",
            "Epoch 5/100\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.2572 - val_loss: 11.7280\n",
            "Epoch 6/100\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 8.8771 - val_loss: 10.2341\n",
            "Epoch 7/100\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.4607 - val_loss: 9.6508\n",
            "Epoch 8/100\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 8.0094 - val_loss: 10.0329\n",
            "Epoch 9/100\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 7.5176 - val_loss: 9.5794\n",
            "Epoch 10/100\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 7.9618 - val_loss: 12.8820\n",
            "Epoch 11/100\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.8792 - val_loss: 9.8920\n",
            "Epoch 12/100\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.5094 - val_loss: 13.1324\n",
            "Epoch 13/100\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.4161 - val_loss: 8.7992\n",
            "Epoch 14/100\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.5051 - val_loss: 9.0733\n",
            "Epoch 15/100\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.0698 - val_loss: 9.1751\n",
            "Epoch 16/100\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 7.3598 - val_loss: 9.0519\n",
            "Epoch 17/100\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.7874 - val_loss: 8.6854\n",
            "Epoch 18/100\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 6.6258 - val_loss: 8.9630\n",
            "Epoch 19/100\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.9291 - val_loss: 9.2569\n",
            "Epoch 20/100\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 7.0241 - val_loss: 9.1760\n",
            "Epoch 21/100\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.7830 - val_loss: 8.8908\n",
            "Epoch 22/100\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.4777 - val_loss: 9.6089\n",
            "Epoch 23/100\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 6.8013 - val_loss: 8.6321\n",
            "Epoch 24/100\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.6808 - val_loss: 8.4924\n",
            "Epoch 25/100\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 7.3458 - val_loss: 8.2364\n",
            "Epoch 26/100\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.8847 - val_loss: 10.4371\n",
            "Epoch 27/100\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 6.8914 - val_loss: 8.8044\n",
            "Epoch 28/100\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.0161 - val_loss: 8.3752\n",
            "Epoch 29/100\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.3857 - val_loss: 9.4407\n",
            "Epoch 30/100\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 6.8834 - val_loss: 9.6498\n",
            "Epoch 31/100\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.5627 - val_loss: 19.3188\n",
            "Epoch 32/100\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 8.1239 - val_loss: 9.1437\n",
            "Epoch 33/100\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.8768 - val_loss: 8.3266\n",
            "Epoch 34/100\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.7749 - val_loss: 8.4494\n",
            "Epoch 35/100\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.9261 - val_loss: 13.9155\n",
            "Epoch 36/100\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 7.4539 - val_loss: 10.3875\n",
            "Epoch 37/100\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.0234 - val_loss: 8.3262\n",
            "Epoch 38/100\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.0917 - val_loss: 12.2995\n",
            "Epoch 39/100\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 7.2967 - val_loss: 11.0665\n",
            "Epoch 40/100\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 6.4532 - val_loss: 12.6815\n",
            "Epoch 41/100\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 6.9210 - val_loss: 16.6524\n",
            "Epoch 42/100\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 7.0623 - val_loss: 8.9131\n",
            "Epoch 43/100\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 6.6154 - val_loss: 8.3172\n",
            "Epoch 44/100\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 6.7258 - val_loss: 19.2243\n",
            "Epoch 45/100\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 9.3502 - val_loss: 8.2817\n",
            "Epoch 46/100\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 6.7146 - val_loss: 9.1638\n",
            "Epoch 47/100\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.8853 - val_loss: 16.9983\n",
            "Epoch 48/100\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 8.2112 - val_loss: 10.2742\n",
            "Epoch 49/100\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 6.8943 - val_loss: 9.1240\n",
            "Epoch 50/100\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 6.6443 - val_loss: 8.3008\n",
            "Epoch 51/100\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 7.2208 - val_loss: 8.4379\n",
            "Epoch 52/100\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 6.2390 - val_loss: 10.1014\n",
            "Epoch 53/100\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 6.7944 - val_loss: 9.5150\n",
            "Epoch 54/100\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 6.5893 - val_loss: 9.2605\n",
            "Epoch 55/100\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 7.3189 - val_loss: 8.1663\n",
            "Epoch 56/100\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 6.2145 - val_loss: 9.3362\n",
            "Epoch 57/100\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.3325 - val_loss: 8.4039\n",
            "Epoch 58/100\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.2890 - val_loss: 11.7651\n",
            "Epoch 59/100\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 6.2793 - val_loss: 8.8607\n",
            "Epoch 60/100\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 7.3518 - val_loss: 9.7118\n",
            "Epoch 61/100\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 6.4530 - val_loss: 8.9342\n",
            "Epoch 62/100\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 7.1472 - val_loss: 9.0439\n",
            "Epoch 63/100\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 6.5554 - val_loss: 9.1440\n",
            "Epoch 64/100\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.8343 - val_loss: 8.4094\n",
            "Epoch 65/100\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 6.9028 - val_loss: 8.4741\n",
            "Epoch 66/100\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 6.9248 - val_loss: 10.2430\n",
            "Epoch 67/100\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.7246 - val_loss: 8.5961\n",
            "Epoch 68/100\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.6070 - val_loss: 8.5034\n",
            "Epoch 69/100\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 6.4695 - val_loss: 8.4527\n",
            "Epoch 70/100\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.3237 - val_loss: 8.1279\n",
            "Epoch 71/100\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.2460 - val_loss: 8.1370\n",
            "Epoch 72/100\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 6.0754 - val_loss: 7.8605\n",
            "Epoch 73/100\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.9798 - val_loss: 7.9187\n",
            "Epoch 74/100\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 6.2457 - val_loss: 8.3135\n",
            "Epoch 75/100\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 6.2221 - val_loss: 8.6356\n",
            "Epoch 76/100\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 6.0426 - val_loss: 7.7871\n",
            "Epoch 77/100\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 6.5782 - val_loss: 8.7082\n",
            "Epoch 78/100\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 6.2743 - val_loss: 8.5285\n",
            "Epoch 79/100\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 6.8993 - val_loss: 9.4769\n",
            "Epoch 80/100\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.9660 - val_loss: 9.8405\n",
            "Epoch 81/100\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 6.2764 - val_loss: 8.3289\n",
            "Epoch 82/100\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.8129 - val_loss: 8.1334\n",
            "Epoch 83/100\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.1123 - val_loss: 8.5674\n",
            "Epoch 84/100\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.1107 - val_loss: 9.0264\n",
            "Epoch 85/100\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 6.7291 - val_loss: 8.2298\n",
            "Epoch 86/100\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.2997 - val_loss: 12.5973\n",
            "Epoch 87/100\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.4798 - val_loss: 8.4090\n",
            "Epoch 88/100\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 6.5998 - val_loss: 8.7874\n",
            "Epoch 89/100\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.8235 - val_loss: 8.0069\n",
            "Epoch 90/100\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.2165 - val_loss: 9.1342\n",
            "Epoch 91/100\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 6.0755 - val_loss: 8.9065\n",
            "Epoch 92/100\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 5.9404 - val_loss: 8.1491\n",
            "Epoch 93/100\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.1509 - val_loss: 7.9127\n",
            "Epoch 94/100\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.9943 - val_loss: 8.6428\n",
            "Epoch 95/100\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.4322 - val_loss: 8.3176\n",
            "Epoch 96/100\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 5.8544 - val_loss: 8.4085\n",
            "Epoch 97/100\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 6.2910 - val_loss: 19.4502\n",
            "Epoch 98/100\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 7.7851 - val_loss: 8.8221\n",
            "Epoch 99/100\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 6.0368 - val_loss: 7.9745\n",
            "Epoch 100/100\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.9357 - val_loss: 8.6646\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = classifier2.predict(X_test)\n",
        "mse_class2 = mean_squared_error(y_test, y_pred)\n",
        "r2_square_class2 = r2_score(y_test, y_pred)\n",
        "print_evaluate(y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_vpwWyjL51b",
        "outputId": "b9acf555-20b0-4f27-ce0c-eee94428a492"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 [==============================] - 0s 1ms/step\n",
            "MSE: 8.664608066930981\n",
            "RMSE: 2.9435706322306894\n",
            "R2 Square 0.7743703317210787\n",
            "__________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### classifier3"
      ],
      "metadata": {
        "id": "GG74tyZkMtSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.85,random_state=42)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full,test_size=0.55, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_valid = scaler.transform(X_valid)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "Q-mP5XJvMsCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier3 = keras.models.Sequential([\n",
        "    keras.layers.Input(shape=X_train.shape[1:]),\n",
        "    keras.layers.Dense(7, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "classifier3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peUXktryM7hx",
        "outputId": "33f5dd9e-5948-4e76-bc3b-f4fd846f2651"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_141\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_373 (Dense)           (None, 7)                 63        \n",
            "                                                                 \n",
            " dense_374 (Dense)           (None, 1)                 8         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 71\n",
            "Trainable params: 71\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier3.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(learning_rate=0.01))\n",
        "history_classifier3 = classifier3.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F425Cv5oM1zM",
        "outputId": "0500447a-5708-41bd-c7e2-ce46bcd9d32e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "3/3 [==============================] - 0s 82ms/step - loss: 340.6091 - val_loss: 200.6018\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 179.7996 - val_loss: 55.4598\n",
            "Epoch 3/100\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 62.1036 - val_loss: 73.2933\n",
            "Epoch 4/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 56.8210 - val_loss: 30.4035\n",
            "Epoch 5/100\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 27.2706 - val_loss: 23.0200\n",
            "Epoch 6/100\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 22.3579 - val_loss: 18.5407\n",
            "Epoch 7/100\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 15.4282 - val_loss: 15.1362\n",
            "Epoch 8/100\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 19.5832 - val_loss: 18.5672\n",
            "Epoch 9/100\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 14.0064 - val_loss: 15.0367\n",
            "Epoch 10/100\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 12.3710 - val_loss: 13.8378\n",
            "Epoch 11/100\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 17.0251 - val_loss: 15.3495\n",
            "Epoch 12/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 13.9671 - val_loss: 15.4968\n",
            "Epoch 13/100\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 12.7372 - val_loss: 15.5193\n",
            "Epoch 14/100\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 14.9405 - val_loss: 14.4078\n",
            "Epoch 15/100\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 17.1868 - val_loss: 16.2764\n",
            "Epoch 16/100\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 12.4599 - val_loss: 13.3054\n",
            "Epoch 17/100\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 14.6147 - val_loss: 33.9437\n",
            "Epoch 18/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 23.1820 - val_loss: 17.1217\n",
            "Epoch 19/100\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 13.6621 - val_loss: 18.3381\n",
            "Epoch 20/100\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 12.9945 - val_loss: 17.5458\n",
            "Epoch 21/100\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 11.5907 - val_loss: 14.9825\n",
            "Epoch 22/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 17.7996 - val_loss: 16.7980\n",
            "Epoch 23/100\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 12.4401 - val_loss: 15.3237\n",
            "Epoch 24/100\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 10.7327 - val_loss: 13.9442\n",
            "Epoch 25/100\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 13.3023 - val_loss: 15.5004\n",
            "Epoch 26/100\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 9.3352 - val_loss: 12.9742\n",
            "Epoch 27/100\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 13.3808 - val_loss: 31.8395\n",
            "Epoch 28/100\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 20.4755 - val_loss: 15.2416\n",
            "Epoch 29/100\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 12.3083 - val_loss: 13.7297\n",
            "Epoch 30/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 12.9091 - val_loss: 13.5885\n",
            "Epoch 31/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 12.5070 - val_loss: 29.2720\n",
            "Epoch 32/100\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 19.5607 - val_loss: 15.6833\n",
            "Epoch 33/100\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 10.3405 - val_loss: 13.8627\n",
            "Epoch 34/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 11.6582 - val_loss: 15.6548\n",
            "Epoch 35/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 10.9537 - val_loss: 19.6840\n",
            "Epoch 36/100\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 12.0989 - val_loss: 13.8861\n",
            "Epoch 37/100\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 11.2947 - val_loss: 24.2934\n",
            "Epoch 38/100\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 16.1081 - val_loss: 16.3178\n",
            "Epoch 39/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 11.1691 - val_loss: 16.2384\n",
            "Epoch 40/100\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 12.0569 - val_loss: 22.0212\n",
            "Epoch 41/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 14.7635 - val_loss: 15.2834\n",
            "Epoch 42/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 8.8446 - val_loss: 12.9065\n",
            "Epoch 43/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 13.8526 - val_loss: 17.4534\n",
            "Epoch 44/100\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 11.0312 - val_loss: 15.6976\n",
            "Epoch 45/100\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 9.1019 - val_loss: 14.7081\n",
            "Epoch 46/100\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 14.3432 - val_loss: 16.7670\n",
            "Epoch 47/100\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 9.7798 - val_loss: 13.5738\n",
            "Epoch 48/100\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 13.4659 - val_loss: 16.5083\n",
            "Epoch 49/100\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 9.6511 - val_loss: 14.1146\n",
            "Epoch 50/100\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 11.1333 - val_loss: 13.8338\n",
            "Epoch 51/100\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 9.2058 - val_loss: 13.2142\n",
            "Epoch 52/100\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 10.1629 - val_loss: 22.8067\n",
            "Epoch 53/100\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 14.4869 - val_loss: 14.1005\n",
            "Epoch 54/100\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 13.2940 - val_loss: 14.9461\n",
            "Epoch 55/100\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 9.9040 - val_loss: 13.9179\n",
            "Epoch 56/100\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 7.9408 - val_loss: 13.8868\n",
            "Epoch 57/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 14.3571 - val_loss: 13.7400\n",
            "Epoch 58/100\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 8.2467 - val_loss: 13.2484\n",
            "Epoch 59/100\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 8.8866 - val_loss: 13.2680\n",
            "Epoch 60/100\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 8.1292 - val_loss: 14.0541\n",
            "Epoch 61/100\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 7.7655 - val_loss: 12.6895\n",
            "Epoch 62/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 8.3410 - val_loss: 12.8663\n",
            "Epoch 63/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 9.4458 - val_loss: 23.6652\n",
            "Epoch 64/100\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 15.1352 - val_loss: 14.3643\n",
            "Epoch 65/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 10.3816 - val_loss: 16.8515\n",
            "Epoch 66/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 9.7580 - val_loss: 12.0870\n",
            "Epoch 67/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 11.2679 - val_loss: 14.1507\n",
            "Epoch 68/100\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 7.7956 - val_loss: 12.9335\n",
            "Epoch 69/100\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 8.4101 - val_loss: 20.0734\n",
            "Epoch 70/100\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 12.6476 - val_loss: 12.6446\n",
            "Epoch 71/100\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 7.7131 - val_loss: 12.9402\n",
            "Epoch 72/100\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 7.6486 - val_loss: 17.1380\n",
            "Epoch 73/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 10.1925 - val_loss: 12.2515\n",
            "Epoch 74/100\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 9.4884 - val_loss: 12.1208\n",
            "Epoch 75/100\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 7.2895 - val_loss: 12.9412\n",
            "Epoch 76/100\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 7.1070 - val_loss: 12.3796\n",
            "Epoch 77/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 7.2230 - val_loss: 12.5551\n",
            "Epoch 78/100\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 6.4181 - val_loss: 11.5809\n",
            "Epoch 79/100\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 7.1199 - val_loss: 13.4640\n",
            "Epoch 80/100\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 6.4963 - val_loss: 11.6520\n",
            "Epoch 81/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 6.8587 - val_loss: 12.2203\n",
            "Epoch 82/100\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 5.9661 - val_loss: 12.4844\n",
            "Epoch 83/100\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 7.7776 - val_loss: 12.1142\n",
            "Epoch 84/100\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 5.6128 - val_loss: 11.3923\n",
            "Epoch 85/100\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 6.5146 - val_loss: 11.8114\n",
            "Epoch 86/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 6.9960 - val_loss: 12.4096\n",
            "Epoch 87/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 8.4915 - val_loss: 12.4021\n",
            "Epoch 88/100\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 6.0167 - val_loss: 10.9710\n",
            "Epoch 89/100\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 5.8945 - val_loss: 10.9906\n",
            "Epoch 90/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 5.6143 - val_loss: 12.0192\n",
            "Epoch 91/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 6.1177 - val_loss: 10.6586\n",
            "Epoch 92/100\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 6.0444 - val_loss: 13.1931\n",
            "Epoch 93/100\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 7.1089 - val_loss: 12.0393\n",
            "Epoch 94/100\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 6.0126 - val_loss: 12.1426\n",
            "Epoch 95/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 7.4059 - val_loss: 10.8110\n",
            "Epoch 96/100\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 4.7413 - val_loss: 10.6310\n",
            "Epoch 97/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 5.1844 - val_loss: 11.0914\n",
            "Epoch 98/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 5.2730 - val_loss: 11.1835\n",
            "Epoch 99/100\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 5.6424 - val_loss: 11.1592\n",
            "Epoch 100/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 4.5591 - val_loss: 10.7073\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = classifier3.predict(X_test)\n",
        "mse_class3 = mean_squared_error(y_test, y_pred)\n",
        "r2_square_class3 = r2_score(y_test, y_pred)\n",
        "print_evaluate(y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXDNxKNANPi3",
        "outputId": "5a67d46d-12c4-4ef9-a0f5-d45e720e1cb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35/35 [==============================] - 0s 1ms/step\n",
            "MSE: 10.707318392954942\n",
            "RMSE: 3.272203904550409\n",
            "R2 Square 0.7205834655106036\n",
            "__________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### classifier4"
      ],
      "metadata": {
        "id": "o8Q5ELLOOCxP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.2,random_state=42)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full,test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_valid = scaler.transform(X_valid)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "LzjixB3LOEbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier4 = keras.models.Sequential([\n",
        "    keras.layers.Input(shape=X_train.shape[1:]),\n",
        "    keras.layers.Dense(7, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
        "    keras.layers.Dense(1)\n",
        "])\n"
      ],
      "metadata": {
        "id": "e__xvE6ZOHTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier4.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(learning_rate=0.01))\n",
        "history_classifier4 = classifier4.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMtRqajnOREX",
        "outputId": "b842948d-d190-40c0-e663-ea0de6e7b946"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "27/27 [==============================] - 1s 8ms/step - loss: 97.9091 - val_loss: 11.2989\n",
            "Epoch 2/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 32.1914 - val_loss: 11.2571\n",
            "Epoch 3/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 12.6674 - val_loss: 20.3690\n",
            "Epoch 4/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 41.0105 - val_loss: 6.7361\n",
            "Epoch 5/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 13.0549 - val_loss: 8.3760\n",
            "Epoch 6/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 11.3577 - val_loss: 6.3441\n",
            "Epoch 7/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 10.5779 - val_loss: 9.3019\n",
            "Epoch 8/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 11.9796 - val_loss: 7.9666\n",
            "Epoch 9/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 10.3015 - val_loss: 17.1166\n",
            "Epoch 10/100\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 9.2424 - val_loss: 11.7501\n",
            "Epoch 11/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 10.0595 - val_loss: 4.8289\n",
            "Epoch 12/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 9.4560 - val_loss: 12.3345\n",
            "Epoch 13/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 8.9945 - val_loss: 5.8849\n",
            "Epoch 14/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 9.2726 - val_loss: 11.6099\n",
            "Epoch 15/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 10.0896 - val_loss: 6.8132\n",
            "Epoch 16/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 9.0191 - val_loss: 5.2501\n",
            "Epoch 17/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 8.6714 - val_loss: 6.8610\n",
            "Epoch 18/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 9.3863 - val_loss: 8.6892\n",
            "Epoch 19/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 7.9441 - val_loss: 4.9779\n",
            "Epoch 20/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 8.1166 - val_loss: 4.6142\n",
            "Epoch 21/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 8.6060 - val_loss: 8.7949\n",
            "Epoch 22/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 8.9561 - val_loss: 9.3543\n",
            "Epoch 23/100\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 10.2873 - val_loss: 5.5356\n",
            "Epoch 24/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 8.3209 - val_loss: 75.5060\n",
            "Epoch 25/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 14.2481 - val_loss: 7.9647\n",
            "Epoch 26/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 8.1469 - val_loss: 8.4230\n",
            "Epoch 27/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 8.7709 - val_loss: 4.7385\n",
            "Epoch 28/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 9.5605 - val_loss: 8.6507\n",
            "Epoch 29/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 8.6353 - val_loss: 7.9663\n",
            "Epoch 30/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 8.4515 - val_loss: 10.7611\n",
            "Epoch 31/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 8.2335 - val_loss: 5.4082\n",
            "Epoch 32/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 7.9707 - val_loss: 5.5537\n",
            "Epoch 33/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 9.0264 - val_loss: 9.9036\n",
            "Epoch 34/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 8.9467 - val_loss: 11.6782\n",
            "Epoch 35/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 8.8692 - val_loss: 14.0694\n",
            "Epoch 36/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 8.0050 - val_loss: 6.3000\n",
            "Epoch 37/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 7.5965 - val_loss: 22.7503\n",
            "Epoch 38/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 8.4131 - val_loss: 9.2660\n",
            "Epoch 39/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 8.7384 - val_loss: 16.0174\n",
            "Epoch 40/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 8.9185 - val_loss: 4.8063\n",
            "Epoch 41/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 9.0879 - val_loss: 5.8959\n",
            "Epoch 42/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 9.2152 - val_loss: 5.2354\n",
            "Epoch 43/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 9.7725 - val_loss: 6.7428\n",
            "Epoch 44/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 8.9978 - val_loss: 4.8053\n",
            "Epoch 45/100\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 8.2474 - val_loss: 17.7273\n",
            "Epoch 46/100\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 8.4387 - val_loss: 6.6473\n",
            "Epoch 47/100\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 9.1488 - val_loss: 5.1342\n",
            "Epoch 48/100\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 9.3622 - val_loss: 9.3974\n",
            "Epoch 49/100\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 7.7971 - val_loss: 9.0688\n",
            "Epoch 50/100\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 8.7113 - val_loss: 5.4941\n",
            "Epoch 51/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 8.6075 - val_loss: 25.6273\n",
            "Epoch 52/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 9.5160 - val_loss: 24.1979\n",
            "Epoch 53/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 8.3495 - val_loss: 10.3387\n",
            "Epoch 54/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 8.6242 - val_loss: 5.4912\n",
            "Epoch 55/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 10.7622 - val_loss: 9.0211\n",
            "Epoch 56/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 7.9436 - val_loss: 9.6372\n",
            "Epoch 57/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 9.0723 - val_loss: 5.5933\n",
            "Epoch 58/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 7.6234 - val_loss: 17.0793\n",
            "Epoch 59/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 8.9678 - val_loss: 16.2472\n",
            "Epoch 60/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 9.0186 - val_loss: 10.5897\n",
            "Epoch 61/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 8.4062 - val_loss: 4.6929\n",
            "Epoch 62/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 8.5326 - val_loss: 10.6925\n",
            "Epoch 63/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 9.0096 - val_loss: 12.2347\n",
            "Epoch 64/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 8.2210 - val_loss: 5.2385\n",
            "Epoch 65/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 7.4460 - val_loss: 8.6701\n",
            "Epoch 66/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 7.8399 - val_loss: 6.2742\n",
            "Epoch 67/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 7.4265 - val_loss: 8.2895\n",
            "Epoch 68/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 8.7041 - val_loss: 5.0416\n",
            "Epoch 69/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 7.8142 - val_loss: 5.3033\n",
            "Epoch 70/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 7.7501 - val_loss: 5.5240\n",
            "Epoch 71/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 8.3861 - val_loss: 7.3702\n",
            "Epoch 72/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 7.7150 - val_loss: 13.3668\n",
            "Epoch 73/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 8.7724 - val_loss: 5.2265\n",
            "Epoch 74/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 8.8047 - val_loss: 8.5067\n",
            "Epoch 75/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 10.2027 - val_loss: 4.8684\n",
            "Epoch 76/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 8.3775 - val_loss: 4.7324\n",
            "Epoch 77/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 8.3684 - val_loss: 5.5858\n",
            "Epoch 78/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 7.9407 - val_loss: 6.1101\n",
            "Epoch 79/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 8.1946 - val_loss: 5.8566\n",
            "Epoch 80/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 7.4713 - val_loss: 12.2188\n",
            "Epoch 81/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 8.3818 - val_loss: 14.4509\n",
            "Epoch 82/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 7.5674 - val_loss: 7.1043\n",
            "Epoch 83/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 8.0878 - val_loss: 7.4417\n",
            "Epoch 84/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 8.4774 - val_loss: 17.8150\n",
            "Epoch 85/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 9.4297 - val_loss: 9.3386\n",
            "Epoch 86/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 8.0124 - val_loss: 17.0313\n",
            "Epoch 87/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 10.2934 - val_loss: 5.5463\n",
            "Epoch 88/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 8.3633 - val_loss: 34.7673\n",
            "Epoch 89/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 10.4849 - val_loss: 6.3480\n",
            "Epoch 90/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 7.8960 - val_loss: 8.2038\n",
            "Epoch 91/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 9.0800 - val_loss: 5.5272\n",
            "Epoch 92/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 6.9462 - val_loss: 5.2949\n",
            "Epoch 93/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 8.6636 - val_loss: 4.7801\n",
            "Epoch 94/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 7.5654 - val_loss: 5.1242\n",
            "Epoch 95/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 7.4641 - val_loss: 6.0742\n",
            "Epoch 96/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 8.6948 - val_loss: 23.5653\n",
            "Epoch 97/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 9.0401 - val_loss: 9.9259\n",
            "Epoch 98/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 8.3722 - val_loss: 9.7476\n",
            "Epoch 99/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 8.7094 - val_loss: 6.4357\n",
            "Epoch 100/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 7.5319 - val_loss: 5.9165\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = classifier4.predict(X_test)\n",
        "mse_class4 = mean_squared_error(y_test, y_pred)\n",
        "r2_square_class4 = r2_score(y_test, y_pred)\n",
        "print_evaluate(y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRv_SKINOppi",
        "outputId": "8819b1aa-1551-4798-886b-4d2ca4301f84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 0s 2ms/step\n",
            "MSE: 5.91646727329234\n",
            "RMSE: 2.4323789329157455\n",
            "R2 Square 0.805704583766535\n",
            "__________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### table of 3 classifiers"
      ],
      "metadata": {
        "id": "m_M2GDo8NTUM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tabulate import tabulate\n",
        "\n",
        "table = [['model_name','describe','MSE', 'R2_Score'], \n",
        "         ['classifier1', 'train:test = 0.75: 0.25',mse_class1, r2_square_class1], \n",
        "         ['classifier2', 'train:test = 0.45: 0.55',mse_class2, r2_square_class2], \n",
        "         ['classifier3', 'train:test = 0.15: 0.85',mse_class3, r2_square_class3], \n",
        "         ['classifier4', 'train:test = 0.80: 0.20',mse_class4, r2_square_class4], \n",
        "         ]\n",
        "         \n",
        "print(tabulate(table))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlusdCrHNS80",
        "outputId": "de042d82-1655-4630-a906-895494c15785"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------  -----------------------  ------------------  ------------------\n",
            "model_name   describe                 MSE                 R2_Score\n",
            "classifier1  train:test = 0.75: 0.25  4.786880449982313   0.8329478089785853\n",
            "classifier2  train:test = 0.45: 0.55  8.664608066930981   0.7743703317210787\n",
            "classifier3  train:test = 0.15: 0.85  10.707318392954942  0.7205834655106036\n",
            "classifier4  train:test = 0.85: 0.15  5.91646727329234    0.805704583766535\n",
            "-----------  -----------------------  ------------------  ------------------\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.13 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "9851e1369492554e682af8da439ce23d94f59fcc2cb07f7273af5455dce3c9c3"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}